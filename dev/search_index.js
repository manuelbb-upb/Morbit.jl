var documenterSearchIndex = {"docs":
[{"location":"notebooks/notebook_polynomial_interpolation/","page":"Lagrange Interpolation","title":"Lagrange Interpolation","text":"<style>\n    table {\n        display: table !important;\n        margin: 2rem auto !important;\n        border-top: 2pt solid rgba(0,0,0,0.2);\n        border-bottom: 2pt solid rgba(0,0,0,0.2);\n    }\n\n    pre, div {\n        margin-top: 1.4rem !important;\n        margin-bottom: 1.4rem !important;\n    }\n</style>\n\n<!-- PlutoStaticHTML.Begin -->\n<!--\n    # This information is used for caching.\n    [PlutoStaticHTML.State]\n    input_sha = \"82012d577aa3f4c8a17e8ae42e5be8699cf7aae035a78d6f6e96e99bcbd777d2\"\n    julia_version = \"1.6.5\"\n-->\n<pre class='language-julia'><code class='language-julia'>begin\n\timport Pkg\n\tPkg.activate(tempname())\n\tPkg.add(\"DynamicPolynomials\")\n\tPkg.add(\"NLopt\")\n\tPkg.add(\"StaticArrays\")\n\tPkg.add(\"CairoMakie\")\n\tPkg.add(\"Makie\")\n\tPkg.add(\"Combinatorics\")\n\tPkg.add(\"BenchmarkTools\")\nend</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tusing DynamicPolynomials\n\tusing BenchmarkTools\n\timport NLopt\n\tusing StaticArrays\n\tusing Makie, CairoMakie\n\tusing Combinatorics\nend</code></pre>\n\n\n\n<div class=\"markdown\"><p>We denote by <span class=\"tex\">$Π_n^d$</span> the space of <span class=\"tex\">$n$</span>-variate Polyoniams of degree at most <span class=\"tex\">$d$</span>. To construct polynomials we use <code>DynamicPolynomials.jl</code>.</p>\n</div>\n\n\n<div class=\"markdown\"><p>The canonical basis is obtained by calculating the non-negative integral solutions to the euqation</p>\n<p class=\"tex\">$$x_1 &#43; … &#43; x_n \\le d.$$</p>\n</div>\n\n\n<div class=\"markdown\"><p>These solutions can be found using the <code>Combinatorics</code> package via <code>multiexponents&#40;n,d&#41;</code> &#40;<code>d</code> must be successively increased&#41;.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function non_negative_ineq_solutions(deg, n_vars)\n\tcollect(Iterators.flatten( ( collect(multiexponents( n_vars, d )) for d = 0 : deg ) ))\nend</code></pre>\n<pre id='var-non_negative_ineq_solutions' class='pre-class'><code class='code-output'>non_negative_ineq_solutions (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function get_poly_basis( deg, n_vars)\n\texponents = non_negative_ineq_solutions(deg, n_vars )\n\tpolys = let\n\t\t@polyvar x[1:n_vars]\n\t\t[ prod(x.^e) for e in exponents ]\n\tend\n\treturn polys\nend</code></pre>\n<pre id='var-get_poly_basis' class='pre-class'><code class='code-output'>get_poly_basis (generic function with 1 method)</code></pre>\n\n\n<div class=\"markdown\"><p>We are going to use the canonical basis to determine a <strong>poised set</strong> of points. This does in fact work with any polynomial basis for <span class=\"tex\">$Π_n^d$</span>. <br />In the process of doing so, we also modify &#40;a copy of?&#41; the basis so that it becomes the Lagrange basis for the returned point set.</p>\n</div>\n\n\n<div class=\"markdown\"><p>The Larange basis is formed by normalizing and orthogonalizing with respect to the point set:</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function orthogonalize_polys( poly_arr, x, i )\n\t# normalize i-th polynomial with respect to `x`\n\tp_i = poly_arr[i] / poly_arr[i](x)\n\t\n\t# orthogoalize \n\treturn [ j != i ? poly_arr[j] - poly_arr[j](x) * p_i : p_i for j = eachindex( poly_arr ) ]\nend</code></pre>\n<pre id='var-orthogonalize_polys' class='pre-class'><code class='code-output'>orthogonalize_polys (generic function with 1 method)</code></pre>\n\n\n<div class=\"markdown\"><p>We use Algorithm 6.2 and Algorithm 6.3 from the book  &quot;Introduction to Derivative-Free Optimization&quot; by Conn et. al. <br />Algorithm 6.2 makes the set poised &#40;suited for interpolation&#41; and returns the corresponding Lagrange basis. Algorithm 6.3 takes the poised set and the Lagrange basis and tries to make it <span class=\"tex\">$Λ$</span>-poised. <span class=\"tex\">$Λ$</span> must be greater 1 and a smaller value makes the set more suited for good models.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>\"\"\"\n    get_poised_set( basis, points; solver = :LN_BOBYQA, max_solver_evals = -1 )\n\nCompute a point set suited for polynomial interpolation.\n\nInput:\n* `basis`: A vector of polynomials constituting a basis for the polynomial space.\n* `points`: (optional) A set of candidate points to be tried for inclusion into the poised set.\n* `solver`: NLopt solver to use. Should be derivative-free.\n* `max_solver_evals`: Maximum number of evaluations in each optimization run. \n\nReturn:\n* `poised_points :: Vector{T}` where `T` is either a `Vector{F}` or an `SVector{n_vars, F}` and `F` is the precision of the points in `points`, but at least `Float32`. \n* `lagrange_basis :: Vector{&lt;:AbstractPolynomialLike}`: The Lagrange basis corresponding to `poised_points`.\n* `point_indices`: An array indicating which points from `points` are also in `poised_points`. A positive entry corresponds to the index of a poised point in `points`. If a poised point is new, then the entry is `-1`.\n\"\"\"\nfunction get_poised_set( basis, points :: AbstractArray{T} = Vector{Float32}[]; \n\t\tsolver = :LN_BOBYQA, max_solver_evals = -1 ) where {\n\t\tT &lt;: AbstractArray{&lt;:Real}\n\t}\n\t\n\tp = length(basis)\n\t@assert p &gt; 0 \"`basis` must not be an empty array.\"\n\n\tvars = variables( basis[end] )\n\tn_vars = length(vars)\n\t@assert n_vars &gt; 0 \"The number of variables must be positive.\"\n\t\n\tif max_solver_evals &lt; 0\n\t\tmax_solver_evals = 2000 * n_vars\n\tend\n\n\tF = promote_type( eltype( T ), Float32 )\n\tP_type = n_vars &gt; 100 ? Vector{Vector{F}} : Vector{SVector{n_vars, F}}\n\tZERO_TOL = min(eps(F) * 100, eps(Float16) * 10)\n\t\n\t# indicates which points from points have been accepted\n\tpoint_indices = fill(-1, p)\n\tnot_accepted_indices = collect( eachindex( points ) )\n\t# return array of points that form a poised set\n\tpoised_points = P_type(undef, p)\n\t\t\n\tnew_basis = basis\n\tfor i = 1 : p\n\t\t_points = points[not_accepted_indices]\n\t\t\n\t\t# find the point that maximizes the i-th polynomial \n\t\t# if the polynomial is constant, then the first remaining point is used (j = 1)\n\t\tl_max, j = if isempty(_points)\n\t\t\t0.0, 0\n\t\telse\n\t\t\tfindmax( abs.( [ new_basis[i]( x ) for x in _points ] ) )\n\t\tend\n\t\t\n\t\tif l_max &gt; ZERO_TOL\n\t\t\t# accept the `j`-th point from `_points`\n\t\t\tpoised_points[i] = _points[j]\n\t\t\t## indicate what the actual point index was  \n\t\t\tpoint_indices[i] = not_accepted_indices[j]\n\t\t\t## delete from further consideration\n\t\t\tdeleteat!(not_accepted_indices, j)\n\t\telse\n\t\t\t# no point was suitable to add to the set\n\t\t\t# trying to find the maximizer for a | l_i(x) |\n\t\t\topt = NLopt.Opt( solver, n_vars ) \n\t\t\topt.lower_bounds = zeros(F, n_vars )\n            opt.upper_bounds = ones(F, n_vars )\n            opt.maxeval = max_solver_evals\n            opt.xtol_rel = 1e-3\n            opt.max_objective = (x,g) -&gt; abs( new_basis[i](x) )\n\t\t\t\n\t\t\tx₀_tmp = [ rand(F, n_vars) for i = 1 : 50 * n_vars ]\n            x₀ = x₀_tmp[argmax( abs.(new_basis[i].(x₀_tmp)) ) ] \n            \n\t\t\t_, ξ, ret = NLopt.optimize(opt, x₀)\n\t\t\t\n\t\t\tpoised_points[i] = ξ\n\t\tend\t\t\n\t\t\n\t\tnew_basis = orthogonalize_polys( new_basis, poised_points[i], i )\n\tend\n\t\n\treturn poised_points, new_basis, point_indices\nend\n\t\t\t</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>\"\"\"\n    make_set_lambda_poised( basis, points; \n        LAMBDA = 1.5, solver = :LN_BOBYQA, max_solver_evals = -1, max_loops = -1, skip_indices = [1,] )\n\nMake the output of `get_poised_set` even better suited for interpolation.\n\nInput:\n* `basis`: A vector of polynomials constituting a Lagrange basis for the polynomial space.\n* `points`: The vector of points belonging to the Lagrange basis.\n* `LAMBDA :: Real &gt; 1`: Determines the quality of the interpolation. \n* `solver`: NLopt solver to use. Should be derivative-free.\n* `max_solver_evals`: Maximum number of evaluations in each optimization run. \n* `max_loops`: Maximum number of loops that try to make the set Λ-poised.\n* `skip_indices`: Inidices of points to discard last.\n\nReturn:\n* `poised_points :: Vector{T}` where `T` is either a `Vector{F}` or an `SVector{n_vars, F}` and `F` is the precision of the points in `points`, but at least `Float32`. \n* `lagrange_basis :: Vector{&lt;:AbstractPolynomialLike}`: The Lagrange basis corresponding to `poised_points`.\n* `point_indices`: An array indicating which points from `points` are also in `poised_points`. A positive entry corresponds to the index of a poised point in `points`. If a poised point is new, then the entry is `-1`.\n\"\"\"\nfunction make_set_lambda_poised( basis, points :: AbstractArray{T}; \n\t\tLAMBDA :: Real = 1.5, solver = :LN_BOBYQA, max_solver_evals = -1,\n\t\tmax_loops = -1, skip_indices = [1,] ) where {\n\t\tT &lt;: AbstractArray{&lt;:Real}\n\t}\n\t\n\t@assert length(basis) == length(points) \"Polynomial array `basis` and point array `points` must have the same length.\"\n\t\n\tif length(points) &gt; 0\n\t\tn_vars = length(points[1])\n\t\t@assert n_vars &gt; 0 \"The number of variables must be positive.\"\n\t\t\n\t\tF = promote_type( eltype( T ), Float32 )\n\t\tP_type = n_vars &gt; 100 ? Vector{Vector{F}} : Vector{SVector{n_vars, F}}\n\n\t\tif max_loops &lt; 0 \n\t\t\tmax_loops = length(basis) * 100\n\t\tend\n\n\t\tif max_solver_evals &lt; 0\n\t\t\tmax_solver_evals = 2000 * n_vars\n\t\tend\n\n\t\tnew_basis = basis\n\t\tnew_points = P_type(points)\n\t\tpoint_indices = collect(eachindex(new_points))\n\n\t\tfor k = 1 : max_loops\n\t\t\tiₖ = -1\n\t\t\txₖ = points[1]\n\t\t\tfor (i, polyᵢ) in enumerate(new_basis)\n\t\t\t\topt = NLopt.Opt( solver, n_vars )\n\t\t\t\topt.lower_bounds = zeros(F, n_vars)\n\t\t\t\topt.upper_bounds = ones(F, n_vars)\n\t\t\t\topt.maxeval = max_solver_evals\n\t\t\t\topt.xtol_rel = 1e-3\n\t\t\t\topt.max_objective = (x,g) -&gt; abs( polyᵢ( x ) ) \n\n\t\t\t\tx₀_tmp = [ rand(F, n_vars) for i = 1 : 50 * n_vars ]\n\t\t\t\tx₀ = x₀_tmp[argmax( abs.(new_basis[i].(x₀_tmp)) ) ] \n\n\t\t\t\tabs_lᵢ, xᵢ, _ = NLopt.optimize(opt, x₀)\n\n\t\t\t\tif abs_lᵢ &gt; LAMBDA\n\t\t\t\t\tiₖ = i\n\t\t\t\t\txₖ = xᵢ\n\t\t\t\t\tif i ∉ skip_indices\n\t\t\t\t\t\t# i is not prioritized we can brake here\n\t\t\t\t\t\tbreak\n\t\t\t\t\tend#if\n\t\t\t\tend#if\n\t\t\tend#for\n\n\t\t\tif iₖ &gt; 0\n\t\t\t\t# perform a point swap\n\t\t\t\tnew_points[iₖ] = xₖ\n\t\t\t\tpoint_indices[iₖ] = -1\n\t\t\t\t# adapt coefficients of lagrange basis\n\t\t\t\tnew_basis = orthogonalize_polys( new_basis, xₖ, iₖ )\n\t\t\telse\n\t\t\t\t# we are done, the set is lambda poised\n\t\t\t\tbreak\n\t\t\tend#if\n\t\tend#for\n\n\t\treturn new_points, new_basis, point_indices\n\telse\n\t\treturn points, basis, collect(eachindex(points))\n\tend\n\t\nend</code></pre>\n\n\n\n<div class=\"markdown\"><p>For the sake of convenience we combine both functions:</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function get_lambda_poised_set( basis, points; solver1 = :LN_BOBYQA, solver2 = :LN_BOBYQA, max_solver_evals1 = -1, max_solver_evals2 = -1, LAMBDA = 1.5, max_lambda_loops = -1 )\n\tlagrange_points, lagrange_basis, lagrange_indices = get_poised_set( \n\t\tbasis, points; solver = solver1, max_solver_evals = max_solver_evals1 )\n\tlambda_points, lambda_basis, lambda_indices = make_set_lambda_poised( \n\t\tlagrange_basis, lagrange_points; LAMBDA, max_loops = max_lambda_loops,\n\t\tsolver = solver2, max_solver_evals = max_solver_evals2 )\n\tcombined_indices = [ i &lt; 0 ? i : lagrange_indices[j] for (j,i) in enumerate( lambda_indices ) ]\n\treturn lambda_points, lambda_basis, combined_indices\nend</code></pre>\n<pre id='var-get_lambda_poised_set' class='pre-class'><code class='code-output'>get_lambda_poised_set (generic function with 1 method)</code></pre>\n\n\n<div class=\"markdown\"><p>Let&#39;s have a look at what the points look like:</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin \n\tbasis = get_poly_basis(2,2)\n\tcustom_points =  [ ones(Float32, 2), ones(Float32,2)] \n\t\n\t#lambda_points, lambda_basis, c_indices = get_lambda_poised_set( basis,custom_points)\n\tlambda_points, lambda_basis, c_indices = get_poised_set( basis,custom_points)\n\tc_indices\nend</code></pre>\n<pre id='var-lambda_points' class='pre-class'><code class='code-output'>6-element Vector{Int64}:\n  1\n -1\n -1\n -1\n -1\n -1</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>scatter(Tuple.(lambda_points))</code></pre>\n<img src=\"data:image/png;base64,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\">\n\n<!-- PlutoStaticHTML.End -->","category":"page"},{"location":"notebooks/notebook_finite_differences/","page":"Finite Differences","title":"Finite Differences","text":"<style>\n    table {\n        display: table !important;\n        margin: 2rem auto !important;\n        border-top: 2pt solid rgba(0,0,0,0.2);\n        border-bottom: 2pt solid rgba(0,0,0,0.2);\n    }\n\n    pre, div {\n        margin-top: 1.4rem !important;\n        margin-bottom: 1.4rem !important;\n    }\n</style>\n\n<!-- PlutoStaticHTML.Begin -->\n<!--\n    # This information is used for caching.\n    [PlutoStaticHTML.State]\n    input_sha = \"f31943618e6ab92ed28034eb7cac5ddb44d3a046b3ba415874adf44fc9520e22\"\n    julia_version = \"1.6.5\"\n-->\n\n<div class=\"markdown\"><h1>Finite Differences for Taylor Models.</h1>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tusing StaticArrays\n\tusing Symbolics\n\tusing Symbolics: Sym\n\tusing Parameters\n\tusing BenchmarkTools\nend</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tconst RVec = AbstractVector{&lt;:Real}\n\tconst RVecOrR = Union{Real, RVec}\nend</code></pre>\n<pre id='var-RVecOrR' class='pre-class'><code class='code-output'>Union{Real, AbstractVector{var\"#s285\"} where var\"#s285\"<:Real}</code></pre>\n\n\n<div class=\"markdown\"><h3>Abstract</h3>\n<p>For calculating finite difference gradients and hessians in Morbit we want to separate the grid construction from the function evaluation and derivative calculations. To my knowledge, this is not easily possible using <code>FiniteDiff</code> or <code>FiniteDifferences.jl</code>.</p>\n<p>This notebook explores a recursive calculation procedure starting from first order finite difference rules &#40;interfaced by <code>FiniteDiffStamp</code>&#41;. To calculate partial derivatives of <span class=\"tex\">$f:ℝ^n \\to ℝ^k$</span> at a fixed point <span class=\"tex\">$x_0 ∈ ℝ^n$</span> a <code>DiffWrapper</code> can be used.  It is initialized devoid of any function evaluation information but only has symbolic representations of required evaluation sites relative to <span class=\"tex\">$x_0$</span>. A <code>DiffWrapper</code> can hence be used to first construct a grid for <span class=\"tex\">$x_0$</span> and at a later stage to approximate gradients or Hessians.</p>\n</div>\n\n\n<div class=\"markdown\"><h2>Finite Difference Rules</h2>\n<p>A finite difference rule is defined by a grid of integer offsets, a decision space stepsize <span class=\"tex\">$h$</span>, and coefficients to combine evaluation results at the grid points.</p>\n<p>For details, please see <a href=\"https://en.wikipedia.org/wiki/Finite_difference_coefficient\">this Wikipedia page</a>.</p>\n<p>We abstract the basic information with the <code>FiniteDiffStamp</code> interface:</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tabstract type FiniteDiffStamp end\n\t\n\t# integer offsets to build a grid along some variable dimension\n\t_grid( :: FiniteDiffStamp ) = nothing\n\t# stepsize to build a grid along some variable dimension in decision space\n\t_stepsize( :: FiniteDiffStamp ) = nothing\n\n\t# coefficients of the rule\n\t_coeff( :: FiniteDiffStamp ) = nothing\n\t\n\t# order of the method \n\t_order( :: FiniteDiffStamp ) = nothing\n\t\n\t# accuracy (exponent of residual in Taylor expansion)\n\t_accuracy( :: FiniteDiffStamp ) = nothing\n\t\n\t# zero index of grid\n\t_zi( :: FiniteDiffStamp ) = nothing\n\t\n\tBase.broadcastable( fds :: FiniteDiffStamp ) = Ref(fds)\n\t\n\t# evaluation of rule at sites in `X` (a vector or an iterable)\n\tfunction (stamp :: FiniteDiffStamp)(X)\t\n\t\tcoeff = _coeff(stamp)\n\t\t@assert length(X) == length(coeff)\n\t\th = _stepsize(stamp)\n\t\treturn sum( c * x for (c,x) in zip(coeff,X) ) ./ h^(_order(stamp))\n\tend\nend</code></pre>\n\n\n\n<div class=\"markdown\"><p>We could already define a finite difference function using a <code>FiniteDiffStamp</code>:</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>\"Evaluate all outputs of `f` with respect to ``x_i``.\" \nfunction dx(stamp :: FiniteDiffStamp, f :: Function, x0 :: RVec, i = 1)\n\th = _stepsize(stamp)\n\tgrid = [ [x0[1:i-1];x0[i] + h*g; x0[i+1:end]] for g in _grid(stamp) ]\n\tevals = f.(grid)\n\treturn stamp( evals )\nend</code></pre>\n\n\n\n<div class=\"markdown\"><p>Of course, some concrete implementations are still missing.  We provide some entries from the table in <a href=\"https://en.wikipedia.org/wiki/Finite_difference_coefficient\">Wikipedia</a>.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tstepsize( x :: F ) where F &lt;: AbstractFloat = 10 * sqrt(eps(F))\n\tstepsize( F :: Type{&lt;:AbstractFloat} ) = 10 * sqrt(eps(F))\n\tstepsize( x :: AbstractVector{F} ) where F&lt;:AbstractFloat = stepsize(F)\n\tstepsize( x ) = stepsize(Float64)\nend</code></pre>\n<pre id='var-stepsize' class='pre-class'><code class='code-output'>stepsize (generic function with 4 methods)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tstruct CFDStamp{N, F &lt;: AbstractFloat} &lt;: FiniteDiffStamp\n\t\tgrid :: SVector{N,Int8}\n\t\tcoeff :: SVector{N,Rational{Int16}}\n\t\torder :: UInt8 \t\n\t\taccuracy :: UInt8\n\t\t\n\t\tstepsize :: F\n\t\t\n\t\tzero_index :: UInt8\n\tend\n\t\n\t_grid( stamp :: CFDStamp ) = stamp.grid\n\t_coeff( stamp :: CFDStamp ) = stamp.coeff \n\t_order( stamp :: CFDStamp ) = stamp.order\n\t_accuracy( stamp :: CFDStamp ) = stamp.accuracy\n\t_stepsize( stamp :: CFDStamp ) = stamp.stepsize\n\t_zi( stamp :: CFDStamp ) = stamp.zero_index\n\t\n\tfunction CFDStamp( order :: Int, accuracy :: Int, _stepsize_ = stepsize(Float64) ) \n\t\treturn CFDStamp( Val(order), Val( floor(Int, accuracy / 2) * 2 ), _stepsize_ )\n\tend\n\t\n\tfunction CFDStamp( ::Val{1}, ::Val{2}, _stepsize_ :: AbstractFloat )\n\t\tCFDStamp( \n\t\t\tSVector{3,Int8}([-1, 0, 1]), \n\t\t\tSVector{3,Rational{Int16}}([-1//2, 0, 1//2]),\n\t\t\tUInt8(1), UInt8(2), _stepsize_, UInt8(2),\n\t\t)\n\tend\n\t\n\tfunction CFDStamp( ::Val{1}, ::Val{4}, _stepsize_ :: AbstractFloat )\n\t\tCFDStamp( \n\t\t\tSVector{5,Int8}([-2,-1,0,1,2]), \n\t\t\tSVector{5,Rational{Int16}}([1//12, -2//3, 0, 2//3, -1//12]), \n\t\t\tUInt8(1), UInt8(4), _stepsize_, UInt8(3)\n\t\t)\n\tend\n\t\n\tfunction CFDStamp( ::Val{1}, ::Val{6}, _stepsize_ :: AbstractFloat )\n\t\tCFDStamp( \n\t\t\tSVector{7,Int8}(collect(-3:1:3)), \n\t\t\tSVector{7,Rational{Int16}}([-1//60, 3//20, -3//4, 0, 3//4, -3//20, 1//60]), \n\t\t\tUInt8(1), UInt8(6), _stepsize_, UInt8(4)\n\t\t)\n\tend\n\t\n\t\nend</code></pre>\n<pre id='var-_zi' class='pre-class'><code class='code-output'>CFDStamp</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tstruct FFDStamp{N, F &lt;: AbstractFloat} &lt;: FiniteDiffStamp\n\t\tgrid :: SVector{N,Int8}\n\t\tcoeff :: SVector{N,Rational{Int16}}\n\t\torder :: UInt8 \t\n\t\taccuracy :: UInt8\n\t\t\n\t\tstepsize :: F\n\tend\n\t\n\t_grid( stamp :: FFDStamp ) = stamp.grid\n\t_coeff( stamp :: FFDStamp ) = stamp.coeff \n\t_order( stamp :: FFDStamp ) = stamp.order\n\t_accuracy( stamp :: FFDStamp ) = stamp.accuracy\n\t_stepsize( stamp :: FFDStamp ) = stamp.stepsize\n\t_zi( stamp :: FFDStamp ) = 1\n\t\n\tfunction FFDStamp( order :: Int, accuracy :: Int, _stepsize_ = stepsize(Float64) ) \n\t\treturn FFDStamp( Val(order), Val( ceil(Int, accuracy / 2) ), _stepsize_ )\n\tend\n\t\n\tfunction FFDStamp( ::Val{1}, ::Val{1}, _stepsize_ :: AbstractFloat )\n\t\tFFDStamp( \n\t\t\tSVector{2,Int8}([0, 1]), \n\t\t\tSVector{2,Rational{Int16}}([-1, 1]),\n\t\t\tUInt8(1), UInt8(1), _stepsize_\n\t\t)\n\tend\n\t\n\tfunction FFDStamp( ::Val{1}, ::Val{2}, _stepsize_ :: AbstractFloat )\n\t\tFFDStamp( \n\t\t\tSVector{3,Int8}([0, 1, 2]), \n\t\t\tSVector{3,Rational{Int16}}([-3//2, 2, -1//2]),\n\t\t\tUInt8(1), UInt8(2), _stepsize_\n\t\t)\n\tend\n\t\n\tfunction FFDStamp( ::Val{1}, ::Val{3}, _stepsize_ :: AbstractFloat )\n\t\tFFDStamp( \n\t\t\tSVector{4,Int8}([0, 1, 2, 3]), \n\t\t\tSVector{4,Rational{Int16}}([-11/6, 3, -3//2, 1//3]),\n\t\t\tUInt8(1), UInt8(3), _stepsize_\n\t\t)\n\tend\n\t\nend</code></pre>\n<pre id='var-_zi' class='pre-class'><code class='code-output'>FFDStamp</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>begin \n\tstruct BFDStamp{N, F &lt;: AbstractFloat} &lt;: FiniteDiffStamp\n\t\tgrid :: SVector{N,Int8}\n\t\tcoeff :: SVector{N,Rational{Int16}}\n\t\torder :: UInt8 \t\n\t\taccuracy :: UInt8\n\t\t\n\t\tstepsize :: F\n\tend\n\t\n\t_grid( stamp :: BFDStamp ) = stamp.grid\n\t_coeff( stamp :: BFDStamp ) = stamp.coeff \n\t_order( stamp :: BFDStamp ) = stamp.order\n\t_accuracy( stamp :: BFDStamp ) = stamp.accuracy\n\t_stepsize( stamp :: BFDStamp ) = stamp.stepsize\n\t_zi( stamp :: BFDStamp ) = 1\n\t\n\tfunction BFDStamp( order :: Int, accuracy :: Int, _stepsize_ = stepsize(Float64) ) \n\t\tffd_stamp = FFDStamp( Val(order), Val( ceil(Int, accuracy / 2) ), _stepsize_ )\n\t\tif isodd(order)\n\t\t\treturn BFDStamp(\n\t\t\t\t- _grid( ffd_stamp ),\n\t\t\t\t- _coeff( ffd_stamp ),\n\t\t\t\t_order(ffd_stamp), _accuracy(ffd_stamp), _stepsize(ffd_stamp)\n\t\t\t)\n\t\telse\n\t\t\treturn  BFDStamp(\n\t\t\t\t_grid( ffd_stamp ), _coeff( ffd_stamp ),\n\t\t\t\t_order(ffd_stamp), _accuaracy(ffd_stamp), _stepsize(ffd_stamp)\n\t\t\t)\n\t\tend\n\tend\n\nend</code></pre>\n<pre id='var-_zi' class='pre-class'><code class='code-output'>BFDStamp</code></pre>\n\n\n<div class=\"markdown\"><p>Does it work?</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tcfd = CFDStamp(1,2)\n\tFunc = x -&gt; x[1]*x[2]^2\n\t\n\t# ∂₁Func = x[2]^2\n\t# ∂₂Func = x[1]\n\tdx( cfd, Func, [1,2], 1)\nend</code></pre>\n<pre id='var-Func' class='pre-class'><code class='code-output'>4.0</code></pre>\n\n\n<div class=\"markdown\"><h2>Tree structure</h2>\n</div>\n\n\n<div class=\"markdown\"><p>Our goal is to recursively approximate high order derivatives of a function <span class=\"tex\">$f\\colon ℝ^n \\to ℝ^k$</span> using a first order finite difference formula <span class=\"tex\">$G_f$</span>. We assume, that <span class=\"tex\">$G_f$</span> requires <span class=\"tex\">$m$</span> values of derivative order <span class=\"tex\">$i-1$</span> to approximate the partial derivative of order <span class=\"tex\">$i$</span>. </p>\n<p>For simplicity, first consider <span class=\"tex\">$k&#61;1$</span> &#40;the single output case&#41;.</p>\n<ul>\n<li><p>For forming <span class=\"tex\">$∂_1 f&#40;x_0&#41;$</span> we would need values <span class=\"tex\">$f&#40;ξ_1^1&#41;, …, f&#40;ξ_m^1&#41;$</span>, where <span class=\"tex\">$ξ^1$</span> varies along the first coordinate and results from applying <span class=\"tex\">$G_f$</span> to <span class=\"tex\">$x_0$</span>.</p>\n</li>\n<li><p>For forming <span class=\"tex\">$∂_1 ∂_1 f&#40;x_0&#41;$</span> we would instead need values approximating <span class=\"tex\">$∂_1 f&#40;ξ_1^1&#41;,…, ∂_1 f&#40;ξ_m^1&#41;$</span>.  Using the same rule to approximate the first order partial derivatives requires function evaluations at sites <span class=\"tex\">$ξ_&#123;1,1&#125;^1, …, ξ_&#123;1,m&#125;^1, ξ_&#123;2,1&#125;^1, …, ξ_&#123;m,m&#125;^1$</span> resulting from applying <span class=\"tex\">$G_f$</span> to each of <span class=\"tex\">$ξ_i^1$</span>.</p>\n</li>\n</ul>\n<p>This process can be recursed infinitely.  To actually compute the desired derivative approximation we would first have to construct the evaluation sites <span class=\"tex\">$ξ_I^J$</span>.  We can think of a tree-like structure, with a root node containing <span class=\"tex\">$x_0$</span> where we add – for each derivative order – child nodes by applying <span class=\"tex\">$G_f$</span> to the previous leaves. <br />The tree is hence build from top to bottom but for evaluation we start at the leaves and resolve the lowest order derivative approximations first.  In a sense, this is a dynamic programming approach.</p>\n</div>\n\n\n<div class=\"markdown\"><p>Our tree is made out of <code>FDiffNode</code>s.   An <code>FDiffNode</code> has a field <code>x_sym</code> storing the symbolic representation of some point relative to <span class=\"tex\">$x_0$</span> that we need a value for. <br />If <code>N :: FDiffNode&#123;T,X,C&#125;</code> is a leave node, then <code>T</code> should be a mutable vector type and <code>vals :: T</code> is meant to store the result of <span class=\"tex\">$f$</span> evaluated at <span class=\"tex\">$x$</span>, where <span class=\"tex\">$x$</span> results from substituting <span class=\"tex\">$x_0$</span> and a stepsize <span class=\"tex\">$h$</span> into <code>x_sym</code>. <br />If <code>N</code> is <em>not</em> a leave node, then <code>T</code> should be a vector type to store <span class=\"tex\">$n$</span> vectors of <code>FDiffNode</code>s and each of those vectors should have <span class=\"tex\">$m$</span> elements, so that it can be used to recursively approximate a derivative.</p>\n<p>Note, that the variables <code>x_vars::Vector&#123;Symbolics.Num&#125;</code> and the finite difference rule are stored outside of the tree to keep it as simple as possible.</p>\n<p>We also allow to use a cache of type <span class=\"tex\">$C$</span> which should be Dict-Like &#40;if not <code>nothing</code>&#41;.  It can be used in the <code>val</code> method to retrieve values that have already been calculated before.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>@with_kw struct FDiffNode{T,X,C} &lt;: Trees.Node\n\tx_sym :: Vector{Symbolics.Num} = []\n\tx :: X = Float64[]\n\tvals :: T = nothing\n\tcache :: C = nothing\nend</code></pre>\n<pre id='var-@pack_FDiffNode' class='pre-class'><code class='code-output'>FDiffNode</code></pre>\n\n\n<div class=\"markdown\"><p>We inherit from <code>Trees.Node</code> and define a <code>children</code> method&#96; so that some nice iterators are available.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tTrees.children( n :: FDiffNode{&lt;:RVec} ) = nothing\n\tTrees.children( n :: FDiffNode ) = Iterators.flatten( n.vals )\nend</code></pre>\n\n\n\n<div class=\"markdown\"><p>For leave nodes &#40;indicated by <code>T</code> being a real vector type&#41;, we simply retrieve the function values if they are present. Else, <code>NaN</code> is returned.  We have a helper function <code>missing</code> to get the right type of <code>NaN</code> and the important <code>val</code> retrieval function.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tmissing(T::Type{&lt;:AbstractFloat}) = T(NaN)\n\tmissing(T) = Float16(NaN)\nend</code></pre>\n<pre id='var-missing' class='pre-class'><code class='code-output'>missing (generic function with 2 methods)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function val( n :: FDiffNode{&lt;:AbstractVector{Y},X,C}, args...; output_index = 1) where {Y&lt;:Real,X,C}\n\tif isempty(n.vals) \n\t\treturn missing(Y)\n\telse \n\t\tn.vals[output_index]\n\tend\nend</code></pre>\n<pre id='var-val' class='pre-class'><code class='code-output'>val (generic function with 2 methods)</code></pre>\n\n\n<div class=\"markdown\"><p>Otherwise, we <em>recurse</em> and apply the finite difference rule <code>stamp</code> to compute the return values.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function val( subnode_list, indices, stamp, output_index )\n\tcoeff = _coeff( stamp )\n\th = _stepsize( stamp )\n\treturn stamp( val(sub_node, indices, stamp; output_index) for sub_node in subnode_list ) \nend</code></pre>\n<pre id='var-val' class='pre-class'><code class='code-output'>val (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function val( n :: FDiffNode{T,X,C}, indices, stamp; output_index = 1 ) where{T,X,C}\n\tcopied_indices = copy(indices)\n\ti = popfirst!( copied_indices )\n\t\n\tif C &lt;: Nothing\n\t\treturn val( n.vals[i], copied_indices, stamp, output_index )\n\tend\n\t\n\tcache_key = [ i; copied_indices; output_index ]\n\tif haskey( n.cache, cache_key ) \n\t\tret_val = n.cache[cache_key]\n\t\t!isnan(ret_val) && return ret_val\n\tend\n\t\n\tret_val = val( n.vals[i], copied_indices, stamp, output_index )\n\tn.cache[cache_key] = ret_val\n\treturn ret_val\nend</code></pre>\n<pre id='var-val' class='pre-class'><code class='code-output'>val (generic function with 3 methods)</code></pre>\n\n\n<div class=\"markdown\"><p>The tree is build recursively from the top down by calling the <code>build_tree</code> function with a decreasing <code>order</code> value.</p>\n<ul>\n<li><p>An <code>order</code> value of 0 indicates that we need need a leave node for <code>x_sym</code> and the correct value container is initialized &#40;and the cache deactivated&#41;.</p>\n</li>\n<li><p>For a higher <code>order</code> value, we collect the <span class=\"tex\">$n$</span> vectors of <span class=\"tex\">$m$</span> sub nodes by calling <code>buid_tree</code> again.</p>\n</li>\n</ul>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function build_tree( x_sym, stamp, vars, order = 1; x_type = Vector{Float64}, val_type = Vector{Float64}, cache_type = Nothing )\n\tif order &lt;= 0\n\t\t# return a leave node\n\t\treturn FDiffNode(; x_sym, x = x_type(), vals = val_type(), cache = nothing )\n\telse\n\t\t# collect ``n`` subnode vectors of length ``m``\n\t\tgrid = _grid( stamp )\t# ``m`` grid points to define the points for sub_nodes\n\t\tm = length( grid )\n\t\tn = length( x_sym )\n\t\th = vars[2]\n\t\t#sub_nodes = SizedVector{n, SizedVector{m, FDiffNode}}(undef)\n\t\tsub_nodes = SizedVector{n, SizedVector{m, FDiffNode}}(undef)\n\t\tfor i = 1 : n\n\t\t\tsub_nodes[i] = [ \n\t\t\t\tbuild_tree( \n\t\t\t\t\t# vary `x_sym` along variable `i`\n\t\t\t\t\t[x_sym[1:i-1]; x_sym[i] + h * g; x_sym[i+1:n]], \n\t\t\t\t\tstamp, vars, order - 1; x_type, val_type, cache_type ) \n\t\t\t\tfor g in grid \n\t\t\t]\n\t\tend\n\t\treturn FDiffNode(; x_sym, x = x_type(), vals = sub_nodes, cache = cache_type() )\n\tend\nend</code></pre>\n<pre id='var-build_tree' class='pre-class'><code class='code-output'>build_tree (generic function with 2 methods)</code></pre>\n\n\n<div class=\"markdown\"><p><code>build_tree</code> is called in default the <code>DiffWrapper</code> constructor to store the <code>tree</code> &#40;out of <code>FDiffNode</code>s&#41; for the derivative <code>order</code> stored within the container.  A <code>DiffWrapper</code> also stores the base point <code>x0</code> and the finite difference rule <code>stamp</code>.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\t\"Helper function to get Symbolic variables for `x_1,…,x_n` and the stepsize `h`.\" \n\tfunction _get_vars(n :: Int)\n\t\treturn Tuple(Num.(Variable.(:x, 1:n))), Num(Variable(:h))\n\tend\n\t\n\t_get_vars( x :: AbstractVector ) = _get_vars(length(x))\nend</code></pre>\n<pre id='var-_get_vars' class='pre-class'><code class='code-output'>_get_vars (generic function with 2 methods)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tvec_typex( x :: AbstractVector{Y}, stamp ) where Y = Vector{ Base.promote_op( +, Y, typeof(_stepsize(stamp))) }\n\tvec_typef( fx :: AbstractVector{Y}, stamp ) where Y = Vector{ Base.promote_op( *, Y, typeof(_coeff(stamp)[1])) }\nend</code></pre>\n<pre id='var-vec_typef' class='pre-class'><code class='code-output'>vec_typef (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>@with_kw struct DiffWrapper{X &lt;: RVec,Y &lt;: RVec,N,S,T,C}\n\tx0 :: X\n\tfx0 :: Y\n\t#vars :: Tuple{Tuple{N,Symbolics.Num}, Symbolics.Num} = _get_vars( x0 )\n\tvars :: N = _get_vars(x0)\n\tx0_sym :: Vector{Symbolics.Num} = [vars[1]...]\n\tstamp :: S = CFDStamp(1,2, stepsize(x0))\n\torder :: Int = 1\n\t\t\n\tcache_type :: C = Dict{Vector{UInt8}, eltype(vec_typef(fx0, stamp))} \n\ttree :: T = build_tree( x0_sym, stamp, vars, order; x_type = vec_typex(x0,stamp), val_type = vec_typef(fx0, stamp), cache_type = cache_type )\nend</code></pre>\n<pre id='var-@pack_DiffWrapper' class='pre-class'><code class='code-output'>DiffWrapper</code></pre>\n\n\n<div class=\"markdown\"><div class=\"admonition note\"><p class=\"admonition-title\">Note</p><p>A <code>DiffWrapper</code> should be initialized with the right &#40;floating point&#41; vector types for <code>x0</code> and <code>fx0</code>. If <code>fx0</code> is not known, but the precision, use something like <code>fx0 &#61; Float32&#91;&#93;</code>.</p>\n</div>\n</div>\n\n\n<div class=\"markdown\"><p>We exploit the meta data stored to forward the <code>val</code> method. <code>indices</code> should be an array of <code>Int</code>s of length <code>dw.order</code>, indicating the partial derivatives we want. Suppose, <code>dw.order &#61;&#61; 2</code>, then <code>val&#40; dw, &#91;1,2&#93; &#41;</code> will give <span class=\"tex\">$∂_1∂_2f_1&#40;x_0&#41;$</span>.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>val( dw :: DiffWrapper, indices; output_index = 1 ) = val( dw.tree, indices, dw.stamp ; output_index)</code></pre>\n<pre id='var-val' class='pre-class'><code class='code-output'>val (generic function with 4 methods)</code></pre>\n\n\n<div class=\"markdown\"><div class=\"admonition note\"><p class=\"admonition-title\">Note</p><p>The <code>tree</code> of a <code>DiffWrapper</code> needs to be initialized befor calling any derivative method.   That means, the <code>x</code> and <code>vals</code> fields have to be set for each leave node. This can be done in one go, by calling <code>prepare_tree&#33;&#40; dw, f &#41;</code>, or sequentially by calling first <code>substitute_leaves&#33;&#40;dw&#41;</code> and and <code>set_leave_values&#40;dw,f&#41;</code>.</p>\n</div>\n</div>\n\n\n<div class=\"markdown\"><p>From this, it is easy to define convenience functions for hessians and gradients. For second order <code>DiffWrapper</code>s we can also make use of the fact, that each derivative rule has a grid point with index <code>zi</code> where <span class=\"tex\">$x_0$</span> is not varied. That means, we can collect the gradient from the leaves with the parent node of index <code>zi</code> &#40;relative to the root&#41;.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function gradient( dw :: DiffWrapper; output_index = 1 )\n\t@assert 1 &lt;= dw.order &lt;= 2 \"Gradient retrieval only implemented for DiffWrapper of order 1 and 2.\"\n\treturn gradient( dw :: DiffWrapper, Val(dw.order); output_index )\nend</code></pre>\n<pre id='var-gradient' class='pre-class'><code class='code-output'>gradient (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function gradient( dw :: DiffWrapper, ::Val{1}; output_index = 1 )\n\tn = length( dw.x0 )\n\tg = Vector{eltype(dw.fx0)}(undef, n)\n\tfor i = 1 : n\n\t\tg[i] = val( dw, [i,]; output_index )\n\tend\n\treturn g\nend</code></pre>\n<pre id='var-gradient' class='pre-class'><code class='code-output'>gradient (generic function with 2 methods)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function gradient( dw :: DiffWrapper, ::Val{2}; output_index = 2 )\n\tn = length( dw.x0 )\n\tg = Vector{eltype(dw.fx0)}(undef, n)\n\tzi = _zi( dw.stamp )\t# index of stamp grid point is zero\n\tnode = dw.tree.vals[1][zi]\n\tfor i = 1 : n\n\t\tg[i] = val( node, [i,], dw.stamp; output_index )\t\t\n\tend\n\treturn g\nend</code></pre>\n<pre id='var-gradient' class='pre-class'><code class='code-output'>gradient (generic function with 3 methods)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function jacobian( dw :: DiffWrapper )\n\t@assert 1 &lt;= dw.order &lt;= 2 \"Gradient retrieval only implemented for DiffWrapper of order 1 and 2.\"\n\tk = isempty( dw.fx0 ) ? length(first(Trees.Leaves(dw.tree)).vals) : length(dw.fx0)\n\treturn transpose( hcat( collect(gradient(dw; output_index = m) for m = 1 : k )...) )\nend</code></pre>\n<pre id='var-jacobian' class='pre-class'><code class='code-output'>jacobian (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function hessian( dw :: DiffWrapper; output_index = 1)\n\t@assert dw.order == 2 \"Hessian only implemented for DiffWrapper of 2.\"\n\tn = length(dw.x0)\n\tH = Matrix{eltype(dw.fx0)}(undef, n, n)\t\n\t# TODO make sure that dw.fx0 == vec_typef(fx0, stamp)\n\tfor i = 1 : n\n\t\tfor j = 1 : n\n\t\t\tH[i,j] = val( dw, [i, j]; output_index ) \n\t\tend\n\tend\n\treturn H\nend</code></pre>\n<pre id='var-hessian' class='pre-class'><code class='code-output'>hessian (generic function with 1 method)</code></pre>\n\n\n<div class=\"markdown\"><p>Does it work?</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\t# I used this cell for fiddling around.\n\t\n\tf = x -&gt; [ 2 * x[1]^2 + x[2]^3; sum( x ) ]\n\t# ∂1 f1 = 4 * x[1] \n\t# ∂2 f1 = 3 * x[2]^2\n\t\n\t#H1 = [\n\t#\t4.0 0.0\n\t#\t0.0 6x[2]\n\t# ]\n\t\n\tdw = DiffWrapper(; x0 = [1.0; 1.0], fx0 = rand(2) , stamp = BFDStamp(1,3,1e-3), order = 2)\n\t# to deactivate caching: `cache_type = Nothing`\n\t\t\n\tprepare_tree!(dw,f)\n\t# this would require 2 tree traversals:\n\t# substitute_leaves!(dw)\t\n\t# set_leave_values!(dw,f)\n\t\n\tH = hessian(dw)\n\tH, sum( ([ 4 0; 0 6 ] .- H).^2 )\nend</code></pre>\n<pre id='var-f' class='pre-class'><code class='code-output'>([4.000000002557513 8.881784197001252e-10; -1.1102230246251565e-9 5.999999997285954], 1.592837543398526e-17)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>jacobian(dw)</code></pre>\n<pre id='var-hash106719' class='pre-class'><code class='code-output'>2×2 transpose(::Matrix{Float64}) with eltype Float64:\n 4.0  3.0\n 1.0  1.0</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>first(Trees.Leaves(dw.tree))</code></pre>\n<pre id='var-hash165135' class='pre-class'><code class='code-output'>FDiffNode{Vector{Float64}, Vector{Float64}, Nothing}\n  x_sym: Array{Num}((2,)) Symbolics.Num[x₁, x₂]\n  x: Array{Float64}((2,)) [1.0, 1.0]\n  vals: Array{Float64}((2,)) [3.0, 2.0]\n  cache: Nothing nothing\n</code></pre>\n\n\n<div class=\"markdown\"><h4>Helpers for filling the Tree</h4>\n<p>I won&#39;t go into detail concering these helper functions. They mostly leverage the <code>Trees.Leaves</code> iterator and should be comprehensible by themselves.</p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function _substitute_symbols!( node :: FDiffNode, x0, h, vars )\n\tx_vars, h_var = vars\n\tempty!(node.x)\n\tappend!(node.x, Symbolics.value.(substitute.(node.x_sym, (\n\t\tDict((x_vars[i] =&gt; x0[i] for i = eachindex(x0))..., \n\t\t\t\t\th_var=&gt;h),\n\t))))\nend</code></pre>\n<pre id='var-_substitute_symbols!' class='pre-class'><code class='code-output'>_substitute_symbols! (generic function with 2 methods)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function _substitute_symbols!(root_iterator, x0, h, vars)\n\tfor node in root_iterator\n\t\t_substitute_symbols!(node, x0, h, vars)\n\tend\nend</code></pre>\n<pre id='var-_substitute_symbols!' class='pre-class'><code class='code-output'>_substitute_symbols! (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function substitute_symbols!(root :: FDiffNode, x0, h, vars )\n\t_substitute_symbols!( Trees.PreOrderDFS( root ), x0, h, vars )\nend</code></pre>\n<pre id='var-substitute_symbols!' class='pre-class'><code class='code-output'>substitute_symbols! (generic function with 2 methods)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function substitute_leaves!(root :: FDiffNode, x0, h, vars )\n\t_substitute_symbols!( Trees.Leaves(root), x0, h, vars )\nend</code></pre>\n<pre id='var-substitute_leaves!' class='pre-class'><code class='code-output'>substitute_leaves! (generic function with 2 methods)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function substitute_symbols!(dw :: DiffWrapper)\n\tsubstitute_symbols!( dw.tree, dw.x0, _stepsize( dw.stamp ), dw.vars )\nend</code></pre>\n<pre id='var-substitute_symbols!' class='pre-class'><code class='code-output'>substitute_symbols! (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function substitute_leaves!(dw :: DiffWrapper)\n\tsubstitute_leaves!( dw.tree, dw.x0, _stepsize( dw.stamp ), dw.vars )\nend</code></pre>\n<pre id='var-substitute_leaves!' class='pre-class'><code class='code-output'>substitute_leaves! (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function collect_leave_sites( dw :: DiffWrapper )\n\treturn [ node.x for node in Trees.Leaves( dw.tree ) ]\nend</code></pre>\n<pre id='var-collect_leave_sites' class='pre-class'><code class='code-output'>collect_leave_sites (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function _set_node_values!( node, f :: Function )\n\tempty!(node.vals)\n\tappend!(node.vals, f( node.x ))\nend</code></pre>\n<pre id='var-_set_node_values!' class='pre-class'><code class='code-output'>_set_node_values! (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function set_leave_values!(dw :: DiffWrapper, f :: Function )\n\tfor node in Trees.Leaves(dw.tree)\n\t\t_set_node_values!(node, f)\n\tend\nend</code></pre>\n<pre id='var-set_leave_values!' class='pre-class'><code class='code-output'>set_leave_values! (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>function set_leave_values!(dw :: DiffWrapper, leave_vals :: AbstractVector )\n\tfor (i,node) in enumerate(Trees.Leaves(dw.tree))\n\t\tempty!(node.vals)\n\t\tappend!(node.vals, leave_vals[i] )\n\tend\nend</code></pre>\n<pre id='var-set_leave_values!' class='pre-class'><code class='code-output'>set_leave_values! (generic function with 2 methods)</code></pre>\n\n\n<div class=\"markdown\"><div class=\"admonition note\"><p class=\"admonition-title\">Note</p><p>The <code>set_leave_values&#33;</code> methods should also reset the cache. Not implemented in this notebook.</p>\n</div>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function prepare_tree!( dw :: DiffWrapper, f :: Function )\n\tx0 = dw.x0\n\tvars = dw.vars\n\th = _stepsize( dw.stamp )\n\t\n\tfor node in Trees.Leaves( dw.tree )\n\t\t_substitute_symbols!(node, x0, h, vars)\n\t\t_set_node_values!( node, f )\n\tend\nend</code></pre>\n<pre id='var-prepare_tree!' class='pre-class'><code class='code-output'>prepare_tree! (generic function with 1 method)</code></pre>\n\n\n<div class=\"markdown\"><h3>Morbit Example</h3>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function unique_with_indices( x :: AbstractVector{T} ) where T\n\tunique_elems = T[]\n\tindices = Int[]\n\tfor elem in x\n\t\ti = findfirst( e -&gt; all( isequal.(e,elem) ), unique_elems )\n\t\tif isnothing(i)\n\t\t\tpush!(unique_elems, elem)\n\t\t\tpush!(indices, length(unique_elems) )\n\t\telse\n\t\t\tpush!(indices, i)\n\t\tend\n\tend\n\treturn unique_elems, indices\nend</code></pre>\n<pre id='var-unique_with_indices' class='pre-class'><code class='code-output'>unique_with_indices (generic function with 1 method)</code></pre>\n\n<pre class='language-julia'><code class='language-julia'>begin\n\tfunc = x -&gt; [ sum(x.^2); exp( sum( x ) ) ]\n\tx_t = ones(Float32, 3)\n\tfx_t = func( x_t )\n\tdiff_wrapper = DiffWrapper(; x0 = x_t, fx0 = fx_t, stamp = CFDStamp(1,2,stepsize(fx_t)), order = 2 )\n\t\n\t#prepare_tree!(diff_wrapper, func)\n\t\n\t# phase I: get sites\n\tsubstitute_leaves!( diff_wrapper )\n\tall_sites = collect_leave_sites( diff_wrapper )\n\t\n\t# phase II: evaluation\n\n\t## find unique sites to avoid costly objective evaluations\n\tunique_sites, set_indices = unique_with_indices( [[x_t,]; all_sites] )\n\t## now unique_sites[set_indices] == [[x_t,]; all_sites]\n\t\n\t@assert unique_sites[set_indices][2:end] == all_sites\n\t\n\t## and x_t will be the first site in unique sites\n\t\n\t## call `func` on new sites\n\tunique_evals = [ [fx_t,]; func.( unique_sites[ 2 : end ] )]\n\tall_evals = unique_evals[set_indices[2:end]]\n\t\n\t# phase III: set the leave values and get jacobian\n\tset_leave_values!(diff_wrapper, all_evals)\n\t\n\thessian(diff_wrapper; output_index = 1), jacobian(diff_wrapper)\nend</code></pre>\n<pre id='var-diff_wrapper' class='pre-class'><code class='code-output'>(Float32[1.9999936 0.0 0.0; 0.0 1.9999936 0.0; 0.0 0.0 1.9999936], Float32[1.9999936 1.9999936 1.9999936; 20.086252 20.086252 20.086252])</code></pre>\n\n\n<div class=\"markdown\"><hr />\n</div>\n\n<pre class='language-julia'><code class='language-julia'>Trees = ingredients( joinpath(@__DIR__, \"Trees.jl\") ).Trees</code></pre>\n<pre id='var-Trees' class='pre-class'><code class='code-output'>Main.Trees.jl.Trees</code></pre>\n\n\n<div class=\"markdown\"><p><code>ingredients</code> thanks to <a href=\"https://github.com/fonsp/Pluto.jl/issues/115\">fonsp</a></p>\n</div>\n\n<pre class='language-julia'><code class='language-julia'>function ingredients(path::String)\n\t# this is from the Julia source code (evalfile in base/loading.jl)\n\t# but with the modification that it returns the module instead of the last object\n\tname = Symbol(basename(path))\n\tm = Module(name)\n\tCore.eval(m,\n        Expr(:toplevel,\n             :(eval(x) = $(Expr(:core, :eval))($name, x)),\n             :(include(x) = $(Expr(:top, :include))($name, x)),\n             :(include(mapexpr::Function, x) = $(Expr(:top, :include))(mapexpr, $name, x)),\n             :(include($path))))\n\tm\nend</code></pre>\n<pre id='var-ingredients' class='pre-class'><code class='code-output'>ingredients (generic function with 1 method)</code></pre>\n\n<!-- PlutoStaticHTML.End -->","category":"page"},{"location":"dev_man/#Developer-Manual","page":"DocStrings","title":"Developer Manual","text":"","category":"section"},{"location":"dev_man/","page":"DocStrings","title":"DocStrings","text":"This page is a big TODO!","category":"page"},{"location":"dev_man/","page":"DocStrings","title":"DocStrings","text":"For now, there are only the doc-strings:","category":"page"},{"location":"dev_man/","page":"DocStrings","title":"DocStrings","text":"Modules = [Morbit]","category":"page"},{"location":"dev_man/#Morbit.AbstractConfig","page":"DocStrings","title":"Morbit.AbstractConfig","text":"Abstract super type for user configurable algorithm configuration.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.AbstractDB","page":"DocStrings","title":"Morbit.AbstractDB","text":"Abstract database super type. Implemented by ArrayDB and MockDB.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.AbstractDescentConfig","page":"DocStrings","title":"Morbit.AbstractDescentConfig","text":"Abstract super type for descent step configuration.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.AbstractIterSaveable","page":"DocStrings","title":"Morbit.AbstractIterSaveable","text":"Abstract super type for some saveable iteration information.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.AbstractIterate","page":"DocStrings","title":"Morbit.AbstractIterate","text":"Abstract super type for a container that stores the site and value vectors.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.AbstractMOP","page":"DocStrings","title":"Morbit.AbstractMOP","text":"AbstractMOP{T}\n\nAbstract super type for multi-objective optimization problems. T is true if the problem is modifyable and `false elsewise.\n\nThe user should define a MOP<:AbstractMOP{true}, see MOP.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.AbstractSurrogate","page":"DocStrings","title":"Morbit.AbstractSurrogate","text":"Abstract super type for the actual surrogate models.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.AbstractSurrogateConfig","page":"DocStrings","title":"Morbit.AbstractSurrogateConfig","text":"Abstract super type for a configuration type defining some surrogate model.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.AbstractSurrogateMeta","page":"DocStrings","title":"Morbit.AbstractSurrogateMeta","text":"Abstract super type for meta data that is used to build a model.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.AbstractVecFun","page":"DocStrings","title":"Morbit.AbstractVecFun","text":"Abstract super type for any kind of (vector) objective.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.CompositeVecFun","page":"DocStrings","title":"Morbit.CompositeVecFun","text":"CompositeVecFun(; inner_ref, outer_ref,\n    inner_nl_index = nothing, outer_nl_index = nothing,\n    num_outputs = num_outputs( outer_ref ) \n)\n\nA CompositeVecFun is a special AbstractVecFun to use for  functions fℝⁿℝᵏ f = φ  g, where gℝⁿ  ℝᵐ is  an expensive function (that is possibly used elsewhere too)  and φℝᵐℝᵏ is an outer function. Hence, when evaluating a CompositeVecFun, the value of the function  referenced by inner_ref is plugged into outer_ref. When evaluating the overall jacobian at x, the chain rule  provides\n\nbeginaligned\nℝ^kn ni Df(x) = Dφ(g(x))Dg(x) quad Dφ  ℝ^km Dg  ℝ^mn\nf_ℓ(x) = (Dφ(g(x))Dg(x))_ℓ^T = (φ_ℓ(g(x))^T Dg(x))^T = Dg(x)^T φ_ℓ(g(x))\n\nFor the Hessian of output f_ℓ it holds that \n\nHf_ℓ(x) = D(f_ℓ(x))\n= \nD(Dφ_ℓ(g(x)) cdot Dg(x))\n= (Hφ_ℓ(g(x))  Dg(x))cdot Dg(x) + Dφ_ℓ(g(x)) cdot Hg(x)\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.ExactConfig","page":"DocStrings","title":"Morbit.ExactConfig","text":"ExactConfig(; gradients, jacobian = nothing, max_evals = typemax(Int64))\n\nConfiguration for an ExactModel. gradients should be a vector of callbacks for the objective gradients or  a Symbol, either :autodiff or fdm, to define the differentiation method  to use on the objective. Alternatively, a jacobian handle can be provided.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.ExactModel","page":"DocStrings","title":"Morbit.ExactModel","text":"ExactModel( index, mop )\n\nExact Model type for evaluating the objective function objf directly. Is instantiated by the corresponding init_model and update_model functions.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.ExprSurrogate","page":"DocStrings","title":"Morbit.ExprSurrogate","text":"ExprSurrogate( model_ref, generated_function, output_indices)\n\nSimilar to RefSurrogate, ExprSurrogate holds a reference model_ref  to some other surrogate. But instead of evaluating this inner model directly, the function generated_function is used for evaluation and differentiation.\n\nRefSurrogate\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.ExprSurrogate-Tuple{Morbit.AbstractSurrogate, String, Any, Any, Any}","page":"DocStrings","title":"Morbit.ExprSurrogate","text":"ExprSurrogate( model, expr_str, scal, output_indices)\n\nInitialize an ExprSurrogate from model (and scal :: AbstractVarScaler)  by turning expr_str into a function, where each occurence of VRFE(x) is  replaced by a call to model and extracting the values at positions output_indices.\n\nstr2func\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.ExprVecFun","page":"DocStrings","title":"Morbit.ExprVecFun","text":"ExprVecFun(inner_ref, generated_function, num_outputs, nl_index = nothing)\n\nLike RefVecFun, an ExprVecFun object stores a reference to a VecFun. But this reference is only used for retrieval of basic information.  For evaluation, we have a generated_function.\n\nRefVecFun, VecFun, str2func\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.ExprVecFun-2","page":"DocStrings","title":"Morbit.ExprVecFun","text":"ExprVecFun( vf :: AbstractVecFun, expr_str :: String,\n    n_out :: Int, nl_index = nothing )\n\nInitialize an ExprVecFun object from another vector function. An evaluation function is created from expr_str by replacing each occurence  of \"VREF(x)\" to a call to vf.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.LagrangeConfig","page":"DocStrings","title":"Morbit.LagrangeConfig","text":"LagrangeConfig(; kwargs... )\n\nConfiguration for Lagrange Polyoniaml models.\n\ndegree\nDegree of the surrogate model polynomials. Default: 2\nθ_enlarge\nEnlargement parameter to consider more points for inclusion. Default: 2.0\nLAMBDA\nQuality parameter in Λ-Poisedness Algorithm. Default: 1.5\nallow_not_linear\nWhether or not the interpolation sets must be Λ-poised (and the models fully linear). Default: false\noptimized_sampling\nWhether or not to try to construct a new interpolation set in each iteration. Default: true\nsave_path\nPath to look at for a pre-saved poised set of interpolation points in [0,1]^n. Default:\nio_lock\nLock to use parallel setups if multiple models can access save_path. Default: nothing\nalgo1_max_evals\nMaximum number of polynomial evaluations to find a poised set. Default: -1\nalgo2_max_evals\nMaximum number of polynomial evaluations to make a set Λ-poised. Default: -1\nalgo1_solver\nNLopt Solver to use for the poisedness problem. Default: :LN_BOBYQA\nalgo2_solver\nNLopt Solver to use for the Λ-poisedness problem. Default: :LN_BOBYQA\nmax_evals\nMaximum number of evaluations allowed to the true objective(s). Default: typemax(Int64)\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.RbfConfig","page":"DocStrings","title":"Morbit.RbfConfig","text":"RbfConfig(; kwarg1 = val1, … )\n\nConfiguration type for local RBF surrogate models.\n\nkernel\nRBF kernel (Symbol), either :cubic, :inv_multiquadric, :multiquadric, :exp or :thin_plate_spline. Default: :inv_multiquadric\nshape_parameter\nRBF shape paremeter, either a number or a string containing Δ. Default: NaN\npolynomial_degree\nDegree of polynomial attached to RBF. -1 means no polynomial. Default: 1\nθ_enlarge_1\nLocal enlargment factor of trust region for sampling. Default: 2\nθ_enlarge_2\nMaximum enlargment factor of maximum trust region for sampling. Default: 2\nθ_pivot\nSampling parameter to generate Λ-poised set. The higher, the more poised. Default: 1 / (2θenlarge1)\nθ_pivot_cholesky\nParameter for 2nd sampling algorithm to ensure boundedness of Cholesky factors. Default: 1.0e-7\nrequire_linear\nRequire models to be fully linear in each iteration. Default: false\nmax_model_points\nMaximum number of training sites. -1 is reset to 2n+1. Default: -1\nuse_max_points\nSample new sites to always use the maximum number of points. Default: false\noptimized_sampling\nWhether or not to re-construct the training set in each iteration. Default: true\nmax_evals\nMaximum number of objective evaluations. Default: typemax(Int64)\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.RefSurrogate","page":"DocStrings","title":"Morbit.RefSurrogate","text":"RefSurrogate(model_ref, output_indices)\n\nA RefSurrogate holds a reference model_ref to some AbstractSurrogate object and delegates most of the evaluation to this inner model. RefSurrogates are meant to model a single (vector-valued) objective or  constraint function.  As an AbstractSurrogate might model more than one objetive or constraint, we have a field output_indices for filtering out the right output indices  from the inner model output.\n\nRefVecFun\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.RefVecFun","page":"DocStrings","title":"Morbit.RefVecFun","text":"RefVecFun( inner_ref, nl_index = nothing )\n\nA RefVecFun simply stores a reference to a VecFun object. Evaluation methods are delegated to this object. nl_index is an optional information field used by MOP.\n\nVecFun, MOP\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.SuperDB","page":"DocStrings","title":"Morbit.SuperDB","text":"SuperDB{T,Vector{<IterSaveable}}\n\nA SuperDB is nothing but a directory of sub-databases (sub_dbs) that store evaluation data for tuples of AnyIndex functions. There is also a field iter_data that stores iteration data in a vector  for later inspection.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.TaylorCallbackConfig","page":"DocStrings","title":"Morbit.TaylorCallbackConfig","text":"TaylorCallbackConfig(;degree=1,max_evals=typemax(Int64))\n\nConfiguration for a linear or quadratic Taylor model where there are callbacks provided for the  gradients and – if applicable – the Hessians.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.TaylorConfig","page":"DocStrings","title":"Morbit.TaylorConfig","text":"TaylorConfig(; degree, gradients :: RFD.CFDStamp, hessians :: RFD.CFDStamp, max_evals)\n\nConfiguration for a polynomial Taylor model using finite difference approximations of the derivatives. By default we have degree = 2 and gradients == hessians == RFD.CFDStamp(1,2), that is,  a first order central difference scheme of accuracy order 3 is recursed to compute the Hessians  and the gradients. In this case, the finite difference scheme is the same for both Hessians and gradients and we profit  from caching intermediate results.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.VecFun","page":"DocStrings","title":"Morbit.VecFun","text":"VecFun(; n_out, model_config, func_handle, diff_wrapper = nothing)\n\nWrap the function func_handle to ensure vector output. A VecFun also provides a unified differentiation API.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Base.length-Tuple{Morbit.AbstractDB}","page":"DocStrings","title":"Base.length","text":"Number of entries in database.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._add_eq_constraint!-Tuple{Morbit.AbstractMOP{true}, MathOptInterface.VectorAffineFunction}","page":"DocStrings","title":"Morbit._add_eq_constraint!","text":"Add a linear equality constraint function to the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._add_ineq_constraint!-Tuple{Morbit.AbstractMOP{true}, MathOptInterface.VectorAffineFunction}","page":"DocStrings","title":"Morbit._add_ineq_constraint!","text":"Add a linear inequality constraint function to the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._add_nl_eq_constraint!-Tuple{Morbit.AbstractMOP{true}, Morbit.AbstractVecFun}","page":"DocStrings","title":"Morbit._add_nl_eq_constraint!","text":"Add a nonlinear equality constraint function to the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._add_nl_ineq_constraint!-Tuple{Morbit.AbstractMOP{true}, Morbit.AbstractVecFun}","page":"DocStrings","title":"Morbit._add_nl_ineq_constraint!","text":"Add a nonlinear inequality constraint function to the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._add_objective!-Tuple{Morbit.AbstractMOP{true}, Morbit.AbstractVecFun}","page":"DocStrings","title":"Morbit._add_objective!","text":"Add an objective function to the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._add_result!-Union{Tuple{I}, Tuple{R}, Tuple{Morbit.AbstractDB{R, I}, R}} where {R, I}","page":"DocStrings","title":"Morbit._add_result!","text":"Add result res to database db.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._backtrack-Union{Tuple{F}, Tuple{AbstractVector{F}, Any, Any, Any, Any, Any}} where F<:AbstractFloat","page":"DocStrings","title":"Morbit._backtrack","text":"Perform a backtracking loop starting at x with an initial step of step_size .* dir and return trial point x₊, the surrogate value-vector m_x₊ and the final step s = x₊ .- x.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._consume_points-NTuple{6, Any}","page":"DocStrings","title":"Morbit._consume_points","text":"_consume_points(data_base, poised_points, poised_indices, candidate_indices)\n\nHelper to return array of database indices for poised_points and  poised_indices. Add result to database if index is -1. candidate_indices are the database indices of the points from the trust region.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._del!-Tuple{Morbit.AbstractMOP{true}, Union{Morbit.ObjectiveIndex, Morbit.ConstraintIndex}}","page":"DocStrings","title":"Morbit._del!","text":"Remove a function from the MOP.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._equal_vals-Tuple{Morbit.Result, Morbit.Result}","page":"DocStrings","title":"Morbit._equal_vals","text":"_equal_vals( r1 :: Result, r2 :: Result )\n\nReturn true if both the site and the value vectors of r1 and r2 are equal.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._eval_models-Tuple{Morbit.TaylorModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}","page":"DocStrings","title":"Morbit._eval_models","text":"Evaluate (internal) output ℓ of TaylorModel tm, provided a difference vector h = x - x0.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._get_global_dir-Tuple{Morbit.PascolettiSerafiniConfig, Any}","page":"DocStrings","title":"Morbit._get_global_dir","text":"_get_global_dir( cfg, fx )\n\nReturn the objective space direction r ≥ 0. If a direction is stored in cfg, then it is returned. If a global ideal point i is stored in cfg, then fx .- i is returned. Else nothing is returned.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._get_optim_handle-Tuple{Morbit.AbstractSurrogate, Morbit.AbstractVarScaler, Any}","page":"DocStrings","title":"Morbit._get_optim_handle","text":"Return a function handle to be used with NLopt for output ℓ of model. That is, if model is a surrogate for two scalar objectives, then ℓ must  be either 1 or 2.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._get_ps_objective_func-Tuple{}","page":"DocStrings","title":"Morbit._get_ps_objective_func","text":"Return objective function for Pascoletti-Serafini, modifying gradient in place.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._init_iterate-Tuple{Type{var\"#s169\"} where var\"#s169\"<:Morbit.IterData, AbstractVector{var\"#s1\"} where var\"#s1\"<:AbstractFloat, AbstractVector{var\"#s1\"} where var\"#s1\"<:AbstractFloat, AbstractVector{var\"#s1\"} where var\"#s1\"<:AbstractFloat, AbstractVector{var\"#s1\"} where var\"#s1\"<:AbstractFloat, AbstractVector{var\"#s1\"} where var\"#s1\"<:AbstractFloat, AbstractVector{var\"#s1\"} where var\"#s1\"<:AbstractFloat, AbstractVector{var\"#s1\"} where var\"#s1\"<:AbstractFloat, Union{AbstractFloat, AbstractVector{var\"#s1\"} where var\"#s1\"<:AbstractFloat}, Any}","page":"DocStrings","title":"Morbit._init_iterate","text":"_init_iterate( T , x, x_scaled, fx, \n    l_e, l_i, c_e, c_i, Δ, x_index_mapping )\n\nReturn an AbstractIterate of type T. The arguments  x through c_i are site and value vectors.  Δ is the associated trust region radius. x_index_mapping is a Dict mapping FunctionIndexTuples  to the index of x in the current (sub)database.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._intersect_bounds-Union{Tuple{R}, Tuple{AbstractVector{R}, Any}, Tuple{AbstractVector{R}, Any, Any}, Tuple{AbstractVector{R}, Any, Any, Any}, Tuple{AbstractVector{R}, Any, Any, Any, Any}, Tuple{AbstractVector{R}, Any, Any, Any, Any, Any}, Tuple{AbstractVector{R}, Any, Any, Any, Any, Any, Any}, Tuple{AbstractVector{R}, Any, Any, Any, Any, Any, Any, Any}} where R<:Real","page":"DocStrings","title":"Morbit._intersect_bounds","text":"Return the maximum or minimum stepsize σ such that x + σd conforms to the linear constraints.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._local_bounds-NTuple{4, Any}","page":"DocStrings","title":"Morbit._local_bounds","text":"Return lower and upper bound vectors combining global and trust region constraints.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._missing_ids-Tuple{Morbit.AbstractDB}","page":"DocStrings","title":"Morbit._missing_ids","text":"Return vector of ids of database db that are not evaluated yet.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._set_delta!-Tuple{Morbit.IterData, Union{Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}}","page":"DocStrings","title":"Morbit._set_delta!","text":"Set current trust region radius (vector?) to Δ.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._steepest_descent_direction-Union{Tuple{F}, Tuple{AbstractVector{F}, AbstractMatrix{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}, Tuple{AbstractVector{F}, AbstractMatrix{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any}, Tuple{AbstractVector{F}, AbstractMatrix{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any, Any}, Tuple{AbstractVector{F}, AbstractMatrix{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any, Any, Any}, Tuple{AbstractVector{F}, AbstractMatrix{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any, Any, Any, Any}, Tuple{AbstractVector{F}, AbstractMatrix{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any, Any, Any, Any, Any}} where F<:AbstractFloat","page":"DocStrings","title":"Morbit._steepest_descent_direction","text":"Provided x and the (surrogate) jacobian ∇F at x, as well as bounds lb and ub, return steepest multi descent direction.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._surrogate_from_vec_function-NTuple{4, Any}","page":"DocStrings","title":"Morbit._surrogate_from_vec_function","text":"_surrogate_from_vec_function( vfun, scal, gs, nl_ind )\n\nProvided a vector function vfun that is either of type  RefVecFun or ExprVecFun and a GroupedSurrogates object gs,  that contains the model for vfun.nl_index, create and return  a RefSurrogate or ExprSurrogate from gs.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._typename","page":"DocStrings","title":"Morbit._typename","text":"Return the basis typename, i.e., remove all parameters from a typename.\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.do_groupings-Tuple{Morbit.AbstractMOP, Morbit.AbstractConfig}","page":"DocStrings","title":"Morbit.do_groupings","text":"Group functions with indices of type NLIndex by model config type.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.ensure_contains_res_with_site!-Tuple{Morbit.AbstractDB, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"DocStrings","title":"Morbit.ensure_contains_res_with_site!","text":"Return id of result in db with site x and values y. Create if necessary.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.ensure_contains_values!-Tuple{Morbit.AbstractDB, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any}","page":"DocStrings","title":"Morbit.ensure_contains_values!","text":"Return id of result in db with site x and values y. Create if necessary.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_missing!-Tuple{Morbit.AbstractDB, Morbit.AbstractMOP, Morbit.AbstractVarScaler, Any}","page":"DocStrings","title":"Morbit.eval_missing!","text":"Evaluate all unevaluated results in db using objectives of mop.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_missing!-Tuple{Morbit.SuperDB, Morbit.AbstractMOP, Morbit.AbstractVarScaler}","page":"DocStrings","title":"Morbit.eval_missing!","text":"Evaluate all unevaluated results in db using objectives of mop.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{Morbit.AbstractSurrogate, Morbit.AbstractVarScaler, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any}","page":"DocStrings","title":"Morbit.eval_models","text":"eval_models( mod, scal, x_scaled, ℓ)\n\nEvaluate output(s) ℓ of model mod at scaled site x_scaled.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{Morbit.ExactModel, Morbit.AbstractVarScaler, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"DocStrings","title":"Morbit.eval_models","text":"Evaluate the ExactModel em at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{Morbit.TaylorModel, Morbit.AbstractVarScaler, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any}","page":"DocStrings","title":"Morbit.eval_models","text":"Evaluate (internal) output(s) ℓ of tm at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{RbfModel, Morbit.AbstractVarScaler, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any}","page":"DocStrings","title":"Morbit.eval_models","text":"Evaluate output ℓ of mod::RbfModel at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{RbfModel, Morbit.AbstractVarScaler, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"DocStrings","title":"Morbit.eval_models","text":"Evaluate mod::RbfModel at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.find_result","page":"DocStrings","title":"Morbit.find_result","text":"find_result(db, x, y)\n\nReturn id of a result in db that has site x and value y or return -1  if there is no such result.\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.full_lower_bounds-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.full_lower_bounds","text":"Return full vector of lower variable vectors for original problem.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.full_upper_bounds-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.full_upper_bounds","text":"Return full vector of upper variable vectors for original problem.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_delta-Tuple{Morbit.IterData}","page":"DocStrings","title":"Morbit.get_delta","text":"Return current trust region radius (vector) Δᵗ.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_eq_const-Tuple{Morbit.IterData}","page":"DocStrings","title":"Morbit.get_eq_const","text":"Return value vector of linear equality constraints.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_eq_constraint_indices-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.get_eq_constraint_indices","text":"Return the vector or tuple of the indices of linear equality constraints used in the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_evaluated_flag-Tuple{Any, Any}","page":"DocStrings","title":"Morbit.get_evaluated_flag","text":"Return true if the result with id in db has a valid evaluation vector.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_fx-Tuple{Morbit.IterData}","page":"DocStrings","title":"Morbit.get_fx","text":"Return current value vector f(xᵗ).\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_gradient-Tuple{Morbit.ExactModel, Morbit.AbstractVarScaler, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any}","page":"DocStrings","title":"Morbit.get_gradient","text":"Gradient vector of output ℓ of em at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_gradient-Tuple{RbfModel, Morbit.AbstractVarScaler, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any}","page":"DocStrings","title":"Morbit.get_gradient","text":"Gradient vector of output ℓ of mod at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_id-Tuple{Morbit.Result}","page":"DocStrings","title":"Morbit.get_id","text":"get_id( res :: Result ) :: Int\n\nReturn the id of a result such that for the database db  containing res it holds that get_result(db, id) == res.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_ids-Tuple{Morbit.AbstractDB}","page":"DocStrings","title":"Morbit.get_ids","text":"List of all id :: Int belonging to the stored results.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_ineq_const-Tuple{Morbit.IterData}","page":"DocStrings","title":"Morbit.get_ineq_const","text":"Return value vector of linear inequality constraints.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_ineq_constraint_indices-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.get_ineq_constraint_indices","text":"Return the vector or tuple of the indices of linear inequality constraints used in the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_jacobian","page":"DocStrings","title":"Morbit.get_jacobian","text":"Jacobian Matrix of ExactModel em at scaled site x̂.\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.get_lower_bound-Tuple{Morbit.AbstractMOP, MathOptInterface.VariableIndex}","page":"DocStrings","title":"Morbit.get_lower_bound","text":"Return the lower bound for the variable with Index VarInd.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_model_jacobian","page":"DocStrings","title":"Morbit.get_model_jacobian","text":"Jacobian Matrix of ExactModel em at scaled site x̂.\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.get_nl_eq_const-Tuple{Morbit.IterData}","page":"DocStrings","title":"Morbit.get_nl_eq_const","text":"Return current equality constraint vector cₑ(xᵗ).\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_nl_eq_constraint_indices-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.get_nl_eq_constraint_indices","text":"Return the vector or tuple of the indices of nonlinear equality constraints used in the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_nl_ineq_const-Tuple{Morbit.IterData}","page":"DocStrings","title":"Morbit.get_nl_ineq_const","text":"Return current inequality constraint vector cᵢ(xᵗ).\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_nl_ineq_constraint_indices-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.get_nl_ineq_constraint_indices","text":"Return the vector or tuple of the indices of nonlinear inequality constraints used in the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_objective_indices-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.get_objective_indices","text":"Return a vector or tuple of all objective indices used in the model.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_poised_set-Union{Tuple{Any}, Tuple{T}, Tuple{Any, AbstractArray{T, N} where N}} where T<:(AbstractArray{var\"#s161\", N} where {var\"#s161\"<:Real, N})","page":"DocStrings","title":"Morbit.get_poised_set","text":"get_poised_set( basis, points; solver = :LN_BOBYQA, max_solver_evals = -1 )\n\nCompute a point set suited for polynomial interpolation.\n\nInput:\n\nbasis: A vector of polynomials constituting a basis for the polynomial space.\npoints: (optional) A set of candidate points to be tried for inclusion into the poised set.\nsolver: NLopt solver to use. Should be derivative-free.\nmax_solver_evals: Maximum number of evaluations in each optimization run. \n\nReturn:\n\npoised_points :: Vector{T} where T is either a Vector{F} or an SVector{n_vars, F} and F is the precision of the points in points, but at least Float32. \nlagrange_basis :: Vector{<:AbstractPolynomialLike}: The Lagrange basis corresponding to poised_points.\npoint_indices: An array indicating which points from points are also in poised_points. A positive entry corresponds to the index of a poised point in points. If a poised point is new, then the entry is -1.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_res_type-Union{Tuple{Morbit.AbstractDB{R, I}}, Tuple{I}, Tuple{R}} where {R, I}","page":"DocStrings","title":"Morbit.get_res_type","text":"Return type of results stored in database.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_result-Union{Tuple{I}, Tuple{R}, Tuple{Morbit.AbstractDB{R, I}, Int64}} where {R, I}","page":"DocStrings","title":"Morbit.get_result","text":"Get result with id from database db.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_saveable_type-Union{Tuple{Morbit.AbstractDB{R, I}}, Tuple{I}, Tuple{R}} where {R, I}","page":"DocStrings","title":"Morbit.get_saveable_type","text":"Return type of AbstractIterSaveables stored in database.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_scaling_poly-Tuple{Any, Any, Any}","page":"DocStrings","title":"Morbit.get_scaling_poly","text":"Return vector of polynomials that scales variables from [lb, ub] to [0,1]^n.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_site-Tuple{Morbit.AbstractDB, Int64}","page":"DocStrings","title":"Morbit.get_site","text":"Return the evaluation value vector for result with id in database db.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_site-Tuple{Morbit.Result}","page":"DocStrings","title":"Morbit.get_site","text":"get_site( res :: Result{XT,YT} )\n\nReturn evaluation site of type XT associated with res.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_sites-Tuple{Morbit.AbstractDB}","page":"DocStrings","title":"Morbit.get_sites","text":"Return a vector of all evaluation site vectors stored in database.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_unscaling_poly-Tuple{Any, Any, Any}","page":"DocStrings","title":"Morbit.get_unscaling_poly","text":"Return vector of polynomials that unscales variables from [0,1]^n to [lb,ub].\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_upper_bound-Tuple{Morbit.AbstractMOP, MathOptInterface.VariableIndex}","page":"DocStrings","title":"Morbit.get_upper_bound","text":"Return the upper bound for the variable with Index VarInd.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_vals-Tuple{Morbit.AbstractIterate, Any, Any}","page":"DocStrings","title":"Morbit.get_vals","text":"Return only the parts of f(x) that are relevant for func_indices.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_value-Tuple{Morbit.AbstractDB, Int64}","page":"DocStrings","title":"Morbit.get_value","text":"Return the evaluation site vector for result with id in database db.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_value-Tuple{Morbit.Result}","page":"DocStrings","title":"Morbit.get_value","text":"get_value( res :: Result{XT,YT} )\n\nReturn evaluation value vector of type YT associated with res.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_values-Tuple{Morbit.AbstractDB}","page":"DocStrings","title":"Morbit.get_values","text":"Return a vector of all evaluation value vectors stored in database.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_x-Tuple{Morbit.IterData}","page":"DocStrings","title":"Morbit.get_x","text":"Return current iteration site vector xᵗ.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_x_index-Tuple{Morbit.IterData, Any}","page":"DocStrings","title":"Morbit.get_x_index","text":"Index (or id) of current iterate in database.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_x_scaled-Tuple{Morbit.IterData}","page":"DocStrings","title":"Morbit.get_x_scaled","text":"Return current iteration site vector xᵗ.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.grow_radius-Tuple{Val{:standard}, Any, Any, Any}","page":"DocStrings","title":"Morbit.grow_radius","text":"Grow radius according to min( Δ_max, γ * Δ ).\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.grow_radius-Tuple{Val{:steplength}, Any, Any, Any}","page":"DocStrings","title":"Morbit.grow_radius","text":"Grow radius according to min( Δ_max, (γ + ||s||/Δ) * Δ )\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.has_valid_site-Tuple{Morbit.Result}","page":"DocStrings","title":"Morbit.has_valid_site","text":"has_valid_site( r :: Result )\n\nReturn true if the site vector of r is neither empty nor NaN.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.has_valid_value-Tuple{Morbit.Result}","page":"DocStrings","title":"Morbit.has_valid_value","text":"has_valid_value( r :: Result )\n\nReturn true if the value vector of r is neither empty nor NaN.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.init_db-Tuple{Morbit.MockDB, Any, Any, Vararg{Any, N} where N}","page":"DocStrings","title":"Morbit.init_db","text":"Constructor for empty database of type MockDB.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.init_db-Tuple{Type{var\"#s167\"} where var\"#s167\"<:Morbit.ArrayDB, Type{var\"#s166\"} where var\"#s166\"<:Morbit.AbstractResult, Type{var\"#s165\"} where var\"#s165\"<:Union{Nothing, Morbit.AbstractSurrogateMeta}}","page":"DocStrings","title":"Morbit.init_db","text":"Constructor for empty database of type ArrayDB.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.init_iterate-Tuple{Type{var\"#s169\"} where var\"#s169\"<:Morbit.AbstractIterate, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Union{Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}, Any}","page":"DocStrings","title":"Morbit.init_iterate","text":"init_iter_data( T , x, fx, Δ )\n\nReturn an instance of \"base\" type T implementing AbstractIterate with  correct type parameters for x, fx and Δ. x and fx should be vectors of floats and Δ can either be a float or  a vector of floats.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.init_model-Tuple{Morbit.ExactMeta, ExactConfig, Any, Any, Any, Any, Any, Any}","page":"DocStrings","title":"Morbit.init_model","text":"Return an ExactModel build from a VecFun objf.  Model is the same inside and outside of criticality round.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.init_res","page":"DocStrings","title":"Morbit.init_res","text":"init_res( id, x, y)\n\nReturn of result with site x, value y and database id id.\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.init_surrogates-Tuple{Morbit.AbstractMOP, Morbit.AbstractVarScaler, Morbit.AbstractIterate, Morbit.AbstractConfig, Vector{Morbit.ModelGrouping}, Any, Any}","page":"DocStrings","title":"Morbit.init_surrogates","text":"Return a SurrogateContainer initialized from the information provided in mop.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.is_transformed-Tuple{Morbit.AbstractDB}","page":"DocStrings","title":"Morbit.is_transformed","text":"Bool indicating if the database data been transformed.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.local_bounds-Tuple{Morbit.AbstractVarScaler, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Union{Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}}","page":"DocStrings","title":"Morbit.local_bounds","text":"Local bounds vectors lb_eff and ub_eff using scaled variable constraints from mop.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.make_set_lambda_poised-Union{Tuple{T}, Tuple{Any, AbstractArray{T, N} where N}} where T<:(AbstractArray{var\"#s161\", N} where {var\"#s161\"<:Real, N})","page":"DocStrings","title":"Morbit.make_set_lambda_poised","text":"make_set_lambda_poised( basis, points; \n    LAMBDA = 1.5, solver = :LN_BOBYQA, max_solver_evals = -1, max_loops = -1, skip_indices = [1,] )\n\nMake the output of get_poised_set even better suited for interpolation.\n\nInput:\n\nbasis: A vector of polynomials constituting a Lagrange basis for the polynomial space.\npoints: The vector of points belonging to the Lagrange basis.\nLAMBDA :: Real > 1: Determines the quality of the interpolation. \nsolver: NLopt solver to use. Should be derivative-free.\nmax_solver_evals: Maximum number of evaluations in each optimization run. \nmax_loops: Maximum number of loops that try to make the set Λ-poised.\nskip_indices: Inidices of points to discard last.\n\nReturn:\n\npoised_points :: Vector{T} where T is either a Vector{F} or an SVector{n_vars, F} and F is the precision of the points in points, but at least Float32. \nlagrange_basis :: Vector{<:AbstractPolynomialLike}: The Lagrange basis corresponding to poised_points.\npoint_indices: An array indicating which points from points are also in poised_points. A positive entry corresponds to the index of a poised point in points. If a poised point is new, then the entry is -1.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.make_vec_fun-Tuple{Function}","page":"DocStrings","title":"Morbit.make_vec_fun","text":"make_vec_fun( fn; \nmodel_cfg, n_out, can_batch = false,\ngradients = nothing, jacobian = nothing, hessian = nothing,\ndiff_method = FiniteDiffWrapper )\n\nPack the function fn::Function into a VecFun and ensure that  appropriate derivative information can be queried, as needed by model_cfg.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.make_vec_fun-Tuple{Morbit.CountedFunc}","page":"DocStrings","title":"Morbit.make_vec_fun","text":"make_vec_fun( fn; \nmodel_cfg, n_out, can_batch = false,\ngradients = nothing, jacobian = nothing, hessian = nothing,\ndiff_method = FiniteDiffWrapper )\n\nPack the function fn::CountedFunc into a VecFun and ensure that  appropriate derivative information can be queried, as needed by model_cfg.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.max_evals-Tuple{Morbit.AbstractVecFun}","page":"DocStrings","title":"Morbit.max_evals","text":"(Soft) upper bound on the number of function calls. \n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.new_result!-Union{Tuple{I}, Tuple{R}, Tuple{Morbit.AbstractDB{R, I}, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}, Tuple{Morbit.AbstractDB{R, I}, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any}, Tuple{Morbit.AbstractDB{R, I}, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Any, Int64}} where {R, I}","page":"DocStrings","title":"Morbit.new_result!","text":"Add a new result to the database, return its id of type Int.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.next_id-Tuple{Morbit.AbstractDB}","page":"DocStrings","title":"Morbit.next_id","text":"Return an id for the next result to be added to db.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.num_objectives-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.num_objectives","text":"Number of scalar-valued objectives of the problem.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.register_func-Tuple{Any, Symbol}","page":"DocStrings","title":"Morbit.register_func","text":"register_func(func, func_name)\n\nRegisters the function func for subsequent use in a function  expression. Note, that using function expressions is really only advisable if  the \"base function\" is truly expensive and surrogate modelling remedies  the performance penalties from parsing strings and @evaling expressions.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.reset_evals!-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.reset_evals!","text":"Set evaluation counter to 0 for each VecFun in m.vector_of_objectives.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.results_in_box_indices","page":"DocStrings","title":"Morbit.results_in_box_indices","text":"Return indices of results in db that lie in a box with corners lb and ub.\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.set_evaluated_flag!","page":"DocStrings","title":"Morbit.set_evaluated_flag!","text":"Set the evaluation status for result with id to state.\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.set_site!-Tuple{Any, Any, Any}","page":"DocStrings","title":"Morbit.set_site!","text":"Set site of result with id in database db to x.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.set_transformed!-Tuple{Morbit.AbstractDB, Bool}","page":"DocStrings","title":"Morbit.set_transformed!","text":"Set the flag indicating whether the database data has been transformed or not.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.set_value!-Tuple{Any, Any, Any}","page":"DocStrings","title":"Morbit.set_value!","text":"Set value of result with id in database db to x.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.shrink_radius-Tuple{Val{:standard}, Any, Any, Any}","page":"DocStrings","title":"Morbit.shrink_radius","text":"Shrink radius according to γ * Δ.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.shrink_radius-Tuple{Val{:steplength}, Any, Any, Any}","page":"DocStrings","title":"Morbit.shrink_radius","text":"Shrink radius according to γ * ||s||.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.shrink_radius_much-Tuple{Val{:standard}, Any, Any, Any}","page":"DocStrings","title":"Morbit.shrink_radius_much","text":"Shrink radius much according to γ * Δ.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.shrink_radius_much-Tuple{Val{:steplength}, Any, Any, Any}","page":"DocStrings","title":"Morbit.shrink_radius_much","text":"Shrink radius according to γ * ||s||.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.stamp!-Tuple{Morbit.AbstractDB, Union{Nothing, Morbit.AbstractSurrogateMeta}}","page":"DocStrings","title":"Morbit.stamp!","text":"stamp!(db, ids)\n\nPut the saveable ids into the database db.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.str2func-Tuple{Any, Morbit.AbstractSurrogate, Any, Any}","page":"DocStrings","title":"Morbit.str2func","text":"str2func(expr_str, model, scal, output_indices; register_adjoint = true)\n\nParse a user provided string describing some function of x and  return the resulting function. Each occurence of \"VREF(x̂)\" in expr_str is replaced by a function  evaluating outputs output_indices of mod::AbstractSurrogate at  the scaled site x̂. If register_adjoint == true, then we register a custom adjoint for  vfunc that uses the get_jacobian method.\n\nThe user may also use custom functions in expr_str hat have been  registered with register_func (and that are differentiable with Zygote).\n\nregister_func\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.str2func-Tuple{Any, Morbit.AbstractVecFun}","page":"DocStrings","title":"Morbit.str2func","text":"str2func(expr_str, vfunc)\n\nParse a user provided string describing some function of x and  return the resulting function. Each occurence of \"VREF(x)\" in expr_str is replaced by a function  evaluating vfunc::AbstractVecFun at x.\n\nThe user may also use custom functions in expr_str hat have been  registered with register_func.\n\nregister_func\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.transform!-Tuple{Morbit.AbstractDB, Int64, Morbit.AbstractVarScaler}","page":"DocStrings","title":"Morbit.transform!","text":"Scale the site of result with id in database db using bounds of mop.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.transform!-Tuple{Morbit.AbstractDB, Morbit.AbstractVarScaler}","page":"DocStrings","title":"Morbit.transform!","text":"Apply scaling and objectives sorting to each result in database db.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.unique_with_indices-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T","page":"DocStrings","title":"Morbit.unique_with_indices","text":"Return unique_elems, indices = unique_with_indices(arr) such that  unique_elems[indices] == arr (and unique_elems == unique(arr)).\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.untransform!-Tuple{Morbit.AbstractDB, Int64, Morbit.AbstractVarScaler}","page":"DocStrings","title":"Morbit.untransform!","text":"Unscale the site of result with id in database db using bounds of mop.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.untransform!-Tuple{Morbit.AbstractDB, Morbit.AbstractVarScaler}","page":"DocStrings","title":"Morbit.untransform!","text":"Undo scaling and objectives sorting to each result in database db.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.var_indices-Tuple{Morbit.AbstractMOP}","page":"DocStrings","title":"Morbit.var_indices","text":"Return a vector of VariableIndices used in the model.\n\n\n\n\n\n","category":"method"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/models/LagrangeModel.jl\"","category":"page"},{"location":"LagrangeModel/#Lagrange-Polynomial-Models","page":"LagrangeModels","title":"Lagrange Polynomial Models","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"This file is automatically generated from source code. For usage examples refer to Summary & Quick Examples.","category":"page"},{"location":"LagrangeModel/#Intro-and-Prerequisites","page":"LagrangeModels","title":"Intro and Prerequisites","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"Polyoniaml interpolation models are a common choice for surrogate modeling. In our setting we want to construct models for n-variate objectives and use polynomials of degree 1 or 2. We hence need a basis for the space Π_n^d of polynomials. Given a point set that is suited for interpolation (a poised set) we can use the Lagarange basis l_i with l_i(x_j) = δ_ij to easily find the coefficients for vector valued models.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We use DynamicPolynomials for polynomial arithmetic, NLopt to optimize polynomials and some more packages:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"using DynamicPolynomials\nimport NLopt\nimport Combinatorics","category":"page"},{"location":"LagrangeModel/#Surrogate-Interface-Implementations","page":"LagrangeModels","title":"Surrogate Interface Implementations","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The model itself is defined only by its vector of Lagrange basis polynomials and the coefficients.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"@with_kw struct LagrangeModel{\n        B <: AbstractArray{<:AbstractPolynomialLike},\n        G <: AbstractArray{<:AbstractArray{<:AbstractPolynomialLike}},\n        V <: AbstractVector{<:AbstractVector{<:AbstractFloat} } } <: AbstractSurrogate\n    basis :: B  # basis polynomials\n    grads :: G  # gradient polynomials for all the basis polynomials\n    coeff :: V  # coefficients to interpolate data with `basis`\n    fully_linear :: Bool = false\n    num_outputs :: Int = -1\nend\n\nfully_linear( lm :: LagrangeModel ) = lm.fully_linear\nnum_outputs( lm :: LagrangeModel ) = lm.num_outputs\n\nfunction set_fully_linear!(lm :: LagrangeModel, val :: Bool )\n\tlm.fully_linear = val\n\treturn nothing\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"There is a multitude of configuration parameters, most of which will be explained later:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"\"\"\"\n    LagrangeConfig(; kwargs... )\n\nConfiguration for Lagrange Polyoniaml models.\n\n$(FIELDS)\n\"\"\"\n@with_kw mutable struct LagrangeConfig <: AbstractSurrogateConfig\n\n    \"Degree of the surrogate model polynomials.\"\n    degree :: Int = 2\n\n    \"Enlargement parameter to consider more points for inclusion.\"\n    θ_enlarge :: Float64 = 2.0\n\n    \"Quality parameter in Λ-Poisedness Algorithm.\"\n    LAMBDA :: Float64 = 1.5\n\n    \"Whether or not the interpolation sets must be Λ-poised (and the models fully linear).\"\n    allow_not_linear :: Bool = false\n\n    \"Whether or not to try to construct a new interpolation set in each iteration.\"\n    optimized_sampling :: Bool = true\n\n    # if optimized_sampling = false, shall we try to use saved sites?\n    \"Path to look at for a pre-saved poised set of interpolation points in [0,1]^n.\"\n    save_path :: String = \"\"\n\n    \"Lock to use parallel setups if multiple models can access `save_path`.\"\n    io_lock :: Union{Nothing, Threads.ReentrantLock} = nothing\n\n    \"Maximum number of polynomial evaluations to find a poised set.\"\n    algo1_max_evals :: Int = -1\n\n    \"Maximum number of polynomial evaluations to make a set Λ-poised.\"\n    algo2_max_evals :: Int = -1\n\n    \"NLopt Solver to use for the poisedness problem.\"\n    algo1_solver :: Symbol = :LN_BOBYQA\n    \"NLopt Solver to use for the Λ-poisedness problem.\"\n    algo2_solver :: Symbol = :LN_BOBYQA\n\n    \"Maximum number of evaluations allowed to the true objective(s).\"\n    max_evals :: Int64 = typemax(Int64);\n\n    @assert 1 <= degree <= 2 \"Only linear and quadratic models are supported.\"\n    @assert LAMBDA > 1 \"`LAMBDA` must be > 1.\"\n    @assert let algo_str = string( algo1_solver );\n        length( algo_str ) > 2 && string(algo_str[2]) == \"N\"\n    end \"`algo1_solver` must be a derivative-free NLopt algorithm.\"\n    @assert let algo_str = string( algo2_solver );\n        length( algo_str ) > 2 && string(algo_str[2]) == \"N\"\n    end \"`algo2_solver` must be a derivative-free NLopt algorithm.\"\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"Overwrite lock and unlock so we can use nothing as a \"lock\":","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function Base.lock(::Nothing) end\nfunction Base.unlock(::Nothing) end","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The required method implementations are straightforward. Note, thate we allow the models to be combined to vector functions if they share the same configuration to avoid redundant efforts whilst constructing models.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"max_evals( cfg :: LagrangeConfig ) :: Int = cfg.max_evals\ncombinable( cfg :: LagrangeConfig ) :: Bool = true","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We also need to introduce our own implementation for isequal and hash for LagrangeConfigs to be combinable, see the docs too.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function Base.hash( cfg :: LagrangeConfig, h :: UInt )\n\treturn hash( getfield.( cfg, Tuple( fn for fn ∈ fieldnames(LagrangeConfig) ) ), h )\nend\nfunction Base.isequal( cfg1 :: LagrangeConfig, cfg2 :: LagrangeConfig )\n\tall( isequal( getfield(cfg1, fn), getfield(cfg2, fn) ) for fn in fieldnames( LagrangeConfig) )\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The LagrangeMeta simply holds the (sub-)database indices of the results we want to interpolate at. We also store the output indices of the model for convenience and carry polynomials that act on 01^n.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"@with_kw struct LagrangeMeta{\n        CB <: Union{Nothing, Vector{<:AbstractPolynomialLike}},\n        LB <: Union{Nothing, Vector{<:AbstractPolynomialLike}},\n        P <: Union{Nothing, AbstractVector{<:AbstractVector{<:Real}}}\n    } <: AbstractSurrogateMeta\n    interpolation_indices :: Vector{Int} = []\n    canonical_basis :: CB = nothing\n    lagrange_basis :: LB = nothing  # store the lagrange basis acting on [0,1]^n\n    stamp_points :: P = nothing     # used only if `optimized_sampling == false`\n    fully_linear :: Bool = false\nend\n\nfunction get_saveable_type( T :: LagrangeConfig, x, y )\n    return LagrangeMeta{Nothing,Nothing, Nothing}\nend\nfunction get_saveable( meta :: LagrangeMeta )\n    return LagrangeMeta(;\n        interpolation_indices = meta.interpolation_indices,\n    )\nend","category":"page"},{"location":"LagrangeModel/#Construction","page":"LagrangeModels","title":"Construction","text":"","category":"section"},{"location":"LagrangeModel/#A-Bit-of-Theory","page":"LagrangeModels","title":"A Bit of Theory","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The canonical basis is obtained by calculating the non-negative integral solutions to the euqation","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"x_1 +  + x_n le d","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"These solutions can be found using the Combinatorics package via multiexponents(n,d) (d must be successively increased).","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function non_negative_ineq_solutions(deg, n_vars)\n\tIterators.flatten( ( collect( Combinatorics.multiexponents( n_vars, d )) for d = 0 : deg ) )\nend\n\nfunction get_poly_basis( deg, n_vars)\n\texponents = non_negative_ineq_solutions(deg, n_vars )\n\tpolys = let\n\t\t@polyvar x[1:n_vars]\n\t\t[ prod(x.^e) for e in exponents ]\n\tend\n\treturn polys\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We are going to use the canonical basis to determine a poised set of points. This does in fact work with any polynomial basis for Π_n^d. \nIn the process of doing so, we also modify (a copy of?) the basis so that it becomes the Lagrange basis for the returned point set.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The Larange basis is formed by normalizing and orthogonalizing with respect to the point set:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function orthogonalize_polys( poly_arr, x, i )\n\t# normalize i-th polynomial with respect to `x`\n\tp_i = poly_arr[i] / poly_arr[i](x)\n\n\t# orthogonalize\n\treturn [ j != i ? poly_arr[j] - ( poly_arr[j](x) * p_i ) : p_i for j = eachindex( poly_arr ) ]\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We use Algorithm 6.2 and Algorithm 6.3 from the book \"Introduction to Derivative-Free Optimization\" by Conn et. al. \nAlgorithm 6.2 makes the set poised (suited for interpolation) and returns the corresponding Lagrange basis. Algorithm 6.3 takes the poised set and the Lagrange basis and tries to make it Λ-poised. Λ must be greater 1 and a smaller value makes the set more suited for good models.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"\"\"\"\n    get_poised_set( basis, points; solver = :LN_BOBYQA, max_solver_evals = -1 )\n\nCompute a point set suited for polynomial interpolation.\n\nInput:\n* `basis`: A vector of polynomials constituting a basis for the polynomial space.\n* `points`: (optional) A set of candidate points to be tried for inclusion into the poised set.\n* `solver`: NLopt solver to use. Should be derivative-free.\n* `max_solver_evals`: Maximum number of evaluations in each optimization run.\n\nReturn:\n* `poised_points :: Vector{T}` where `T` is either a `Vector{F}` or an `SVector{n_vars, F}` and `F` is the precision of the points in `points`, but at least `Float32`.\n* `lagrange_basis :: Vector{<:AbstractPolynomialLike}`: The Lagrange basis corresponding to `poised_points`.\n* `point_indices`: An array indicating which points from `points` are also in `poised_points`. A positive entry corresponds to the index of a poised point in `points`. If a poised point is new, then the entry is `-1`.\n\"\"\"\nfunction get_poised_set( basis, points :: AbstractArray{T} = Vector{MIN_PRECISION}[];\n\t\tsolver = :LN_BOBYQA, max_solver_evals = -1 ) where {\n\t\tT <: AbstractArray{<:Real}\n\t}\n\n\tp = length(basis)\n\t@assert p > 0 \"`basis` must not be an empty array.\"\n\n    @logmsg loglevel3 \"Trying to find a poised set with $(p) points.\"\n\n\tvars = variables( basis[end] )\n\tn_vars = length(vars)\n\t@assert n_vars > 0 \"The number of variables must be positive.\"\n\n\tif max_solver_evals < 0\n\t\tmax_solver_evals = 2000 * n_vars\n\tend\n\n\tF = promote_type( eltype( T ), MIN_PRECISION )\n\t#P_type = n_vars > 100 ? Vector{Vector{F}} : Vector{SVector{n_vars, F}}\n    P_type = Vector{Vector{F}}\n\tZERO_TOL = min(eps(F) * 100, eps(Float16) * 10)\n\n\t# indicates which points from points have been accepted\n\tpoint_indices = fill(-1, p)\n\tnot_accepted_indices = collect( eachindex( points ) )\n\t# return array of points that form a poised set\n\tpoised_points = P_type(undef, p)\n\n\tnew_basis = basis\n\tfor i = 1 : p\n\t\t_points = points[not_accepted_indices]\n\n\t\t# find the point that maximizes the i-th polynomial\n\t\t# if the polynomial is constant, then the first remaining point is used (j = 1)\n\t\tl_max, j = if isempty(_points)\n\t\t\t0.0, 0\n\t\telse\n\t\t\tfindmax( abs.( [ new_basis[i]( x ) for x in _points ] ) )\n\t\tend\n\n\t\tif l_max > ZERO_TOL\n\t\t\t# accept the `j`-th point from `_points`\n\t\t\tpoised_points[i] = _points[j]\n\t\t\t### indicate what the actual point index was\n\t\t\tpoint_indices[i] = not_accepted_indices[j]\n\t\t\t### delete from further consideration\n\t\t\tdeleteat!(not_accepted_indices, j)\n\t\telse\n\t\t\t# no point was suitable to add to the set\n\t\t\t# trying to find the maximizer for a | l_i(x) |\n\t\t\topt = NLopt.Opt( solver, n_vars )\n\t\t\topt.lower_bounds = zeros(F, n_vars )\n            opt.upper_bounds = ones(F, n_vars )\n            opt.maxeval = max_solver_evals\n            opt.xtol_rel = 1e-3\n            opt.max_objective = (x,g) -> abs( new_basis[i](x) )\n\n            # try to find a good starting point\n\t\t\tx₀_tmp = [ rand(F, n_vars) for i = 1 : 50 * n_vars ]\n            x₀ = x₀_tmp[argmax( abs.(new_basis[i].(x₀_tmp)) ) ]\n\n\t\t\t_, ξ, ret = NLopt.optimize(opt, x₀)\n\n\t\t\tpoised_points[i] = ξ\n\t\tend\n\n\t\tnew_basis = orthogonalize_polys( new_basis, poised_points[i], i )\n\tend\n\n\treturn poised_points, new_basis, point_indices\nend\n\n\"\"\"\n    make_set_lambda_poised( basis, points;\n        LAMBDA = 1.5, solver = :LN_BOBYQA, max_solver_evals = -1, max_loops = -1, skip_indices = [1,] )\n\nMake the output of `get_poised_set` even better suited for interpolation.\n\nInput:\n* `basis`: A vector of polynomials constituting a Lagrange basis for the polynomial space.\n* `points`: The vector of points belonging to the Lagrange basis.\n* `LAMBDA :: Real > 1`: Determines the quality of the interpolation.\n* `solver`: NLopt solver to use. Should be derivative-free.\n* `max_solver_evals`: Maximum number of evaluations in each optimization run.\n* `max_loops`: Maximum number of loops that try to make the set Λ-poised.\n* `skip_indices`: Inidices of points to discard last.\n\nReturn:\n* `poised_points :: Vector{T}` where `T` is either a `Vector{F}` or an `SVector{n_vars, F}` and `F` is the precision of the points in `points`, but at least `Float32`.\n* `lagrange_basis :: Vector{<:AbstractPolynomialLike}`: The Lagrange basis corresponding to `poised_points`.\n* `point_indices`: An array indicating which points from `points` are also in `poised_points`. A positive entry corresponds to the index of a poised point in `points`. If a poised point is new, then the entry is `-1`.\n\"\"\"\nfunction make_set_lambda_poised( basis, points :: AbstractArray{T};\n\t\tLAMBDA :: Real = 1.5, solver = :LN_BOBYQA, max_solver_evals = -1,\n\t\tmax_loops = -1, skip_indices = [1,] ) where {\n\t\tT <: AbstractArray{<:Real}\n\t}\n\n\t@assert length(basis) == length(points) \"Polynomial array `basis` and point array `points` must have the same length.\"\n\tif length(points) > 0\n\t\tn_vars = length(points[1])\n\t\t@assert n_vars > 0 \"The number of variables must be positive.\"\n\n\t\tF = promote_type( eltype( T ), MIN_PRECISION )\n\t\t#P_type = n_vars > 100 ? Vector{Vector{F}} : Vector{SVector{n_vars, F}}\n        P_type = Vector{Vector{F}}\n\n\t\tif max_loops < 0\n\t\t\tmax_loops = length(basis) * 100\n\t\tend\n\n\t\tif max_solver_evals < 0\n\t\t\tmax_solver_evals = 2000 * n_vars\n\t\tend\n\n       \t@logmsg loglevel3 \"Trying $(max_loops) times to make a set poised with Λ = $(LAMBDA).\"\n\n\t\tnew_basis = basis\n\t\tnew_points = P_type(points)\n\t\tpoint_indices = collect(eachindex(new_points))\n\n\t\tfor k = 1 : max_loops\n            iₖ = -1\n\t\t    xₖ = points[1]\n\t\t\tfor (i, polyᵢ) in enumerate(new_basis)\n\t\t\t\topt = NLopt.Opt( solver, n_vars )\n\t\t\t\topt.lower_bounds = zeros(F, n_vars)\n\t\t\t\topt.upper_bounds = ones(F, n_vars)\n\t\t\t\topt.maxeval = max_solver_evals\n\t\t\t\topt.xtol_rel = 1e-3\n\t\t\t\topt.max_objective = (x,g) -> abs( polyᵢ( x ) )\n\n                x₀ = points[i]\n\n\t\t\t\tabs_lᵢ, xᵢ, _ = NLopt.optimize(opt, x₀)\n\n\t\t\t\tif abs_lᵢ > LAMBDA\n\t\t\t\t\tiₖ = i\n\t\t\t\t\txₖ = xᵢ\n\t\t\t\t\tif iₖ ∉ skip_indices\n\t\t\t\t\t\t# i is not prioritized we can brake here\n\t\t\t\t\t\tbreak\n\t\t\t\t\tend#if\n\t\t\t\tend#if\n\t\t\tend#for\n\n\t\t\tif iₖ > 0\n                @logmsg loglevel4 \"Discarding point $(iₖ).\"\n\t\t\t\t# perform a point swap\n\t\t\t\tnew_points[iₖ] = xₖ\n\t\t\t\tpoint_indices[iₖ] = -1\n\t\t\t\t# adapt coefficients of lagrange basis\n\t\t\t\tnew_basis = orthogonalize_polys( new_basis, xₖ, iₖ )\n\t\t\telse\n\t\t\t\t# we are done, the set is lambda poised\n\t\t\t\tbreak\n\t\t\tend#if\n\t\tend#for\n\n\t\treturn new_points, new_basis, point_indices\n\telse\n\t\treturn points, basis, collect(eachindex(points))\n\tend\n\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"And a convenient function that combines both steps:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function get_lambda_poised_set( basis, points; solver1 = :LN_BOBYQA, solver2 = :LN_BOBYQA, max_solver_evals1 = -1, max_solver_evals2 = -1, LAMBDA = 1.5, max_lambda_loops = -1 )\n\tlagrange_points, lagrange_basis, lagrange_indices = get_poised_set(\n\t\tbasis, points; solver = solver1, max_solver_evals = max_solver_evals1 )\n\tlambda_points, lambda_basis, lambda_indices = make_set_lambda_poised(\n\t\tlagrange_basis, lagrange_points; LAMBDA, max_loops = max_lambda_loops,\n\t\tsolver = solver2, max_solver_evals = max_solver_evals2 )\n\tcombined_indices = [ i < 0 ? i : lagrange_indices[j] for (j,i) in enumerate( lambda_indices ) ]\n\treturn lambda_points, lambda_basis, combined_indices\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We actually only try to find points suitable points in the hypercube 01^n. The points can be (un)scaled with the usual methods. But for Polynomials we can actually use substition to make evaluation more effective.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"\"Return vector of polynomials that unscales variables from [0,1]^n to [lb,ub].\"\nfunction get_unscaling_poly( vars, lb, ub )\n    # we don't have to check for Inf here because of finite trust region\n    w = ub .- lb\n    return vars .* w .+ lb\nend\n\n\"Return vector of polynomials that scales variables from [lb, ub] to [0,1]^n.\"\nfunction get_scaling_poly( vars, lb, ub )\n    w = ub .- lb\n    return ( vars .- lb ) ./ w\nend","category":"page"},{"location":"LagrangeModel/#Method-Implementations","page":"LagrangeModels","title":"Method Implementations","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We will use the functions from above in the prepare_XXX routines:\nThe initial prepare_init_model function should return a meta object that can be used to build an initial surrogate model. We delegate the work to prepare_update_model.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function prepare_init_model(\n        cfg :: LagrangeConfig, func_indices,\n        mop, scal, x_it,\n        sdb, ac;\n\t    ensure_fully_linear = true, kwargs...\n    )\n\n    n_vars = num_vars( mop )\n\n\tmeta = LagrangeMeta(;\n        canonical_basis = get_poly_basis( cfg.degree, n_vars )\n    )\n\n\treturn prepare_update_model(nothing, meta, cfg, func_indices, mop, scal, x_it, sdb, ac; ensure_fully_linear, kwargs...)\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"Usually, prepare_update_model would only accept a model as its first argument. Because of the trick from above, we actually allow nothing, too.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"\"\"\"\n    _consume_points(data_base, poised_points, poised_indices, candidate_indices)\n\nHelper to return array of database indices for `poised_points` and\n`poised_indices`. Add result to database if index is -1.\n`candidate_indices` are the database indices of the points from the trust region.\n\"\"\"\nfunction _consume_points( db, poised_points, poised_indices, candidate_indices, lb, ub )\n    interpolation_indices = Int[]\n    w = ub .- lb\n    for (i,ind) in enumerate(poised_indices)\n        if ind < 0\n            # we need an additional new site\n            # every p ∈ `poised_points` was sampled with respect to [0,1]^n\n            # supposing `lb,ub` are with respect to right trust region, `unscale`\n            # puts `p` into that trust region (w.r.t. to global internal scaling)\n            new_db_id = new_result!(db, _unscale_lb_w(poised_points[i], lb, w))\n            push!(interpolation_indices, new_db_id)\n        else\n            # we could recycle a candidate point\n            push!(interpolation_indices, candidate_indices[ind])\n        end\n    end\n    return interpolation_indices\nend\n\nfunction _scale_poly_basis( poised_basis, lb, ub )\n    # we modify the basis so that the input is scaled to [0,1]^n with respect to\n    # the enlarged trust region bounds, because the poisedness algos sought points there\n    poly_vars = variables( poised_basis[1] )\n    scaling_poly = get_scaling_poly( poly_vars, lb, ub )\n\n    zero_pol = sum( 0 .* poly_vars ) # TODO remove once https://github.com/JuliaAlgebra/DynamicPolynomials.jl/issues/92 is fixed\n\n    return [ subs(p, poly_vars => scaling_poly) + zero_pol for p in poised_basis ]\nend\n\nfunction prepare_update_model( mod :: Union{Nothing, LagrangeModel},\n    meta :: LagrangeMeta, cfg :: LagrangeConfig, func_indices,\n    mop, scal, x_it,\n    sdb, algo_config;\n    ensure_fully_linear = true, kwargs... )\n\n    @logmsg loglevel2 \"Building LagrangeModel for $(func_indices).\"\n    x_scaled = get_x_scaled( x_it )\n    n_vars = length(x_scaled)\n\n    x_index = get_x_index( x_it, func_indices )\n\n    db = get_sub_db( sdb, func_indices )\n\n    Δ = get_delta( x_it )\n\n    lb, ub = local_bounds(scal, x_scaled, Δ * cfg.θ_enlarge )\n\n    if cfg.optimized_sampling\n        # Find points in current trust region …\n        candidate_indices = [x_index; results_in_box_indices( db, lb, ub, [x_index,] )]\n        # … and scale them to [0,1]^n\n        candidate_points = [_scale(ξ, lb, ub) for ξ in get_site.(db, candidate_indices)]\n\n        # Get a poised set and lagrange basis from the candidates\n        poised_points, poised_basis, poised_indices = get_poised_set(\n            meta.canonical_basis, candidate_points;\n            solver = cfg.algo1_solver, max_solver_evals = cfg.algo1_max_evals\n        )\n\n        fully_linear = false\n        # Make set even better\n        if ensure_fully_linear || !cfg.allow_not_linear\n            ### We would like to keep x if possible\n            skip_indices = let l = findfirst( i -> i == 1, poised_indices );\n                isnothing(l) ? [] : [l,]\n            end\n\n            poised_points, poised_basis, indices_2 = make_set_lambda_poised(\n                poised_basis, poised_points;\n                LAMBDA = cfg.LAMBDA, solver = cfg.algo2_solver,\n                max_solver_evals = cfg.algo2_max_evals, skip_indices\n            )\n\n            # if some i ∈ `indices_2` is equal -1 then it is a new point and we keep the negative index\n            # else it is an index of a p ∈ `poised_points` which should be kept. then:\n            # `p == poised_points[ i ]` and the index of `p` in candidates is `poised_indices[i]`\n            poised_indices = [ i < 0 ? i : poised_indices[i] for i = indices_2 ]\n            fully_linear = true\n        end\n\n        # if needed (∀ i ∈ poised_indices with i == -1) put results into sub database `db`\n        # and get database indices needed for interpolation\n        interpolation_indices = _consume_points( db, poised_points, poised_indices, candidate_indices, lb, ub )\n\n        return LagrangeMeta(;\n            interpolation_indices,\n            canonical_basis = meta.canonical_basis,\n            lagrange_basis = poised_basis,\n            fully_linear\n        )\n\n    else\n        # unoptimized sampling: we only look for a good point set once\n        # in the very first iteration and store the basis and the points\n        # in the meta data which is then passed through in subsequent iterations\n        lpoints, lbasis = if isnothing(meta.lagrange_basis)\n            candidate_points = [ fill(.5, n_vars) ]\n            lagrange_points, lagrange_basis, _ = get_lambda_poised_set(\n                meta.canonical_basis, candidate_points;\n                solver1 = cfg.algo1_solver, solver2 = cfg.algo2_solver,\n                max_solver_evals1 = cfg.algo1_max_evals, max_solver_evals2 = cfg.algo2_max_evals,\n                LAMBDA = cfg.LAMBDA )\n\n            lagrange_points, lagrange_basis\n        else\n            meta.stamp_points, meta.lagrange_basis\n        end\n\n        candidate_indices = [x_index,]\n        lindices = fill(-1, length(lpoints))\n\n        # check if x (scaled to [0,1] wrt trust region bounds) is center of `lpoints`\n        #src TODO does using `≈` make problems for small trust region radii? `==` always fails\n        x_s = _scale(x_scaled, lb, ub)\n        x_in_points_index = findfirst(χ -> χ ≈ x_s, lpoints )\n        if !isnothing(x_in_points_index)\n             lindices[ x_in_points_index ] = 1\n        end\n\n        interpolation_indices = _consume_points( db, lpoints, lindices, candidate_indices, lb, ub )\n\n        return LagrangeMeta(;\n            interpolation_indices,\n            lagrange_basis = lbasis,\n            stamp_points = lpoints,\n            fully_linear = true\n        )\n    end\nend#function","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The improvement preparation enforces a Λ-poised set:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function prepare_improve_model(mod :: Union{Nothing, LagrangeModel},\n    meta :: LagrangeMeta, cfg :: LagrangeConfig, func_indices,\n    mop, scal, x_it,\n    sdb, algo_config;\n    kwargs... )\n    return prepare_update_model( mod, meta, cfg, func_indices, mop, scal, x_it, sdb, algo_config; ensure_fully_linear = true, kwargs...)\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"Now, in the 2-phase construction process, first all prepare_ functions are called for all surrogate models. Then, the unevaluated results are evaluated and we can proceed with the model building. As before, _init_model simply delegates work to update_model. \nNot much is left to do, only to retrieve the correct values from the database to use as coefficients. We also store the gradient (vector of polynomials) for each basis polynomial.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function init_model(\n    meta :: LagrangeMeta, cfg :: LagrangeConfig, func_indices,\n    mop, scal, x_it,\n    sdb, algo_config;\n    kwargs...)\n\n\treturn update_model( nothing, meta, cfg, func_indices, mop, scal, x_it, sdb, algo_config )\nend\n\nfunction update_model( mod :: Union{Nothing, LagrangeModel},\n    meta :: LagrangeMeta, cfg :: LagrangeConfig, func_indices,\n    mop, scal, x_it,\n    sdb, algo_config;\n    kwargs... )\n\n    db = get_sub_db( sdb, func_indices )\n    coeff = get_value.(db, meta.interpolation_indices)\n\n    Δ = get_delta( x_it )\n    x_scaled = get_x_scaled( x_it )\n    lb, ub = local_bounds(scal, x_scaled, Δ * cfg.θ_enlarge )\n\n    # make polynomial basis act on current trust region instead of [0,1]^n\n    scaled_basis = _scale_poly_basis( meta.lagrange_basis, lb, ub )\n    return LagrangeModel(;\n        coeff, fully_linear = meta.fully_linear,\n        basis = scaled_basis,\n        grads = [ differentiate( p, variables(p) ) for p in scaled_basis ]\n    ), meta,\n    num_outputs( func_indices )\nend\n\nfunction improve_model(\n    mod :: Union{Nothing, LagrangeModel},\n    meta :: LagrangeMeta, cfg :: LagrangeConfig, func_indices,\n    mop, scal, x_it,\n    sdb, algo_config;\n    kwargs... )\n    return update_model( mod, meta, cfg, func_indices, mop, scal, x_it, sdb, algo_config )\nend","category":"page"},{"location":"LagrangeModel/#Evaluation","page":"LagrangeModels","title":"Evaluation","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The evaluation of some output is","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"sum_i=1^p c_i l_i( x )","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"where p = dim Π_n^d.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function _eval_poly_vec( poly_vec, x )\n    return [ p(x) for p in poly_vec ]\nend\n\nfunction eval_models( lm :: LagrangeModel, scal :: AbstractVarScaler, x̂ :: Vec, ℓ )\n    return sum( c[ℓ] * p(x̂) for (c,p) in zip( lm.coeff, lm.basis ) )\nend\n\nfunction eval_models( lm :: LagrangeModel, scal :: AbstractVarScaler, x̂ :: Vec )\n    return sum( c * p(x̂) for (c,p) in zip( lm.coeff, lm.basis ) )\nend\n\nfunction get_gradient( lm :: LagrangeModel, scal :: AbstractVarScaler, x̂ :: Vec, ℓ )\n    sum( c[ℓ] * _eval_poly_vec(p,x̂) for (c,p) in zip( lm.coeff, lm.grads ) )\nend\n\nfunction get_jacobian( lm :: LagrangeModel, scal :: AbstractVarScaler, x_scaled :: Vec, rows = nothing )\n    no_out = num_outputs(lm)\n    indices = if isnothing(rows) 1:no_out else rows end\n    grad_evals = [ _eval_poly_vec(p,x_scaled) for p in lm.grads ]\n    T = promote_type( eltype(lm.coeff[1]), eltype(x_scaled) )\n    J = Matrix{T}(undef, length(indices), length(x_scaled))\n    for ℓ=indices\n        J[ℓ,:] = sum( c[ℓ] * g for (c,g) in zip( lm.coeff, grad_evals) )\n    end\n    return J\n    #return transpose( hcat( (sum( c[ℓ] * g for (c,g) in zip( lm.coeff, grad_evals) ) for ℓ = 1 : no_out)... ) )\nend","category":"page"},{"location":"LagrangeModel/#lagrange_summary","page":"LagrangeModels","title":"Summary & Quick Examples","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"To use the default configuration for a scalar objective f do\nadd_objective!(mop, f, LagrangeConfig())\nFor a vector valued objective do\nadd_vector_objective!(mop, f, LagrangeConfig(); n_out = 2)\nIf you want a linear polyonmial only:\nadd_objective!(mop, f, LagrangeConfig(;degree=1))\nBy default, a new interpolation set is built in every iteration. To use a \"stamp\" instead, turn of optimized sampling:\nadd_objective!(mop, f, LagrangeConfig(;optimized_sampling=true))","category":"page"},{"location":"LagrangeModel/#Complete-usage-example","page":"LagrangeModels","title":"Complete usage example","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"using Morbit\nMorbit.print_all_logs()\nmop = MixedMOP(3)\n\nF = x -> [ sum( ( x .- 1 ).^2 ); sum( ( x .+ 1 ).^2 ) ]\n\nadd_vector_objective!( mop, F, LagrangeConfig() )\nadd_objective!( mop, F; model_cfg = LagrangeConfig() )\n\nx_fin, f_fin, _ = optimize( mop, [-π, ℯ, 0])","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"This page was generated using Literate.jl.","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/examples/example_two_parabolas.jl\"","category":"page"},{"location":"example_two_parabolas/#Two-Parabolas","page":"Two Parabolas","title":"Two Parabolas","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"The “two parabolas” problem in two dimensions reads as","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"    min_𝐱  X \n    beginbmatrix f₁(mathbfx)  f₂(mathbfx) endbmatrix =\n    min_mathbfx  X\n    beginbmatrix\n    (x₁ - 1)² + (x₂ - 1)² \n    (x₁ + 1)² + (x₂ + 1)²\n    endbmatrix","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"It is unconstrained if the feasible set is X = ℝ^2. The individual minima 11 and -1-1 are such that (in the unconstrained case) the global Pareto Set is","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"mathcalP_S =  mathbfx  ℝ^2  x₁ = x₂  -1 le x₁ x₂ le 1  ","category":"page"},{"location":"example_two_parabolas/#Solve-using-Exact-Functions","page":"Two Parabolas","title":"Solve using Exact Functions","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"The gradients are easily calculated as","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"nabla f_1 (mathbf x) = 2 beginbmatrix\nx_1 -1  x_2 - 1 endbmatrix \nnabla f_2 (mathbf x) = 2 beginbmatrix\nx_1 +1  x_2 + 1 endbmatrix ","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"We can provide them to the solver to find a critical point:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"using Morbit\n\nf₁ = x -> sum( (x .- 1).^2 )\nf₂ = x -> sum( (x .+ 1).^2 )\n∇f₁ = x -> 2 .* ( x .- 1 )\n∇f₂ = x -> 2 .* ( x .+ 1 )\n\nmop = MOP(2);  # problem with 2 variables\nadd_exact_objective!(mop, f₁; gradients = ∇f₁ )\nadd_exact_objective!(mop, f₂, gradients = ∇f₂ )\n\n#  starting point\nx₀ = [ -π ;  2.71828 ]\n\n#  `optimize` will return parameter and result vectors as well\n#  as an return code and the evaluation database:\nx, fx, ret_code, db, _ = optimize( mop, x₀;\n    max_iter = 20,\n);\nx","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"Hopefully, x is critical, i.e., x[1] ≈ x[2].","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"note: Note\nTo print more information on what the solver is doing, you can use the verbosity keyword argument. Or you can use the Logging module:import Logging: global_logger, ConsoleLogger\nglobal_logger( ConsoleLogger( stderr, Morbit.loglevel4;\n    meta_formatter = Morbit.morbit_formatter ) )loglevel4 is the most detailed and loglevel1 is least detailed. Morbit.print_all_logs() is a convenient shorthand.","category":"page"},{"location":"example_two_parabolas/#Plotting-Iteration-Sites","page":"Two Parabolas","title":"Plotting Iteration Sites","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"Let's retrieve the iteration sites. We convert to Tuples for easier plotting.","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"iter_sites = [ Tuple(iter.x) for iter=db.iter_data ]","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"For Plotting we use CairoMakie","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"using Makie, CairoMakie\n\n#  Pareto Set ≙ line from (-1,-1) to (1,1)\nfig, ax, _ = lines( [(-1,-1),(1,1)];\n    color = :blue, linewidth = 2,\n    figure = (resolution = (600, 600),)\n)\n\n#  Plot the iteration sites:\nlines!(iter_sites)\nscatter!(iter_sites;\n    color = LinRange(0, 1, length(iter_sites)),\n    colormap = :winter\n)\n\n#  Plot function contours\nY = X = LinRange(-4, 4, 100)\nZ₁ = [ f₁([x;y]) for x ∈ X, y ∈ X ]\nZ₂ = [ f₂([x;y]) for x ∈ X, y ∈ X ]\nlevels = [ i.^2 for i = LinRange(.1, 6, 6) ]\ncontour!(X,Y,Z₁; colormap = :greens, levels = levels, linewidth = .5 )\ncontour!(X,Y,Z₂; colormap = :heat, levels = levels, linewidth = .5 )\n\n#  Show the plot:\nax.title[] = \"Pareto Set and Iterates.\"\nax.xgridvisible[] = false\nax.ygridvisible[] = false\n\nfig","category":"page"},{"location":"example_two_parabolas/#Solving-using-RBF-Surrogates","page":"Two Parabolas","title":"Solving using RBF Surrogates","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"Suppose now that we do not have access to the objective gradients and that the objectives also take some time to evaluate. In this situation, we could try to model them using surrogate models. To use radial basis function models, pass an RbfConfig when specifying the objective:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"mop_rbf = MOP(2)\n\n#  Define the RBF surrogates\nrbf_cfg = RbfConfig(\n    kernel = :inv_multiquadric\n)\n#  Add objective functions to `mop_rbf`\nadd_objective!(mop_rbf, f₁; model_cfg = rbf_cfg, n_out = 1 )\n#  Or use the default configuration via shorthand:\nadd_rbf_objective!(mop_rbf, f₂)\n\n#  only perform 10 iterations\nac = AlgoConfig( max_iter = 10 )\nx, fx, ret_code, db, _ = optimize( mop_rbf, x₀; algo_config = ac )\nx\n\nit_sites_rbf = [ Tuple(iter.x) for iter in db.iter_data ]\nlines!(it_sites_rbf) #hide\nscatter!(it_sites_rbf; color = :orange) #hide\nnothing #hide","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"The iteration sites are the orange circles:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"fig #hide","category":"page"},{"location":"example_two_parabolas/#Different-Starting-Points-and-Recycling-Data","page":"Two Parabolas","title":"Different Starting Points and Recycling Data","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"The method could converge to different points depending on the starting point. We can pass the evaluation data from previous runs to facilitate the construction of surrogate models:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"mop_rbf = MOP(2); #hide\n#  add objective functions to `mop_rbf` #hide\nadd_rbf_objective!(mop_rbf, f₁); #hide\nadd_rbf_objective!(mop_rbf, f₂); # hide\n\n#  an array of well spread points in [-4,4]² #hide\nX =[ #hide\n [-4.0, -4.0], #hide\n [3.727327839472812, 3.8615291196035457], #hide\n [3.804712690019901, -3.9610212058521235], #hide\n [-0.14512898384374573, -0.005775390168885508], #hide\n [-3.775315499879552, 3.8150054323309064], #hide\n [1.714228746087743, 1.8435786475209621], #hide\n [-1.9603720505875337, -2.0123206708499275], #hide\n [3.9953803225349187, -0.47734576293976794], #hide\n [-3.9944468955728745, 0.49857343385493635], #hide\n [-1.0455585089057458, 2.735699160002545] #hide\n]; #hide\nnothing #hide","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"Suppose, X is a list of different points (a Vector{<:Vector{<:Real}}) in ℝ².","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"#  A dict to associate starting and end points:\nstart_fin_points = Dict{Tuple{Float64,Float64},Tuple{Float64,Float64}}();\n#  To re-cycle the database, we have to untransform it","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"at the end of each optimization loop:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"ac = AlgoConfig( max_iter = 10, untransform_final_database = true )\n#  Now perform several runs:\ndb₀ = nothing # initial database can be `nothing`\nfor x₀ ∈ X\n    global db₀, start_fin_points\n    x_fin, fx_fin, re_code, db₀, _ = optimize(\n        mop_rbf, x₀;\n        algo_config = ac, populated_db = db₀\n    )\n    #  add points to dict\n    start_fin_points[Tuple(x₀)] = Tuple(x_fin)\nend\n#%%","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"Plotting:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"fig, ax, _ = lines( [(-1,-1),(1,1)];\n    color = :blue, linewidth = 2,\n    figure = (resolution = (600, 600), ),\n    axis = (title=\"Different Starting Points\",),\n)\n\nfor (k,v) in start_fin_points\n    lines!( [k, v]; color = :lightgray )\nend\n\nscatter!( collect(keys(start_fin_points)); color = :green )\nscatter!( collect(values(start_fin_points)); color = :lightblue )\n\nfig #hide","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"In the plot, the green points show the starting points and the lightblue circles show the final iterates:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"This page was generated using Literate.jl.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/examples/constraints.jl\"","category":"page"},{"location":"constraints/#Constrained-Optimization","page":"Constraints","title":"Constrained Optimization","text":"","category":"section"},{"location":"constraints/#Box-Constraints","page":"Constraints","title":"Box Constraints","text":"","category":"section"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Box constraints are supported and treated as \"un-relaxable\". The true problem functions won't be evaluated outside of global box constraints.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"The easiest way to define box constraints is by calling the MOP constructor with a lower bound vector and an upper bound vector.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"n_vars = 2\nlb = [-1.0, -2.0]\nub = [3.0, 4.0]\nmop = MOP(lb, ub)","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"If the problem is fully finitely box constrained, i.e., all variables are constrained to finite intervals, then the algorithm internally scales the global domain to the unit hypercube 01^n and the trust region radius is defined with respect to the scaled domain.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Alternatively, the problem can be set up similarly to how its done with MathOptInterface:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"mop = MOP()\n\nvar_1 = Morbit.add_variable!(mop)\nMorbit.add_lower_bound!(mop, var_1, -1.0)\nMorbit.add_upper_bound!(mop, var_1, 3.0)\n\nvar_2 = Morbit.add_variable!(mop)\nMorbit.add_lower_bound!(mop, var_2, -2.0)\nMorbit.add_upper_bound!(mop, var_2, 4.0)","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Or, if the variables have not been added manually:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"mop = MOP( n_vars )\nvars = Morbit.var_indices(mop)\n\nMorbit.add_lower_bound!(mop, vars[1], -1.0)\nMorbit.add_upper_bound!(mop, vars[1], 3.0)\n\nMorbit.add_lower_bound!(mop, vars[2], -2.0)\nMorbit.add_upper_bound!(mop, vars[2], 4.0)","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"To delete the bound on a variable, use del_lower_bound!(mop, var_index) or del_upper_bound!(mop, var_index). \nThe bound vectors can be inspected with full_lower_bounds and full_upper_bounds.","category":"page"},{"location":"constraints/#Linear-Constraints","page":"Constraints","title":"Linear Constraints","text":"","category":"section"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Linear constraints are supported, but treated as \"relaxable\", that is, the true problem functions might be evaluated outside of the global feasible set. In theory, the original trust region algorithm supports any convex constraints natively. However, it is difficult to check for convexity and the constraints also have to be supported by the inner solver for the descent step calculation. For this reason, only linear constraints are passed to the inner solver without modification (except possibly scaling).","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Internally, a MOP stores linear constraints as MOI.VectorAffineFunctions. They also can be added as such, using the internal _add_eq_constraint! or _add_ineq_constraint! method:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"const MOI = Morbit.MOI\n# x₂ ≤ 4 - x₁   ⇔   x₁ + x₂ - 4 ≤ 0\nx1_term = MOI.VectorAffineTerm(1, MOI.ScalarAffineTerm(1, vars[1]))\nx2_term = MOI.VectorAffineTerm(1, MOI.ScalarAffineTerm(1, vars[2]))\nlin_const = MOI.VectorAffineFunction([x1_term, x2_term], [-4,])\nc1 = Morbit._add_ineq_constraint!(mop,lin_const)","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"It is much easier to provide matrices:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"# x₂ ≤ x₁ + 3   ⇔  -x₁ + x₂ - 3 ≤ 0\nc2 = add_ineq_constraint!(mop, [-1 1], [-3])","category":"page"},{"location":"constraints/#Nonlinear-Constraints","page":"Constraints","title":"Nonlinear Constraints","text":"","category":"section"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Relaxable nonlinear constraints are supported via an algorithm extension. To add them to the model, the add_nl_eq_constraint! and add_nl_ineq_constraint! methods can be used. These methods work just like the add_objective! method. The constraint functions have to be reformulated so as to conform to g(x)  0. For example, if want to add the constraint x₂  (x₁-1)² - 2, we have to add the function g(x) = (x₁-1)² - x₂ - 2.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"c3 = add_nl_ineq_constraint!(\n\tmop, x -> (x[1] - 1)^2 - x[2] - 2;\n\tn_out = 1, model_cfg = ExactConfig()\n)","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"As can be seen, the same mandatory keyword arguments (n_out and model_cfg) are required as for objectives. The constraint with index c3 will be evaluated exactly and by default its derivatives are calculated using automatic differentiation. First order derivative functions could also be provided with the gradients or jacobian keyword arguments.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"We also support inexact constraint gradients! Just like with objectives, ask for a derivative surrogate model with the model_cfg keyword. For scalar functions, there are also shorthands:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"add_exact_nl_eq_constraint and add_exact_nl_ineq_constraint\nadd_rbf_nl_eq_constraint and add_rbf_nl_ineq_constraint\nadd_lagrange_nl_eq_constraint and add_lagrange_nl_ineq_constraint\nadd_taylor_nl_eq_constraint and add_taylor_nl_ineq_constraint.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"# x₁²+x₂²-10 ≤ 0\nc4 = add_rbf_nl_ineq_constraint!(mop, x -> sum(x.^2)-10)","category":"page"},{"location":"constraints/#Optimization","page":"Constraints","title":"Optimization","text":"","category":"section"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"For the problem to be setup completely, objectives are still missing:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"o1 = add_lagrange_objective!(mop, x -> sum( (x .- 1).^2 ) )\n#o2 = add_taylor_objective!(mop, x -> sum( (x .- 1).^2 ) )","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Now, we can call optimize as usual. The initial vector x0 must not necessarily be feasible for the nonlinear constraints. (ATM it must be feasible for the box constraints.) If it is not feasible, then the first iteration will enter the so called \"restoration\" procedure. At the moment, this procedure is very expensive, as the true constraints are used by NLopt to reduce the constraint violation.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"x0 = [-0.8, 1.7]\nx, fx, ret, sdb, id, filter = optimize(mop, x0; max_iter = 100, verbosity = 2);\nnothing #hide","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Constraint values can be either be calculated …","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"# linear eq, linear ineq constraint values:\nMorbit.eval_linear_constraints_at_unscaled_site( x, mop )\n# nonlinear ineq constraint values\nMorbit.eval_nl_ineq_constraints_to_vec_at_unscaled_site( mop, x )","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"… or extracted from the final AbstractIterate object id:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"# linear inequality constraint values & nonlinear inequality values:\nid.l_i, id.c_i","category":"page"},{"location":"constraints/#Results","page":"Constraints","title":"Results","text":"","category":"section"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Let's plot everything …","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"using CairoMakie\nusing CairoMakie.GeometryBasics","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"First, the box constraints","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"fig, ax, _ = poly( Point2f[ Tuple(lb), (ub[1], lb[2]), Tuple(ub), (lb[1], ub[2]) ],\n\tcolor = RGBAf(0,0,0,0), strokecolor = :blue, strokewidth = 2\n)\n\nax.aspect = DataAspect() #src","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Now, the constraint boundaries:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"xs = LinRange(lb[1], ub[1], 50)\n\ny1 = - xs .+ 4\ny2 = xs .+ 3\ny3 = (xs .- 1).^2 .- 1\nlines!(xs,y1; color = RGBf(204/255,51/255,1), label = \"c1\")\nlines!(xs,y2; color = RGBf(204/255,0,153/255), label = \"c2\" )\nlines!(xs,y3; color = RGBf(102/255,0,51/255), label = \"c3\" )\n\nφ = LinRange(0,2*π,100)\nx4 = sqrt(10) .* cos.(φ)\ny4 = sqrt(10) .* sin.(φ)\nlines!(x4,y4, label = \"c4\")","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"And the constraint interior:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"xs = LinRange(lb[1], ub[1], 300)\nys = LinRange(lb[2], ub[2], 300)\nθ = function (x1,x2)\n\tconstraint_vector = [\n\t\tlb[1] - x1;\n\t\tlb[2] - x2;\n\t\tx1 - ub[1];\n\t\tx2 - ub[2];\n\t\tx1 + x2 - 4;\n\t\t-x1 + x2 - 3;\n\t\t(x1 - 1)^2 - x2 - 1;\n\t\tx1^2 + x2^2 - 10\n\t]\n\tif maximum(constraint_vector) <= 0\n\t\treturn 0\n\telse\n\t\treturn 1\n\tend\nend\nzs = [θ(x,y) for x = xs, y=ys]\nimage!(xs,ys,zs; colormap = [RGBAf(0,0,0,0.2), RGBAf(0,0,0,0)])","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Finally, plot the unconstrained Pareto set (the line connecting (-1,-1) and (1,1)) as well the iterates:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"lines!([(-1,-1),(1,1)], color = :green, label = \"PS\")\n\nx_iter = [ Tuple(iter.x) for iter = sdb.iter_data]\nscatter!(x_iter, color = :red, markersize = 5 )\nlines!(x_iter, color = :orange)\n\naxislegend()\nfig","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"This page was generated using Literate.jl.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/custom_logging.jl\"","category":"page"},{"location":"custom_logging/#Printing-Debug-Info","page":"Pretty Printing","title":"Printing Debug Info","text":"","category":"section"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"We provide a custom formatter method and define our own log levels. The user can choose, how much information is printed and it should look nicer this way.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Log messages are only displayed if they have a LogLevel that is ≥ than a minimum log-level defined for the current logger. The current minimum log-level can be determined with","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Logging.min_enabled_level( Logging.current_logger() )","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"For more information see the docs. Usually, the minimum log level is -1.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"We have the following LogLevels and they can be referred to as Morbit.loglevel1 ect.:","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"const loglevel1 = LogLevel(-1);\nconst loglevel2 = LogLevel(-2);\nconst loglevel3 = LogLevel(-3);\nconst loglevel4 = LogLevel(-4);\nnothing #hide","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"The can be made visible by setting one of these levels with a custom logger. For example, to see the most detailled messages, do something like this:","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"logger = Logging.ConsoleLogger( stderr, Morbit.loglevel4 )\nLogging.global_logger(logger)","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Or use with_logger(logger) do … end to leave the global logger unchanged.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"For prettier output, we define custom colors and indented prefixes:","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"const printDict = Dict(\n    loglevel1 => (:blue, \"Morbit\"),\n    loglevel2 => (:cyan, \"Morbit \"),\n    loglevel3 => (:green, \"Morbit  \"),\n    loglevel4 => (:green, \"Morbit   \")\n)","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"These are used in the morbit_formatter. The morbit_formatter can be enabled for a logger, such as Logging.ConsoleLogger, by passing the keyword argument meta_formatter, i.e.,","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Logging.ConsoleLogger( stderr, Morbit.loglevel4; meta_formatter = morbit_formatter )","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Note, that morbit_formatter is exported.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"function morbit_formatter(level::LogLevel, _module, group, id, file, line)\n    @nospecialize\n\tglobal printDict\n    if level in keys(printDict)\n        color, prefix = printDict[ level ]\n        return color, prefix, \"\"\n    else\n        return Logging.default_metafmt( level, _module, group, id, file, line )\n    end\nend\n\nfunction get_morbit_logger( level = Morbit.loglevel4 )\n    Logging.ConsoleLogger( stderr, level; meta_formatter = morbit_formatter )\nend","category":"page"},{"location":"custom_logging/#Shorthand-Function","page":"Pretty Printing","title":"Shorthand Function","text":"","category":"section"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"The following (unexported) function sets the global logger to print everything:","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"function print_all_logs()\n    Logging.global_logger( get_morbit_logger() )\nend","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"This page was generated using Literate.jl.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/models/RbfModel.jl\"","category":"page"},{"location":"RbfModel/#Radial-Basis-Function-Surrogate-Models","page":"RbfModels","title":"Radial Basis Function Surrogate Models","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"This file is automatically generated from source code. For usage examples refer to Summary & Quick Examples.","category":"page"},{"location":"RbfModel/#Intro-and-Prerequisites","page":"RbfModels","title":"Intro and Prerequisites","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"We want to offer radial basis function (RBF) surrogate models (implementing the AbstractSurrogate interface). To this end, we leverage the package RadialBasisFunctionModels.jl. A scalar RBF model consists of a n-variate Polynomial and linear combination of shifted radial kernels. For more information, see the documentation of RadialBasisFunctionModels.jl.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"import RadialBasisFunctionModels\nconst RBF = RadialBasisFunctionModels\n\nusing LinearAlgebra: qr, Hermitian, cholesky, inv, I, givens, diag","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The polyonmials will have a degree of at most 1. To construct “good” linear polynomials, we need to make sure to have construction sites that span the decision space well. Such a set of construction sites is called Λ-poised or sufficiently affinely independent. The file AffinelyIndependentPoints.jl implements some helpers to find suitable points as described by Wild et. al.[wild_diss]","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"include(\"AffinelyIndependentPoints.jl\")","category":"page"},{"location":"RbfModel/#Surrogate-Interface-Implementations","page":"RbfModels","title":"Surrogate Interface Implementations","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The model used in our algorithm simply wraps an interpolation model from the RBF package.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"@with_kw struct RbfModel{R} <: AbstractSurrogate\n\tmodel :: R\n\n\t# indicator: is the model fully linear?\n\tfully_linear :: Bool = false\nend\n\nfully_linear( rbf :: RbfModel ) :: Bool = rbf.fully_linear\nnum_outputs( rbf :: RbfModel ) = rbf.model.num_outputs\n\nfunction set_fully_linear!(rbf :: RbfModel, val :: Bool )\n\trbf.fully_linear = val\n\treturn nothing\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"We offer a large range of configuration parameters in the RBFConfig, which implements a AbstractSurrogateConfig.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"\"\"\"\n    RbfConfig(; kwarg1 = val1, … )\n\nConfiguration type for local RBF surrogate models.\n\n$(FIELDS)\n\n\"\"\"\n@with_kw struct RbfConfig <: AbstractSurrogateConfig\n\t\"RBF kernel (Symbol), either `:cubic`, `:inv_multiquadric`, `:multiquadric`, `:exp` or `:thin_plate_spline`.\"\n\tkernel :: Symbol = :inv_multiquadric\n\n\t\"RBF shape paremeter, either a number or a string containing `Δ`.\"\n\tshape_parameter :: Union{String, Float64} = NaN\n\n\t\"Degree of polynomial attached to RBF. `-1` means no polynomial.\"\n\tpolynomial_degree :: Int64 = 1;\n\n\t\"Local enlargment factor of trust region for sampling.\"\n\tθ_enlarge_1 :: Float64 = 2\n\n\t\"Maximum enlargment factor of maximum trust region for sampling.\"\n\tθ_enlarge_2 :: Float64 = 2\n\n\t\"Sampling parameter to generate Λ-poised set. The higher, the more poised.\"\n\tθ_pivot :: Float64 = 1 / (2 * θ_enlarge_1)\n\n\t\"Parameter for 2nd sampling algorithm to ensure boundedness of Cholesky factors.\"\n\tθ_pivot_cholesky :: Float64 = 1e-7\n\n\t\"Require models to be fully linear in each iteration.\"\n\trequire_linear :: Bool = false\n\n\t\"Maximum number of training sites. `-1` is reset to `2n+1`.\"\n\tmax_model_points :: Int64 = -1 # is probably reset in the algorithm\n\t\"Sample new sites to always use the maximum number of points.\"\n\tuse_max_points :: Bool = false\n\n\t\"Whether or not to re-construct the training set in each iteration.\"\n\toptimized_sampling = true\n\n\t\"Maximum number of objective evaluations.\"\n\tmax_evals :: Int64 = typemax(Int64)\n\n\t@assert θ_enlarge_1 * θ_pivot ≤ 1 \"θ_pivot must be <= θ_enlarge_1^(-1).\"\n\n\t# @assert sampling_algorithm ∈ [:orthogonal, :monte_carlo] \"Sampling algorithm must be either `:orthogonal` or `:monte_carlo`.\"\n\t@assert kernel ∈ Symbol.([\"gaussian\", \"inv_multiquadric\", \"multiquadric\", \"cubic\", \"thin_plate_spline\"]) \"Kernel '$kernel' not supported yet.\"\n\n\t# Some sanity checks for the shape parameters:\n\t@assert kernel != :thin_plate_spline || ( isnan(shape_parameter) || shape_parameter % 1 == 0 && shape_parameter >= 1 ) \"Invalid shape_parameter for :thin_plate_spline.\"\n\t@assert kernel != :cubic || ( isnan(shape_parameter) || shape_parameter % 1 == 0 && shape_parameter % 2 == 1 ) \"Invalid shape_parameter for :cubic.\"\n\t@assert (isa( shape_parameter, String ) || isnan(shape_parameter)) || shape_parameter > 0 \"Shape parameter must be strictly positive.\"\n\t@assert θ_enlarge_1 >=1 && θ_enlarge_2 >=1 \"θ's must be >= 1.\"\nend\n\n_get_signature( cfg :: RbfConfig ) = ( cfg.θ_pivot, cfg.θ_enlarge_1, cfg.θ_enlarge_2, cfg.optimized_sampling)","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The required method implementations are straightforward. Note, thate we allow the models to be combined to vector functions if they share the same configuration to avoid redundant efforts whilst constructing models.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"max_evals( cfg :: RbfConfig ) :: Int = cfg.max_evals\ncombinable( cfg :: RbfConfig ) :: Bool = true","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"We also need to introduce our own implementation for isequal and hash for RbfConfigs to be combinable, see the docs too.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function Base.hash( cfg :: RbfConfig, h :: UInt )\n\treturn hash( getfield.( cfg, Tuple( fn for fn ∈ fieldnames(RbfConfig) ) ), h )\nend\nfunction Base.isequal( cfg1 :: RbfConfig, cfg2 :: RbfConfig )\n\tall( isequal( getfield(cfg1, fn), getfield(cfg2, fn) ) for fn in fieldnames( RbfConfig) )\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"To allow the user to set the shape parameter relative to the current trust region radius using a verbose string, we need this little helper function, which evaluates the string.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function parse_shape_param_string( Δ :: F, expr_str) :: F where F\n    ex = Meta.parse(expr_str)\n    sp = @eval begin\n        let Δ=$Δ\n            $ex\n        end\n    end\n\treturn sp\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The RbfMeta is used to store construction and update data for the models. To be specific, we have several inidices lists that store database indices of (potentially unevaluated) results that are later used for fitting the model.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"@with_kw mutable struct RbfMeta{F<:AbstractFloat, T} <: AbstractSurrogateMeta\n\tsignature :: Tuple{ Float64, Float64, Float64, Bool} = (-1.0, -1.0, -1.0, true)\n\tfunc_indices :: T\n\n    center_index :: Int = -1\n    round1_indices :: Vector{Int} = []\n    round2_indices :: Vector{Int} = []\n    round3_indices :: Vector{Int} = []\n    round4_indices :: Vector{Int} = []\n    fully_linear :: Bool = false\n\timproving_directions :: Vector{Vector{F}} = []\nend\n\n\nfunction get_saveable_type( :: RbfConfig, x :: AbstractVector{F}, y ) where F<:AbstractFloat\n\treturn RbfMeta{F, Nothing}\nend\n\nget_saveable( meta :: RbfMeta ) = RbfMeta(;\n\tfunc_indices = nothing,\n\tcenter_index = meta.center_index,\n\tround1_indices = meta.round1_indices,\n\tround2_indices = meta.round2_indices,\n\tround3_indices = meta.round3_indices,\n\tround4_indices = meta.round4_indices,\n\tfully_linear = meta.fully_linear,\n\timproving_directions = meta.improving_directions\n)","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"A little helper to retrieve all those indices:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _collect_indices( meta :: RbfMeta; include_x = true ) :: Vector{Int}\n\treturn [\n\t\tinclude_x ? meta.center_index : [];\n\t\tmeta.round1_indices;\n\t\tmeta.round2_indices;\n\t\tmeta.round3_indices;\n\t\tmeta.round4_indices\n\t]\nend","category":"page"},{"location":"RbfModel/#Construction","page":"RbfModels","title":"Construction","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"When an RBF model is constructed, there are three to four rounds of data collection and sampling.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"In the first round, we look within a box with bounds lb_1 and ub_2 and maximum radius Δ_1 for suitable datasites in the database db. A site is deemed \"suitable\" if its sufficiently affinely independent from the sites already collected, and the test operatornameproj_Z ξ ge θ is performed with θ as piv_val_1, an iteration dependent threshold.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The second round is much the same, but we look in a larger box with corners lb_2 and ub_2, and respect the sites we allready found.\nHence, in both cases we can make use of the following helper. Y is a matrix whose columns consists of previously found sites translated by -x and the columns of Z are orthogonal to it:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _find_suitable_points(db, lb, ub, x :: Vector{F}, x_index, piv_val;\n\talready_inspected_indices = Int[],\n\tY = Matrix{F}(undef, length(x), 0),\n\tZ = Matrix{F}(I(length(x))),\n\tn_missing = length(x),\n\tcollect_improving_directions = true\n) where F\n\n\t# Look for candidates in box …\n\tcandidate_indices = results_in_box_indices(\n\t\tdb, lb, ub, [x_index; already_inspected_indices],\n\t)\n\n\t# … and filter them to obtain affinely independent points.\n\tindex_filter = AffinelyIndependentPointFilter(;\n\t\tx_0 = x,\n\t\tseeds = get_site.(db, candidate_indices),\n\t\treturn_indices = true,\n\t\tpivot_val = piv_val,\n\t\tn = n_missing,\n\t\tp = Inf,\t# for consistency, use norm(…, Inf)\n\t\tY,Z\n\t)\n\n\tfiltered_indices = candidate_indices[ collect( index_filter ) ]\n\n\timproving_directions = if collect_improving_directions\n\t\treverse(collect(Vector{F}, eachcol(index_filter.Z)))\n\telse\n\t\tnothing\n\tend\n\n\treturn filtered_indices, improving_directions, candidate_indices, index_filter.Y, index_filter.Z\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"Now, if the right values lb_1, ub_1 and piv_val_1 are already provided, we simply forward to the helper function:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _rbf_round1(db, lb_1, ub_1, x, x_index, piv_val_1)\n\tfiltered_indices, improving_directions, candidate_indices, Y, Z = _find_suitable_points(\n\t\tdb, lb_1, ub_1, x, x_index, piv_val_1\n\t)\n\t@logmsg loglevel3 \"Found $(length(filtered_indices)) sites in first round.\"\n\treturn filtered_indices, improving_directions, candidate_indices, Y, Z\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"For round 2 we have to set the keyword arguments:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _rbf_round2(\n\tdb, lb_2, ub_2, Δ_2, x, x_index, piv_val_2,\n\tn_missing, Y, Z, candidate_indices_1\n)\n\t@logmsg loglevel3 \"Missing $(n_missing) sites still.\"\n\t@logmsg loglevel3 \"Round2: Inspect box with radius $(Δ_2) and pivot value $(piv_val_2).\"\n\n\tfiltered_indices, _ = _find_suitable_points(\n\t\tdb, lb_2, ub_2, x, x_index, piv_val_2;\n\t\talready_inspected_indices = candidate_indices_1,\n\t\tcollect_improving_directions = false,\n\t\tn_missing, Y, Z\n\t)\n\treturn filtered_indices\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"If there are still not enough data sites (n), then we perform sampling along the improving directions from round 1 (i.e., the colums of Z_1):","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _rbf_round3(db, lb_1, ub_1, Δ_1, x::Vector{F}, piv_val_1,\n\timproving_directions, max_new, n_missing, ensure_fully_linear, force_rebuild\n) where F\n\t@logmsg loglevel3 \"Round3: Still missing $(n_missing). Sampling in box of radius $(Δ_1).\"\n\n\tn_new = min(n_missing, max_new)\n\n\tnew_points = Vector{Vector{F}}(undef, n_new)\n\t_fully_linear = n_new >= n_missing\n\n\t@assert length(improving_directions) >= n_new \"There must be more improving directions than points missing.\"\n\n\tfor i = 1 : n_new\n\t\tdir = improving_directions[i]\n\t\tlen = intersect_box( x, dir, lb_1, ub_1; return_vals = :absmax )\n\t\toffset = len .* dir\n\t\tif norm( offset, Inf ) <= piv_val_1\n\t\t\t### the new point does not pass the thresholding test\n\t\t\tif ensure_fully_linear && !force_rebuild\n\t\t\t\t### If we need a fully linear model, we dismiss the inidices gathered so far …\n\t\t\t\t### … and call for a rebuild along the coordinate axis (in the caller method):\n\t\t\t\treturn nothing, nothing, nothing\n\t\t\telse\n\t\t\t\t### we include the point nonetheless,\n\t\t\t\t### but the model will not qualify as fully linear...\n\t\t\t\t_fully_linear = false\n\t\t\tend\n\t\tend\n\t\tnew_points[i] = x .+ offset\n\tend\n\n\t# by adding the points to the database at this point in time (i.e., afterwards),\n\t# we avoid requesting unnecessary results from a round 3 interrupted by rebuilding\n\tnew_indices = Vector{Int}(undef, length(new_points))\n\tfor (i,p) = enumerate(new_points)\n\t\tnew_id = new_result!( db, p, F[] )\n\t\tnew_indices[i] = new_id\n\tend\n\n\treturn new_indices, _fully_linear, improving_directions[n_new+1:end]\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"As rounds 1-3 are based on gemotric reasoning only (and do not depend on the RBF kernel), we can actually exploit the work done for previous RBF models in the same outer iteration:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _exploit_other_rbf_metas!(meta,db,sdb,meta_array)\n\tisnothing(meta_array) && return false\n\tskip_first_rounds = false\n\n\tfor other_meta in meta_array\n\t\tif other_meta isa RbfMeta && other_meta.signature == meta.signature\n\t\t\tother_db = get_sub_db(sdb, other_meta.func_indices )\n\t\t\tfor fn in [ Symbol(\"round$(i)_indices\") for i = 1: 3 ]\n\t\t\t\tthis_id_arr = getfield(meta, fn)\n\t\t\t\tempty!(this_id_arr)\n\t\t\t\tfor res_id = getfield(other_meta, fn)\n\t\t\t\t\t# transfer result from `other_db` to `db`\n\t\t\t\t\tres = get_result.(other_db, res_id)\n\t\t\t\t\tnew_res_id = ensure_contains_res_with_site!(db, get_site(res))\n\t\t\t\t\t# push! index into correct array in `meta`\n\t\t\t\t\tpush!( this_id_arr, new_res_id )\n\t\t\t\tend\n\t\t\tend\n\t\t\t# also transfer the improving directions\n\t\t\tempty!(meta.improving_directions)\n\t\t\tappend!(\n\t\t\t\tmeta.improving_directions,\n\t\t\t\tdeepcopy(other_meta.improving_directions)\n\t\t\t)\n\t\t\tmeta.fully_linear = other_meta.fully_linear\n\t\t\tskip_first_rounds = true\n\t\t\tbreak\n\t\tend\n\tend\n\n\treturn skip_first_rounds\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"Round 4 is different from rounds 1-3 in that we now have sufficiently linearly independent points and try to find additional points in the database, such that the model hessians stay bounded. The procedure is described in [wild_diss].","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _rbf_round4(db, lb_2, ub_2, x::Vector{F}, Δ, indices_found_so_far, cfg,\n) where F\n\tn_vars = length(x)\n\n\tmax_points = cfg.max_model_points <= 0 ? 2 * n_vars + 1 : cfg.max_model_points\n\n\tN = length(indices_found_so_far)\n\n\tcandidate_indices_4 = results_in_box_indices( db, lb_2, ub_2, indices_found_so_far )\n\n\tmax_tries = 10 * max_points\n\tnum_tries = 0\n\n\tround4_indices = Int[]\n\n\tif N < max_points && ( !isempty(candidate_indices_4) || cfg.use_max_points )\n\t\t@logmsg loglevel3 \"Round4: Can we find $(max_points - N) additional sites?\"\n\n\t\tchol_pivot = cfg.θ_pivot_cholesky\n\n\t\tcenters = get_site.(db, indices_found_so_far)\n\t\tφ = _get_radial_function( Δ, cfg )\n\t\tΦ, Π, kernels, polys = RBF.get_matrices( φ, centers;\n\t\t\tpoly_deg = cfg.polynomial_degree )\n\n\t\t# prepare matrices as by Wild, R has to be augmented by rows of zeros\n\t\tQ, R = qr( transpose(Π) )\n\t\tR = [\n\t\t\tR;\n\t\t\tzeros( size(Q,1) - size(R,1), size(R,2) )\n\t\t]\n\t\tZ = Q[:, N + 1 : end ] ## columns of Z are orthogonal to Π\n\n\t\t# Note: usually, Z, ZΦZ and L should be empty (if N == n_vars + 1)\n\t\tZΦZ = Hermitian(Z'Φ*Z)\t## make sure, it is really symmetric\n\t\tL = cholesky( ZΦZ ).L   ## perform cholesky factorization\n\t\tL⁻¹ = inv(L)\t\t\t## most likely empty at this point\n\n\t\tφ₀ = Φ[1,1]\n\n\t\t@logmsg loglevel3 \"Round4: Considering $(length(candidate_indices_4)) candidates.\"\n\n\t\twhile N < max_points && num_tries <= max_tries\n\n\t\t\tif !isempty( candidate_indices_4 )\n\t\t\t\tid = popfirst!( candidate_indices_4 )\n\t\t\t\t### get candidate site ξ ∈ ℝⁿ\n\t\t\t\tξ = get_site( db, id )\n\t\t\telse\n\t\t\t\tif cfg.use_max_points\n\t\t\t\t\t### there are no more sites in the db, but we **want**\n\t\t\t\t\t### to use as many as possible\n\t\t\t\t\tid = -1\n\t\t\t\t\tξ = _rand_box_point( lb_2, ub_2, F)\n\t\t\t\t\tnum_tries += 1\n\t\t\t\telse\n\t\t\t\t\tbreak\n\t\t\t\tend\n\t\t\tend\n\n\t\t\t### apply all RBF kernels\n\t\t\tφξ = kernels( ξ )\n\n\t\t\t### apply polynomial basis system and augment polynomial matrix\n\t\t\tπξ = polys( ξ )\n\t\t\tRξ = [ R; πξ' ]\n\n\t\t\t### perform Givens rotations to turn last row in Rξ to zeros\n\t\t\trow_index = size( Rξ, 1)\n\t\t\tG = Matrix(I, row_index, row_index) # whole orthogonal matrix\n\t\t\tfor j = 1 : size(R,2)\n\t\t\t\t# in each column, take the diagonal as pivot to turn last elem to zero\n\t\t\t\tg = givens( Rξ[j,j], Rξ[row_index, j], j, row_index )[1]\n\t\t\t\tRξ = g*Rξ;\n\t\t\t\tG = g*G;\n\t\t\tend\n\n\t\t\t### now, from G we can update the other matrices\n\t\t\tGᵀ = transpose(G)\n\t\t\tg̃ = Gᵀ[1 : end-1, end]\n\t\t\tĝ = Gᵀ[end, end]\n\n\t\t\tQg = Q*g̃;\n\t\t\tv_ξ = Z'*( Φ*Qg + φξ .* ĝ )\n\t\t\tσ_ξ = Qg'*Φ*Qg + (2*ĝ) * φξ'*Qg + ĝ^2*φ₀\n\n\t\t\tτ_ξ² = σ_ξ - norm( L⁻¹ * v_ξ, 2 )^2\n\t\t\t# τ_ξ (and hence τ_ξ^2) must be bounded away from zero\n\t\t\t# for the model to remain fully linear\n\t\t\tif τ_ξ² > chol_pivot\n\n\t\t\t\tif id < 0\n\t\t\t\t\tid = new_result!( db, ξ, F[] )\n\t\t\t\tend\n\t\t\t\tpush!(round4_indices, id)\t# accept the result\n\n\t\t\t\tτ_ξ = sqrt(τ_ξ²)\n\n\t\t\t\t# zero-pad Q and multiply with Gᵗ\n\t\t\t\tQ = [\n\t\t\t\t\tQ \t\t\t\t\tzeros( size(Q,1), 1);\n\t\t\t\t\tzeros(1, size(Q,2)) 1\n\t\t\t\t] * Gᵀ\n\n\t\t\t\tZ = [\n\t\t\t\t\tZ  \t\t\t\t\t\tQg;\n\t\t\t\t\tzeros(1, size(Z,2)) \tĝ\n\t\t\t\t]\n\n\t\t\t\tL = [\n\t\t\t\t\tL          zeros(size(L,1), 1) ;\n\t\t\t\t\tv_ξ'L⁻¹'   τ_ξ\n\t\t\t\t]\n\n\t\t\t\tL⁻¹ = [\n\t\t\t\t\tL⁻¹                zeros(size(L⁻¹,1),1);\n\t\t\t\t\t-(v_ξ'L⁻¹'L⁻¹)./τ_ξ   1/τ_ξ\n\t\t\t\t]\n\n\t\t\t\tR = Rξ\n\n\t\t\t\t# finally, augment basis matrices and add new kernel for next iteration\n\t\t\t\tΠ = [ Π πξ ]\n\n\t\t\t\tΦ = [\n\t\t\t\t\tΦ   φξ;\n\t\t\t\t\tφξ' φ₀\n\t\t\t\t]\n\t\t\t\tpush!( kernels, RBF.make_kernel(φ, ξ) )\n\n\t\t\t\t# assert all( diag( L * L⁻¹) .≈ 1 )\n\t\t\t\tN += 1\n\t\t\tend#if\n\t\tend#for\n\t\t@logmsg loglevel3 \"Round4: found $(length(round4_indices)) additional sites.\"\n\tend#if\n\treturn round4_indices\nend","category":"page"},{"location":"RbfModel/#Piecing-it-all-together","page":"RbfModels","title":"Piecing it all together","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The initial prepare_init_model function should return a meta object that can be used to build an initial surrogate model. We delegate the work to prepare_update_model.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function prepare_init_model( cfg :: RbfConfig, func_indices,\n\tmop, scal,\n\tid, sdb, ac;\n\tensure_fully_linear = true, kwargs...)\n\tF = eltype( get_x_scaled(id) )\n\tmeta = RbfMeta{F, typeof(func_indices)}(; signature = _get_signature( cfg ), func_indices )\n\treturn prepare_update_model(nothing, meta, cfg, func_indices, mop, scal, id, sdb, ac; ensure_fully_linear, kwargs... )\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"Usually, prepare_update_model would only accept a model as its first argument. Because of the trick from above, we actually allow nothing, too. We then make use of the _rbf_roundX methods:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function prepare_update_model( mod :: Union{Nothing, RbfModel}, meta :: RbfMeta,\n\t\tcfg, func_indices, mop, scal,\n\t\titer_data, sdb, algo_config;\n\t\tensure_fully_linear = false, force_rebuild = false, meta_array = nothing\n\t)\n\n\t!force_rebuild && @logmsg loglevel2 \"Building RBF model for $(func_indices)\"\n\n\tforce_rebuild && @logmsg loglevel2 \"Rebuilding along coordinate axes.\"\n\n\t# Retrieve current iteration information and some meta data.\n\tdb = get_sub_db( sdb, func_indices )\n\n\tfunc_index_tuple = Tuple(func_indices)\n\tΔ = get_delta(iter_data)\n\tΔ_max = get_delta_max(algo_config)\n\tx = get_x_scaled(iter_data)\n\tx_index = get_x_index(iter_data, func_index_tuple)\n\n\tF = eltype(x)\n\tn_vars = length(x)\n\n\t# By default, assume that our model is not fully linear\n\tmeta.fully_linear = false\n\n\t# Can we skip the first rounds?\n\t# (Because we already found interpolation sets for other RBFModels?)\n\tskip_first_rounds = _exploit_other_rbf_metas!(meta,db,sdb,meta_array)\n\n\t# use center as first training site ⇒ at least `n_vars` required still\n\tmeta.center_index = x_index\n\n\t# First round of sampling:\n\t### Try to find points in slightly enlarged trust region\n\tΔ_1 = F.(cfg.θ_enlarge_1 * Δ)\n\tlb_1, ub_1 = local_bounds( scal, x, Δ_1 )\n\tpiv_val_1 = F.(cfg.θ_pivot * Δ_1) # threshold value for acceptance in filter\n\n\t### `Δ_2` is the maximum allowed trust region radius and used in rounds 2 & 4\n\t### We set it here due to the `@goto` statement.\n\tΔ_2 = F.(cfg.θ_enlarge_2 * Δ_max )\n\tlb_2, ub_2 = local_bounds( scal, x, Δ_2 )\n\tpiv_val_2 = piv_val_1 # the pivot value stays the same\n\n\tskip_first_rounds && @goto round4\n\n\tif force_rebuild || !cfg.optimized_sampling\n\t\t### `force_rebuild` makes us skip the point searching procedures to …\n\t\t### … rebuild the model along the coordinate axes.\n\t\tfiltered_indices_1 = candidate_indices_1 = Int[]\n\t\timproving_directions = collect( Vector{F}, eachcol(I(n_vars)) )\n\t\tY_1 = Z_1 = nothing ## should never be used due to the `if` conditions\n\telse\n\t\tfiltered_indices_1, improving_directions, candidate_indices_1, Y_1, Z_1 = _rbf_round1(\n\t\t\tdb, lb_1, ub_1, x, x_index, piv_val_1\n\t\t)\n\tend\n\t### Store indices in meta data object:\n\tempty!(meta.round1_indices)\n\tappend!(meta.round1_indices, filtered_indices_1)\n\tempty!(meta.improving_directions)\n\tappend!(meta.improving_directions, improving_directions )\n\n\t# Second round of sampling:\n\n\t### If there are not enough sites to have a fully linear model\n\t### try to at least find more sites in maximum allowed radius `Δ_2`.\n\n\tn_missing = n_vars - length( meta.round1_indices )\n\n\tif n_missing == 0 || force_rebuild || !cfg.optimized_sampling || ensure_fully_linear || Δ ≈ Δ_max && cfg.θ_enlarge_1 == cfg.θ_enlarge_2\n\t\t@logmsg loglevel3 \"Skipping round 2.\"\n\t\tmeta.fully_linear = true\n\t\tempty!(meta.round2_indices)\n\telse\n\t\t### actually perform round 2\n\t\tfiltered_indices_2 = _rbf_round2(db, lb_2, ub_2, Δ_2, x, x_index, piv_val_2,\n\t\t\tn_missing, Y_1, Z_1, candidate_indices_1\n\t\t)\n\n\t\t### Store indices\n\t\tempty!(meta.round2_indices)\n\t\tappend!(meta.round2_indices, filtered_indices_2)\n\n\t\t@logmsg loglevel3 \"Round2: Found $(length(meta.round2_indices)) sites and model is $(meta.fully_linear ? \"\" : \"not \" )fully linear.\"\n\tend\n\n\t# Round 3:\n\t### If we still don't have enough sites, generate them\n\t### along model improving directions (from first round of sampling)\n\n\tn_missing -= length(meta.round2_indices)\n\tempty!(meta.round3_indices)\n\tif n_missing > 0\n\t\t### Take into consideration the maximum number of evaluations allowed:\n\t\tnum_objf_evals = maximum( num_evals(_get(mop, ind)) for ind in func_indices )\n\t\tnum_unevaluated = length(_missing_ids(db))\n\t\tmax_new = min( max_evals(algo_config), max_evals(cfg) ) -\n\t\t\t1 - num_objf_evals - num_unevaluated;\n\n\t\t### Perform round 3:\n\t\tnew_indices, _fully_linear, improving_directions  = _rbf_round3(\n\t\t\tdb, lb_1, ub_1, Δ_1, x, piv_val_1,\n\t\t\timproving_directions, max_new, n_missing, ensure_fully_linear, force_rebuild\n\t\t)\n\n\t\t### Update `meta`:\n\t\tif !isnothing( new_indices )\n\t\t\tappend!(meta.round3_indices, new_indices)\n\t\t\t### If round 2 did not yield any new points,\n\t\t\t### the model is (hopefully) fully linear now.\n\t\t\tmeta.fully_linear = _fully_linear && (length(meta.round2_indices) == 0)\n\t\telse\n\t\t\t### If round 3 was not successful, the model is rebuild along the coordinate axes:\n\t\t\treturn prepare_update_model(\n\t\t\t\tmod, meta, cfg, func_indices, mop, scal, iter_data, db, algo_config;\n\t\t\t\tensure_fully_linear = true, force_rebuild = true\n\t\t\t)\n\t\tend\n\tend\n\n\t@label round4\n\t# In round 4 we have found `n_vars + 1` training sites and try to\n\t# find additional points within the largest possible trust region.\n\n\tempty!(meta.round4_indices)\n\n\tif cfg.optimized_sampling\n\t\tindices_found_so_far = _collect_indices( meta )\n\n\t\tround4_indices = _rbf_round4(db,lb_2,ub_2,x,Δ,indices_found_so_far,cfg)\n\t\tappend!(meta.round4_indices, round4_indices)\n\tend\n\n\treturn meta\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"note: Note\nAt the moment, we do not store the matrices calculated in round 4 of the update procedure. This could be done to save some work when actually calculating the coefficients.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"In contrast to the old RBF mechanism, the models in RadialBasisFunctionModels sometimes accept 2 parameters for the kernel. We use this little helper, to get defaults from the shape parameter. Note, that sanity check are performed in the RbfConfig constructor.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _get_kernel_params( Δ , cfg )\n\n\tsp = if cfg.shape_parameter isa String\n\t\tparse_shape_param_string( Δ, cfg.shape_parameter )\n\telse\n\t\tcfg.shape_parameter\n\tend\n\n\tisnan(sp) && return nothing\n\n\tkernel_name = cfg.kernel\n\n\tif kernel_name == :gaussian\n\t\treturn sp\n\telseif kernel_name == :inv_multiquadric\n\t\treturn (sp, 1//2)\n\telseif kernel_name == :multiquadric\n\t\treturn (sp, 1//2)\n\telseif kernel_name == :cubic\n\t\treturn Int(sp)\n\telseif kernel_name == :thin_plate_spline\n\t\treturn Int(sp)\n\telse\n\t\treturn sp\n\tend\nend\n\nfunction _get_radial_function( Δ, cfg )\n\tkernel_params = _get_kernel_params( Δ, cfg )\n\n\treturn RBF._get_rad_func( cfg.kernel, kernel_params )\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"An improvement step consists of adding a new site to the database, along an improving direction:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function prepare_improve_model( mod :: Union{Nothing, RbfModel}, meta :: RbfMeta, cfg :: RbfConfig,\n\tfunc_indices, mop, scal, iter_data, sdb,\n\talgo_config; kwargs... )\n\n\tif !meta.fully_linear\n\t\tif isempty(meta.improving_directions)\n\t\t\t@warn \"RBF model is not fully linear, but there are no improving directions.\"\n\t\telse\n\t\t\tdb = get_sub_db(sdb, func_indices)\n\t\t\tx = get_x_scaled(iter_data)\n\t\t\tΔ = get_delta(iter_data)\n\t\t\tΔ_1 = Δ * cfg.θ_enlarge_1\n\t\t\tlb_1, ub_1 = local_bounds(scal, x, Δ_1)\n\t\t\tpiv_val_1 = Δ_1 * cfg.θ_pivot\n\n\t\t\tsuccess = false\n\t\t\tdir = popfirst!( meta.improving_directions )\n\t\t\tlen = intersect_box( x, dir, lb_1, ub_1; return_vals = :absmax )\n\t\t\toffset = len .* dir\n\t\t\tif norm( offset, Inf ) > piv_val_1\n\t\t\t\tnew_id = new_result!( db, x .+ offset )\n\t\t\t\tpush!(meta.round1_indices, new_id)\n\t\t\t\tsuccess = true\n\t\t\tend\n\n\t\t\tsuccess && @logmsg loglevel3 \"Performed an improvement step.\"\n\t\t\tif isempty( meta.improving_directions ) && success\n\t\t\t\tmeta.fully_linear = true\n\t\t\t\t@logmsg loglevel3 \"The RBF Model is now fully linear.\"\n\t\t\tend\n\t\tend\n\tend\n\treturn meta\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"Now, in the 2-phase construction process, first all prepare_ functions are called for all surrogate models. Then, the unevaluated results are evaluated and we can proceed with the model building. As before, _init_model simply delegates work to update_model.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function init_model( meta :: RbfMeta, cfg :: RbfConfig, func_indices,\n\tmop, scal, iter_data, sdb, ac; kwargs... )\n\treturn update_model( nothing, meta, cfg, func_indices, mop, scal, iter_data, sdb, ac; kwargs... )\nend\n\nfunction update_model( mod::Union{Nothing,RbfModel}, meta :: RbfMeta, cfg :: RbfConfig,\n\tfunc_indices, mop, scal, iter_data,\n\tsdb, ac;\n\tkwargs... )\n\n\tdb = get_sub_db(sdb, func_indices)\n\tΔ = get_delta(iter_data)\n\n\tkernel_params = _get_kernel_params( Δ, cfg )\n\n\t# get the training data from `meta` and the database `db`\n\ttraining_indices = _collect_indices( meta )\n\ttraining_results = get_result.( db, training_indices )\n\ttraining_sites = get_site.( training_results )\n\ttraining_values = get_value.( training_results )\n\n\tinner_model = RBF.RBFInterpolationModel( training_sites, training_values, cfg.kernel, kernel_params; save_matrices = false )\n\n\t@logmsg loglevel3 \"The model is $(meta.fully_linear ? \"\" : \"not \")fully linear.\"\n\treturn RbfModel( inner_model, meta.fully_linear ), meta\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The improvement function also simply cals the update function:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function improve_model( mod::Union{Nothing,RbfModel},meta :: RbfMeta, cfg :: RbfConfig,\n\tfunc_indices, mop, scal, iter_data,\n\tsdb, ac;\n\tkwargs... )\n\n\treturn update_model( mod, meta, cfg, func_indices, mop, scal, iter_data, sdb, ac; kwargs... )\nend","category":"page"},{"location":"RbfModel/#Evaluation","page":"RbfModels","title":"Evaluation","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"All the work is done by the inner model :)","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"\"Evaluate `mod::RbfModel` at scaled site `x̂`.\"\nfunction eval_models( mod :: RbfModel, scal :: AbstractVarScaler, x̂ :: Vec)\n\treturn mod.model( x̂ )\nend\n\n\"Evaluate output `ℓ` of `mod::RbfModel` at scaled site `x̂`.\"\nfunction eval_models( mod :: RbfModel, scal :: AbstractVarScaler, x̂ :: Vec, ℓ)\n\treturn mod.model( x̂, ℓ)\nend\n\n@doc \"Gradient vector of output `ℓ` of `mod` at scaled site `x̂`.\"\nfunction get_gradient( mod :: RbfModel, scal :: AbstractVarScaler, x̂ :: Vec, ℓ)\n    return RBF.grad( mod.model, x̂, ℓ )\nend\n\n@doc \"Jacobian Matrix of ExactModel `em` at scaled site `x̂`.\"\nfunction get_jacobian( mod :: RbfModel, scal :: AbstractVarScaler, x̂ :: Vec, rows = nothing )\n    return RBF.jac( mod.model, x̂, rows )\nend","category":"page"},{"location":"RbfModel/#rbf_summary","page":"RbfModels","title":"Summary & Quick Examples","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"To use the default configuration for a scalar objective f do\nadd_objective!(mop, f; model_cfg =  RbfConfig(), n_out = 1)\nFor a vector valued objective do\nadd_objective!(mop, f; model_cfg =  RbfConfig(), n_out = 2)\nIf you don't want to use a polynomial:\nadd_objective!(mop, f;\n  model_cfg = RbfConfig(;kernel = :cubic, polynomial_degree = -1 ),\n  n_out = 1)\nThis only works for certain kernels. polynomial_degree = 0 will add a constant term.\nTo require sampling of the maximum number of allowed model points:\nRbfConfig(;use_max_points = true)\nTo only sample along the coordinate axis:\nRbfConfig(;optimized_sampling = false)\nIf polynomial_degree == 1 the model will now be a linear interpolation model.","category":"page"},{"location":"RbfModel/#Complete-usage-example","page":"RbfModels","title":"Complete usage example","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"using Morbit\nMorbit.print_all_logs()\nmop = MixedMOP(3)\n\nF = x -> [ sum( ( x .- 1 ).^2 ); sum( ( x .+ 1 ).^2 ) ]\n\nadd_objective!(mop, f; model_cfg =  RbfConfig(), n_out = 2)\n\nx_fin, f_fin, _ = optimize( mop, [-π, ℯ, 0])","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"[wild_diss]: “Derivative-Free Optimization Algorithms For Computationally Expensive Functions”, Stefan M. Wild, 2009","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"This page was generated using Literate.jl.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/models/TaylorModel.jl\"","category":"page"},{"location":"TaylorModel/#Taylor-Polynomial-Models","page":"TaylorModels","title":"Taylor Polynomial Models","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"This file is automatically generated from source code. For usage examples refer to Summary & Quick Examples.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"We provide vector valued polynomial Taylor models of degree 1 or 2. They implement the AbstractSurrogate interface.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"We allow the user to either provide gradient and hessian callback handles or to request finite difference approximations. For using callbacks, we have TaylorConfigCallbacks. \nThere are two ways to use finite differences. The old (not recommended way) is to use TaylorConfigFiniteDiff. This uses FiniteDiff.jl and could potentially require more evaluations. \nTo make use of the new 2-phase construction procedure, use TaylorConfig and set the fields gradients and hessians to an RFD.FiniteDiffStamp. If they use the same stamp (default: RFD.CFDStamp(1,3) :: CFDStamp{3,Float64}), it should be the most efficient, because we get the gradients for free from computing the hessians.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"include(joinpath(@__DIR__,\"RecursiveFiniteDifferences.jl\"))\n\nusing .RecursiveFiniteDifferences\nconst RFD = RecursiveFiniteDifferences","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The actual model is defined only by the gradient vectors at x₀ and the Hessians (if applicable).","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"@with_kw struct TaylorModel{\n    XT <: AbstractVector{<:Real}, FXT <: AbstractVector{<:Real},\n    G <: AbstractVector{<:AbstractVector{<:Real}},\n    HT <: Union{Nothing,AbstractVector{<:AbstractMatrix{<:Real}}},\n    } <: AbstractSurrogate\n\n    # expansion point and value\n    x0 :: XT\n    fx0 :: FXT\n\n    # gradient(s) at x0\n    g :: G\n    H :: HT = nothing\n\n    num_outputs = length(fx0)\nend\n\nfully_linear( :: TaylorModel ) = true\nnum_outputs( m :: TaylorModel ) = m.num_outputs","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Note, that the derivative approximations are actually constructed for the function(s)","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"    f_ℓ  s^-1","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"if some internal transformation s has happened before. If the problem is unbounded then s = operatornameid = s^-1.","category":"page"},{"location":"TaylorModel/#Model-Construction","page":"TaylorModels","title":"Model Construction","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Because of all the possibilities offered to the user, we actually have several (sub-)implementiations of AbstractSurrogateConfig for Taylor Models.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"abstract type TaylorCFG <: AbstractSurrogateConfig end","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"We make sure, that all subtypes have a field max_evals:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"max_evals( cfg :: TaylorCFG ) = cfg.max_evals","category":"page"},{"location":"TaylorModel/#Recursive-Finite-Difference-Models","page":"TaylorModels","title":"Recursive Finite Difference Models","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Let's start by defining the recommended way of using Taylor approximations. The derivative information is approximated using a dynamic programming approach and we take care to avoid unnecessary objective evaluations.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"@doc \"\"\"\n    TaylorConfig(; degree, gradients :: RFD.CFDStamp, hessians :: RFD.CFDStamp, max_evals)\n\nConfiguration for a polynomial Taylor model using finite difference approximations of the derivatives.\nBy default we have `degree = 2` and `gradients == hessians == RFD.CFDStamp(1,2)`, that is,\na first order central difference scheme of accuracy order 3 is recursed to compute the Hessians\nand the gradients.\nIn this case, the finite difference scheme is the same for both Hessians and gradients and we profit\nfrom caching intermediate results.\n\"\"\"\n@with_kw struct TaylorConfig{\n        S1 <: RFD.FiniteDiffStamp,\n        S2 <: Union{Nothing,RFD.FiniteDiffStamp}\n    } <: TaylorCFG\n\n    degree :: Int64 = 2\n\n    gradients :: S1 = RFD.CFDStamp(1,2)\n    hessians :: S2 = gradients\n\n    max_evals :: Int64 = typemax(Int64)\n\n    @assert 1 <= degree <= 2 \"Can only construct linear and quadratic polynomial Taylor models.\"\nend\n\ncombinable( :: TaylorConfig ) = true","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The new meta type only stores database indices of sites used for a finite diff approximation in the actual construction call and is filled in the prepare_XXX methods:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"@with_kw struct TaylorIndexMeta{W1, W2} <: AbstractSurrogateMeta\n    database_indices :: Vector{Int} = Int[]\n    grad_setter_indices :: Vector{Int} = Int[]\n    hess_setter_indices :: Vector{Int} = Int[]\n    hess_wrapper :: W1 = nothing\n    grad_wrapper :: W2 = nothing\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The end user won't be interested in the wrappers, so we put nothing in there:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function get_saveable_type( :: TaylorConfig )\n    return TaylorIndexMeta{Nothing, Nothing}\nend\nget_saveable( meta :: TaylorIndexMeta ) = TaylorIndexMeta(;\n    grad_setter_indices = meta.grad_setter_indices,\n    hess_setter_indices = meta.hess_setter_indices\n)","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"And the configs should easily be available:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"export TaylorConfig, TaylorCallbackConfig","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The new construction process it is a bit complicated. We set up a recursive finite diff tree and need this little helper:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"\"Return `unique_elems, indices = unique_with_indices(arr)` such that\n`unique_elems[indices] == arr` (and `unique_elems == unique(arr)`).\"\nfunction unique_with_indices( x :: AbstractVector{T} ) where T\n\tunique_elems = T[]\n\tindices = Int[]\n\tfor elem in x\n\t\ti = findfirst( e -> all( isequal.(e,elem) ), unique_elems )\n\t\tif isnothing(i)\n\t\t\tpush!(unique_elems, elem)\n\t\t\tpush!(indices, length(unique_elems) )\n\t\telse\n\t\t\tpush!(indices, i)\n\t\tend\n\tend\n\treturn unique_elems, indices\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Now, if the polynomial degree equals 2 we construct a tree for the Hessian calculation. In any case, we need a tree for the gradients/jacobian. If the RFD.FiniteDiffStamp for the gradients is the same as for the Hessians, we can re-use the Hessian tree for this purpose. Else, we need to construct a new one.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function _get_RFD_trees( x, fx, grad_stamp, hess_stamp = nothing, deg = 2)\n    if deg >= 2\n        @assert !isnothing(hess_stamp)\n        # construct tree for hessian first\n        hess_wrapper = RFD.DiffWrapper(; x0 = x, fx0 = fx, stamp = hess_stamp, order = 2 )\n    else\n        hess_wrapper = nothing\n    end\n\n    if !isnothing(hess_wrapper) && grad_stamp == hess_stamp\n        grad_wrapper = hess_wrapper\n    else\n        grad_wrapper = RFD.DiffWrapper(; x0 = x, fx0 = fx, stamp = grad_stamp, order = 1 )\n    end\n\n    return grad_wrapper, hess_wrapper\nend\n\n\nfunction prepare_init_model(cfg :: TaylorConfig, func_indices,\n    mop, scal, id, sdb, ac; kwargs...)\n    return prepare_update_model(nothing, TaylorIndexMeta(), cfg, func_indices, mop, scal, id, sdb, ac ; kwargs... )\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The actual database preparations are delegated to the prepare_update_model function.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function prepare_update_model(\n    mod :: Union{Nothing, TaylorModel}, meta :: TaylorIndexMeta,\n    cfg :: TaylorConfig, func_indices, mop, scal, iter_data, sdb, algo_config;\n    kwargs...\n)\n\n    @logmsg loglevel2 \"Building Taylor model for $(func_indices)\"\n    db = get_sub_db( sdb, func_indices )\n    x = get_x_scaled( iter_data )\n    x_index = get_x_index( iter_data, func_indices )\n    fx = get_value( db, x_index )\n\n    grad_wrapper, hess_wrapper = _get_RFD_trees( x, fx, cfg.gradients, cfg.hessians, cfg.degree )\n\n    XT = typeof(x)\n\n    lb, ub = full_bounds_internal( scal )\n\n    if cfg.degree >= 2\n        RFD.substitute_leaves!(hess_wrapper)\n        # We project into the scaled variable boundaries to avoid violations:\n        hess_sites = [ _project_into_box(s,lb,ub) for s in RFD.collect_leave_sites( hess_wrapper ) ]\n    else\n        hess_sites = XT[]\n    end\n\n    # collect leave sites for gradients\n    if grad_wrapper == hess_wrapper\n        grad_sites = hess_sites\n    else\n        RFD.substitute_leaves!( grad_wrapper )\n        grad_sites = [ _project_into_box(s,lb,ub) for s in RFD.collect_leave_sites( grad_wrapper ) ]\n    end\n\n    combined_sites = [ [x,]; hess_sites; grad_sites ]\n\n    unique_new, unique_indices = unique_with_indices(combined_sites)\n    # now: `combined_sites == unique_new[unique_indices]`\n\n    num_hess_sites = length(hess_sites)\n    hess_setter_indices = unique_indices[ 2 : num_hess_sites + 1]\n    grad_setter_indices = unique_indices[ num_hess_sites + 2 : end ]\n    # now: `hess_sites == unique_new[ hess_setter_indices ]` and\n    # `grad_sites == unique_new[ grad_setter_indices ]`\n\n    db_indices = [ [x_index,]; [ new_result!(db, ξ, []) for ξ in unique_new[ 2:end ] ] ]\n    # now: `unique_new == get_site.(db, db_indices)`\n\n    # we return a new meta object in each iteration, so that the node cache is reset in between.\n    return TaylorIndexMeta(;\n        database_indices = db_indices,\n        grad_setter_indices,\n        hess_setter_indices,\n        grad_wrapper,\n        hess_wrapper\n    )\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"If the meta data is set correctly, we only have to set the value vectors for the RFD trees and then ask for the right matrices:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function init_model(meta :: TaylorIndexMeta, cfg :: TaylorConfig, func_indices,\n\tmop, scal, iter_data, sdb, ac; kwargs... )\n\n    return update_model( nothing, meta, cfg, func_indices, mop, scal, iter_data, sdb, ac; kwargs...)\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Note, that we only perform updates if the iterate has changed, x != mod.x0, because we don't change the differencing parameters.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function update_model( mod::Union{Nothing,TaylorModel}, meta :: TaylorIndexMeta, cfg :: TaylorConfig,\n\tfunc_indices, mop, scal, iter_data,\n\tsdb, ac;\n\tkwargs... )\n\n    db = get_sub_db( sdb, func_indices )\n    x = get_x_scaled(iter_data)\n    x_index = get_x_index( iter_data, func_indices )\n    fx = get_value( db, x_index )\n\n    if isnothing(mod) || (x != mod.x0)\n        all_leave_vals = get_value.( db, meta.database_indices )\n\n        if !isnothing( meta.hess_wrapper )\n            hess_leave_vals = all_leave_vals[ meta.hess_setter_indices ]\n            RFD.set_leave_values!( meta.hess_wrapper, hess_leave_vals )\n            H = [ RFD.hessian( meta.hess_wrapper; output_index = ℓ ) for ℓ = 1 : num_outputs(func_indices) ]\n        else\n            H = nothing\n        end\n\n        # calculate gradients\n        if meta.hess_wrapper != meta.grad_wrapper\n            grad_leave_vals = all_leave_vals[ meta.grad_setter_indices ]\n            RFD.set_leave_values!( meta.grad_wrapper, grad_leave_vals )\n        end\n\n        # if hessians have been calculated before and `grad_wrapper == hess_wrapper` we profit from caching\n        J = RFD.jacobian( meta.grad_wrapper )\n        g = copy.( eachrow( J ) )\n\n        return TaylorModel(;\n            x0 = x,\n            fx0 = fx,\n            g, H\n        ), meta\n    else\n        return mod,meta\n    end\nend","category":"page"},{"location":"TaylorModel/#Callback-Models-with-Derivatives,-AD-or-Adaptive-Finite-Differencing","page":"TaylorModels","title":"Callback Models with Derivatives, AD or Adaptive Finite Differencing","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The old way of defining Taylor Models was to provide an objective callback function and either give callbacks for the derivatives too or ask for automatic differencing. This is very similar to the ExactModels, with the notable difference that the gradient and Hessian information is only used to construct models m_ℓ = f_0 + mathbf g^T mathbf h + mathbf h^T mathbf H mathbf h once per iteration and then use these m_ℓ for all subsequent model evaluations/differentiation.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"\"\"\"\n    TaylorCallbackConfig(;degree=1,max_evals=typemax(Int64))\n\nConfiguration for a linear or quadratic Taylor model where there are callbacks provided for the\ngradients and -- if applicable -- the Hessians.\n\"\"\"\n@with_kw struct TaylorCallbackConfig <: TaylorCFG\n\n    degree :: Int64 = 1\n\n    max_evals :: Int64 = typemax(Int64)\n\n    @assert 1 <= degree <= 2 \"Can only construct linear and quadratic polynomial Taylor models.\"\nend\n\nneeds_gradients( cfg :: TaylorCallbackConfig ) = true\nneeds_hessians( cfg :: TaylorCallbackConfig ) = cfg.degree >= 2","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"For these models, it is not advisable to combine objectives:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"combinable( :: TaylorCallbackConfig ) = false","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The meta structs are just for show:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"struct TaylorCallbackMeta <: AbstractSurrogateMeta end","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The initialization for the legacy config types is straightforward as they don't use the new 2-phase process:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function prepare_init_model(cfg :: TaylorCallbackConfig, func_indices,\n    mop, scal, id, sdb, ac; kwargs...)\n    return TaylorCallbackMeta()\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The model construction happens in the update_model method and makes use of the get_gradient and get_hessian methods of the AbstractVectorObjective.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function init_model(meta :: TaylorCallbackMeta, cfg :: TaylorCallbackConfig, func_indices,\n    mop, scal, id, sdb, ac; kwargs...)\n    return update_model(nothing, meta, cfg, func_indices, mop, scal, id, sdb, ac; kwargs... )\nend\n\nfunction update_model( mod :: Union{Nothing,TaylorModel}, meta :: TaylorCallbackMeta, cfg :: TaylorCallbackConfig, func_indices,\n    mop, scal, id, sdb, ac; kwargs...)\n\n    x0 = get_x_scaled(id)\n    x0_unscaled = get_x(id)","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"if there is no model yet OR x0 has changed","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"    if isnothing(mod) || (x0 != mod.x0)\n        fx0 = get_vals( id, sdb, func_indices )\n\n        J = jacobian_of_unscaling(scal)\n        Jᵀ = transpose(J)\n\n        g = collect( Iterators.flatten(\n            [ let func = _get(mop, ind), func_jac = _get_jacobian(func, x0_unscaled);\n                [ _ensure_vec( Jᵀ * func_jac[ℓ,:] ) for ℓ = 1 : num_outputs(func) ]\n            end for ind = func_indices ]\n        ) )\n\n        H = if cfg.degree >= 2\n            collect( Iterators.flatten(\n                [ let func = _get(mop, ind);\n                    [ (Jᵀ * _get_hessian(func, x0_unscaled, ℓ) * J) for ℓ = 1 : num_outputs(func) ]\n                end for ind = func_indices ]\n            ) )\n        else\n            nothing\n        end\n\n        return TaylorModel(; x0, fx0, g, H ), meta\n    else\n        return mod, meta\n    end\n\nend","category":"page"},{"location":"TaylorModel/#Model-Evaluation","page":"TaylorModels","title":"Model Evaluation","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The evaluation of a Taylor model of form","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"    m_ℓ(mathbf x) = f_ℓ(mathbf x_0) +\n    mathbf g^T ( mathbf x - mathbf x_0 ) + ( mathbf x - mathbf x_0 )^T mathbf H_ℓ ( mathbf x - mathbf x_0)","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"is straightforward:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"\"Evaluate (internal) output `ℓ` of TaylorModel `tm`, provided a difference vector `h = x - x0`.\"\nfunction _eval_models( tm :: TaylorModel, h :: Vec, ℓ :: Int )\n    ret_val = tm.fx0[ℓ] + tm.g[ℓ]'h\n    if !isnothing(tm.H)\n        ret_val += .5 * h'tm.H[ℓ]*h\n    end\n    return ret_val\nend\n\n\"Evaluate (internal) output(s) `ℓ` of `tm` at scaled site `x̂`.\"\nfunction eval_models( tm :: TaylorModel, scal :: AbstractVarScaler, x̂ :: Vec, ℓ )\n    h = x̂ .- tm.x0\n    return reduce( vcat, _eval_models( tm, h, l ) for l = ℓ )\n end","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"For the vector valued model, we iterate over all (internal) outputs:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function eval_models( tm :: TaylorModel, scal :: AbstractVarScaler, x̂ :: Vec )\n    h = x̂ .- tm.x0\n    return eval_models(tm, scal, x̂, 1:num_outputs(tm))\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The gradient of m_ℓ can easily be determined:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function get_gradient( tm :: TaylorModel, scal :: AbstractVarScaler, x̂ :: Vec, ℓ)\n    if isnothing(tm.H)\n        return tm.g[ℓ]\n    else\n        h = x̂ .- tm.x0\n        return tm.g[ℓ] .+ .5 * ( tm.H[ℓ]' + tm.H[ℓ] ) * h\n    end\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"And for the Jacobian, we again iterate:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function get_jacobian( tm :: TaylorModel, scal :: AbstractVarScaler, x̂ :: Vec, rows = nothing )\n    indices = isnothing(rows) ? eachindex(tm.g) : rows\n    grad_list = [ get_gradient(tm, scal, x̂, ℓ) for ℓ = indices ]\n    return transpose( hcat( grad_list... ) )\n    #scr # TODO pre-allocate matrix for speed\nend","category":"page"},{"location":"TaylorModel/#taylor_summary","page":"TaylorModels","title":"Summary & Quick Examples","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The recommended way to use Finite Difference Taylor models is to define them with TaylorConfig, i.e.,\nadd_objective!(mop, f; model_cfg = TaylorConfig(), n_out = 1)\nTo use FiniteDiff.jl instead, do\nadd_objective!(mop, f;\n   model_cfg = TaylorCallbackConfig(),\n   diff_method = Morbit.FiniteDiffWrapper)\nHave callbacks for the gradients and the Hessians? Great!\nadd_objective!(mop, f;\n   TaylorCallbackConfig(; degree = 1),\n   gradients = [g1,g2]))\nNo callbacks, but you want the correct matrices anyways? ForwardDiff to the rescue:\nadd_objective!(mop, f;\n   model_cfg = TaylorCallbackConfig(),\n   diff_method = Morbit.AutoDiffWrapper)","category":"page"},{"location":"TaylorModel/#Complete-usage-example","page":"TaylorModels","title":"Complete usage example","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"using Morbit\nMorbit.print_all_logs()\nmop = MixedMOP(3)\n\nadd_objective!( mop, x -> sum( ( x .- 1 ).^2 ); model_cfg = TaylorConfig(), n_out = 1)\nadd_objective!( mop, x -> sum( ( x .+ 1 ).^2 ), model_cfg = TaylorConfig(), n_out = 1)\n\nx_fin, f_fin, _ = optimize( mop, [-π, ℯ, 0])","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"This page was generated using Literate.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Morbit","category":"page"},{"location":"#Morbit","page":"Home","title":"Morbit","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package Morbit.jl provides a local derivative-free solver for multiobjective optimization problems with possibly expensive objectives. It is meant to find a single Pareto-critical point, not a good covering of the global Pareto Set.","category":"page"},{"location":"","page":"Home","title":"Home","text":"“Morbit” stands for Multiobjective Optimization by Radial Basis Function Interpolation in Trust-regions.  The name was chosen so as to pay honors to the single objective algorithm ORBIT by Wild et. al.  ","category":"page"},{"location":"","page":"Home","title":"Home","text":"We have a paper explaining the algorithm!","category":"page"},{"location":"","page":"Home","title":"Home","text":"This was my first project using Julia and there have been many messy rewrites. Nonetheless, the solver should now work sufficiently well to tackle most problems.  I hope to rewrite the custom types soonish. At the moment they are weakly typed and the performance suffers.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To get started, see the examples, e.g. Two Parabolas.","category":"page"},{"location":"","page":"Home","title":"Home","text":"There are also some documentation pages for the different model types. These were auto-generated from source code using Literate.jl. Hence, they are very detailed but not user-oriented, except for some usage examples at the bottom.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This project was founded by the European Region Development Fund.","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"https://www.efre.nrw.de/fileadmin/Logos/EU-Fo__rderhinweis__EFRE_/EFRE_Foerderhinweis_englisch_farbig.jpg\" width=\"45%\"/>","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"https://www.efre.nrw.de/fileadmin/Logos/Programm_EFRE.NRW/Ziel2NRW_RGB_1809_jpg.jpg\" width=\"45%\"/>","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/models/ExactModel.jl\"","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"Exact models","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"This file is automatically generated from source code. For usage examples refer to Summary & Quick Examples.","category":"page"},{"location":"ExactModel/#Introduction","page":"ExactModels","title":"Introduction","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"The ExactModel is used to evaluate the objective exactly, without surrogate modelling (except for internal variable scaling). The derivatives are either user provided callbacks or can be deterimned using ForwardDiff or FiniteDiff automatically.","category":"page"},{"location":"ExactModel/#Surrogate-Model-Interface-Implementations","page":"ExactModels","title":"Surrogate Model Interface Implementations","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"\"\"\"\n    ExactModel( index, mop )\n\nExact Model type for evaluating the objective function `objf` directly.\nIs instantiated by the corresponding `init_model` and `update_model` functions.\n\"\"\"\nstruct ExactModel{M <: Base.RefValue } <: AbstractSurrogate\n    func_index :: NLIndex\n    mop :: M\nend\n\nfunction ExactModel( func_ind, mop :: AbstractMOP )\n    return ExactModel( func_ind, Ref(mop) )\nend","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"The can determine the behavior of an ExactModel using ExactConfig:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"\"\"\"\n    ExactConfig(; gradients, jacobian = nothing, max_evals = typemax(Int64))\n\nConfiguration for an `ExactModel`.\n`gradients` should be a vector of callbacks for the objective gradients **or**\na `Symbol`, either `:autodiff` or `fdm`, to define the differentiation method\nto use on the objective.\nAlternatively, a `jacobian` handle can be provided.\n\"\"\"\n@with_kw struct ExactConfig <: AbstractSurrogateConfig\n    max_evals :: Int64 = typemax(Int64)\n    @assert max_evals > 1 \"(ExactConfig) `max_evals` is too low.\"\nend\n\nneeds_gradients(cfg::ExactConfig) = true","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"There is no need for custom meta information:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"struct ExactMeta <: AbstractSurrogateMeta end   # no construction meta data needed","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"The remaining implementations are straightforward:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"num_outputs( emc :: ExactConfig ) = emc.num_outputs\nmax_evals( emc :: ExactConfig ) = emc.max_evals","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"We always deem the models fully linear:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"fully_linear( em :: ExactModel ) = true","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"They are not combinable to have individiual gradients availabe:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"combinable( :: ExactConfig ) = false","category":"page"},{"location":"ExactModel/#Construction","page":"ExactModels","title":"Construction","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"All \"construction\" work is done in the init_model function:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"function prepare_init_model(cfg :: ExactConfig, func_indices,\n    mop, scal, id, sdb, ac; kwargs...\n)\n    return ExactMeta()\nend\n\n@doc \"Return an ExactModel build from a VecFun `objf`.\nModel is the same inside and outside of criticality round.\"\nfunction init_model(meta :: ExactMeta, cfg :: ExactConfig,\n    func_indices, mop, scal, id, sdb, ac; kwargs...\n)\n    em = ExactModel( first(func_indices), mop)\n    return em, meta\nend","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"We do not need the improve_model and update_model methods, so we keep the defaults. We also make this information availabe by owerwriting:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"requires_update( cfg :: ExactConfig ) = false\nrequires_improve( cfg :: ExactConfig ) = false","category":"page"},{"location":"ExactModel/#Evaluation","page":"ExactModels","title":"Evaluation","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"@doc \"Evaluate the ExactModel `em` at scaled site `x̂`.\"\nfunction eval_models( em :: ExactModel, scal :: AbstractVarScaler, x_scaled :: Vec)\n    return eval_vfun( _get(em.mop[], em.func_index), untransform(x_scaled, scal) )\nend\n\n@doc \"Gradient vector of output `ℓ` of `em` at scaled site `x̂`.\"\nfunction get_gradient( em :: ExactModel, scal :: AbstractVarScaler, x_scaled :: Vec, ℓ )\n    mop = em.mop[]\n    f_ind = em.func_index\n    objf = _get( mop, f_ind )\n    J = jacobian_of_unscaling( scal )\n    x = untransform( x_scaled, scal )\n    return _ensure_vec( J'_get_gradient( objf, x, ℓ ) )\nend\n\n@doc \"Jacobian Matrix of ExactModel `em` at scaled site `x̂`.\"\nfunction get_model_jacobian( em :: ExactModel, scal :: AbstractVarScaler, x_scaled :: Vec, rows = nothing )\n    mop = em.mop[]\n    J = jacobian_of_unscaling(scal)\n    x = untransform( x_scaled, scal )\n    f_ind = em.func_index\n    partial_jac = if isnothing(rows)\n        _get_jacobian( _get(mop, f_ind), x )\n    else\n        _get_jacobian( _get(mop,f_ind), x, rows)\n    end\n    return partial_jac * J\nend\n\nfunction get_jacobian(em :: ExactModel, scal :: AbstractVarScaler, x_s :: Vec )\n    return get_model_jacobian(em, scal, x_s)\nend\n\nfunction get_jacobian(em :: ExactModel, scal :: AbstractVarScaler, x_s :: Vec, rows )\n    return get_model_jacobian( em, scal, x_s, rows)\nend","category":"page"},{"location":"ExactModel/#exact_summary","page":"ExactModels","title":"Summary & Quick Examples","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"using Morbit\nMorbit.print_all_logs()\nmop = MixedMOP(3)\n\nf1 = x -> sum( ( x .- 1 ).^2\nf2 = x -> sum( ( x .+ 1 ).^2\ng1 = x -> 2 .* ( x .- 1 )\ng2 = x -> 2 .* ( x .+ 1 )\n\nadd_objective!( mop, f1; n_out = 1, model_cfg = ExactConfig(), gradients = [g1,]) )\nadd_objective!( mop, f2; n_out = 1, model_cfg = ExactConfig(), gradients = [g2,]) )\n\nx_fin, f_fin, _ = optimize( mop, [-π, ℯ, 0])","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"This page was generated using Literate.jl.","category":"page"}]
}
