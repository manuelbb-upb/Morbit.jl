var documenterSearchIndex = {"docs":
[{"location":"notebook_polynomial_interpolation/","page":"Lagrange Interpolation","title":"Lagrange Interpolation","text":"<iframe id=\"fdnotebook\" src=\"../custom_assets/notebook_polynomial_interpolation.html\" width=\"100%\"></iframe>\n<!--<script src=\"../custom_assets/iframeResizer.min.js\"></srcipt>-->\n<script>\nconst iFrameResizerPath = '../custom_assets/iframeResizer.min.js';\n\nif (require) {\n  require([iFrameResizerPath], (iFrameResize) => iFrameResize())\n} else {\n  const script = document.createElement('script')\n  script.onload = () => iFrameResize()\n  script.src = iFrameResizerPath\n}\n</script>\n<script>\ndocument.addEventListener('DOMContentLoaded', function(){\n\tvar myIframe = document.getElementById(\"fdnotebook\");\n\tiFrameResize({log:true}, myIframe);\t\n});\n</script>","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/examples/example_zdt.jl\"","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"This example is out of date and won't work.","category":"page"},{"location":"example_zdt/#ZDT3-Problem","page":"ZDT3","title":"ZDT3 Problem","text":"","category":"section"},{"location":"example_zdt/#Setup","page":"ZDT3","title":"Setup","text":"","category":"section"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"Install the test problem suite:","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"using Pkg\nPkg.activate(tempname())\nPkg.develop(url=\"https://github.com/manuelbb-upb/MultiObjectiveProblems.jl\")\nusing MultiObjectiveProblems","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"using MultiObjectiveProblems; #hide\nnothing #hide","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"Import other dependencies:","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"using CairoMakie\nusing Morbit","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"Retrieve test problem and define a MixedMOP","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"test_problem = ZDT3(2);\nbox = constraints(test_problem);\n\nobjectives = get_objectives(test_problem)\nx₀ = get_random_point(test_problem)\n\nmop = MixedMOP( box.lb, box.ub );\nobjf_cfg = ExactConfig()\nfor objf ∈ objectives\n    add_objective!(mop, objf, objf_cfg)\nend","category":"page"},{"location":"example_zdt/#Run","page":"ZDT3","title":"Run","text":"","category":"section"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"Run optimization and plot:","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"I = get_ideal_point(test_problem)\nac = AlgoConfig(; descent_method = :ps, reference_point = I )\n\nx, fx, id = optimize( mop, x₀; algo_config = ac);\n\npset = get_pareto_set(test_problem)\nPSx,PSy = get_scatter_points(pset, 100)\n\n#  scatter Pareto set points in grey\nfig, ax, _ = scatter( PSx, PSy;\n    figure = (resolution = (600, 650),),\n)\n\n#  set axis limits to whole feasible set\nxlims!(ax, (box.lb[1] .- .2, box.ub[1] .+ .2) )\nylims!(ax, (box.lb[2] .- .2, box.ub[2] .+ .2) )\n\n#  final iterate in red\nscatter!(Tuple(x); color = :red)\n\nfig","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"","category":"page"},{"location":"example_zdt/","page":"ZDT3","title":"ZDT3","text":"This page was generated using Literate.jl.","category":"page"},{"location":"dev_man/#Developer-Manual","page":"Internals","title":"Developer Manual","text":"","category":"section"},{"location":"dev_man/","page":"Internals","title":"Internals","text":"This page is a big TODO!","category":"page"},{"location":"dev_man/","page":"Internals","title":"Internals","text":"For now, there are only the doc-strings:","category":"page"},{"location":"dev_man/","page":"Internals","title":"Internals","text":"Modules = [Morbit]","category":"page"},{"location":"dev_man/#Morbit.ExactConfig","page":"Internals","title":"Morbit.ExactConfig","text":"ExactConfig(; gradients, jacobian = nothing, max_evals = typemax(Int64))\n\nConfiguration for an ExactModel. gradients should be a vector of callbacks for the objective gradients or  a Symbol, either :autodiff or fdm, to define the differentiation method  to use on the objective. Alternatively, a jacobian handle can be provided.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.ExactModel","page":"Internals","title":"Morbit.ExactModel","text":"ExactModel( tfn, objf, diff_fn )\n\nExact Model type for evaluating the objective function objf directly. Is instantiated by the corresponding init_model and update_model functions.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.RbfConfig","page":"Internals","title":"Morbit.RbfConfig","text":"RbfConfig(; kwarg1 = val1, … )\n\nConfiguration type for local RBF surrogate models.\n\nTo choose a kernel, use the kwarg kernel and a value of either  :cubic (default), :inv_multiquadric, :multiquadric, :gaussian or :thin_plate_spline. The kwarg shape_parameter takes a constant number or a string  that defines a calculation on Δ, e.g, \"Δ/10\". Note, that shape_parameter has a different meaning for the different kernels. For `:gaussian, :inv_multiquadric, :multiquadric it actually is a floating point shapeparameter. For :cubic it is the (odd) integer exponent and for `thinplate_splineit is an integer exponent as well. UseNaN` for defaults.\n\nTo see other configuration parameters use fieldnames(Morbit.RbfConfig). They have individual docstrings attached.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.TaylorApproximateConfig","page":"Internals","title":"Morbit.TaylorApproximateConfig","text":"TaylorApproximateConfig(;degree=1,mode=:fdm,max_evals=typemax(Int64))\n\nConfigure a linear or quadratic Taylor model where the gradients and Hessians are constructed  either by finite differencing (mode = :fdm) or automatic differencing (mode = :autodiff).\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.TaylorCallbackConfig","page":"Internals","title":"Morbit.TaylorCallbackConfig","text":"TaylorCallbackConfig(;degree=1,gradients,hessians=nothing,max_evals=typemax(Int64))\n\nConfiguration for a linear or quadratic Taylor model where there are callbacks provided for the  gradients and – if applicable – the Hessians. The gradients keyword point to an array of callbacks where each callback evaluates  the gradient of one of the outputs.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.TaylorConfig","page":"Internals","title":"Morbit.TaylorConfig","text":"TaylorConfig(; degree, gradients :: RFD.CFDStamp, hessians :: RFD.CFDStamp, max_evals)\n\nConfiguration for a polynomial Taylor model using finite difference approximations of the derivatives. By default we have degree = 2 and gradients == hessians == RFD.CFDStamp(1,2), that is,  a first order central difference scheme of accuracy order 3 is recursed to compute the Hessians  and the gradients. In this case, the finite difference scheme is the same for both Hessians and gradients and we profit  from caching intermediate results.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.TransformerFn","page":"Internals","title":"Morbit.TransformerFn","text":"Return the TransformerFn defined by mop with a minimum precision of T.\n\n\n\n\n\n","category":"type"},{"location":"dev_man/#Morbit.TransformerFn-Tuple{AbstractVector{var\"#s72\"} where var\"#s72\"<:Real}","page":"Internals","title":"Morbit.TransformerFn","text":"Unscale the point x̂ from internal to original domain.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Base.eachindex-Tuple{Morbit.AbstractDB}","page":"Internals","title":"Base.eachindex","text":"List of all id :: Int belonging to the stored results.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Base.length-Tuple{Morbit.AbstractDB}","page":"Internals","title":"Base.length","text":"Number of entries in database.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._add!-Tuple{Morbit.AbstractMOP, Morbit.AbstractObjective, Union{Nothing, Vector{Int64}}}","page":"Internals","title":"Morbit._add!","text":"Add an objective function to MOP with specified output indices.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._backtrack-NTuple{5, Any}","page":"Internals","title":"Morbit._backtrack","text":"Perform a backtracking loop starting at x with an initial step of step_size .* dir and return trial point x₊, the surrogate value-vector m_x₊ and the final step s = x₊ .- x.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._consume_points-NTuple{7, Any}","page":"Internals","title":"Morbit._consume_points","text":"_consume_points(data_base, poised_points, poised_indices, candidate_indices)\n\nHelper to return array of database indices for poised_points and  poised_indices. Add result to database if index is -1. candidate_indices are the database indices of the points from the trust region.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._del!-Tuple{Morbit.AbstractMOP, Morbit.AbstractObjective}","page":"Internals","title":"Morbit._del!","text":"Remove an objective function from MOP.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._eval_models-Tuple{Morbit.TaylorModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}","page":"Internals","title":"Morbit._eval_models","text":"Evaluate (internal) output ℓ of TaylorModel tm, provided a difference vector h = x - x0.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._get_optim_handle-Tuple{Morbit.SurrogateModel, Int64}","page":"Internals","title":"Morbit._get_optim_handle","text":"Return a function handle to be used with NLopt for output ℓ of model. That is, if model is a surrogate for two scalar objectives, then ℓ must  be either 1 or 2.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._get_ps_constraint_func-Tuple{Morbit.SurrogateContainer, Any, Any, Any}","page":"Internals","title":"Morbit._get_ps_constraint_func","text":"_get_ps_constraint_func( sc :: SurrogateContainer, mx, dir, l )\n\nReturn the l-th (possibly non-linear) constraint function  for Pascoletti-Serafini. dir .>= 0 is the image direction; χ = [t;x] is the augmented variable vector;\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._get_ps_objective_func-Tuple{}","page":"Internals","title":"Morbit._get_ps_objective_func","text":"Return objective function for Pascoletti-Serafini, modifying gradient in place.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._init_model-Tuple{ExactConfig, Morbit.AbstractObjective, Morbit.AbstractMOP, Morbit.AbstractIterData, Morbit.AbstractDB, Morbit.AbstractConfig, Morbit.ExactMeta}","page":"Internals","title":"Morbit._init_model","text":"Return an ExactModel build from a VectorObjectiveFunction objf.  Model is the same inside and outside of criticality round.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._intersect_bounds-NTuple{4, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit._intersect_bounds","text":"Return smallest positive and biggest negative and σ₊ and σ₋ so that x .+ σ± .* d stays within bounds.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._local_bounds-Tuple{AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Union{Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit._local_bounds","text":"Return lower and upper bound vectors combining global and trust region constraints.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._objf_index-Tuple{Morbit.AbstractObjective, Morbit.AbstractMOP}","page":"Internals","title":"Morbit._objf_index","text":"Position of objf in list_of_objectives(mop).\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._ps_optimization-Union{Tuple{F}, Tuple{Morbit.SurrogateContainer, Symbol, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64, AbstractVector{F}, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64, Int64}} where F","page":"Internals","title":"Morbit._ps_optimization","text":"Construct and solve Pascoletti Serafini subproblem using surrogates from sc.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._steepest_descent_direction-Union{Tuple{F}, Tuple{AbstractVector{F}, AbstractMatrix{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}} where F<:AbstractFloat","page":"Internals","title":"Morbit._steepest_descent_direction","text":"Provided x and the (surrogate) jacobian ∇F at x, as well as bounds lb and ub, return steepest multi descent direction.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._wrap_func-Union{Tuple{O}, Tuple{T}, Tuple{Type{var\"#s42\"} where var\"#s42\"<:Morbit.OutTypeWrapper{T, O}, Function, Morbit.SurrogateConfig, Int64, Int64}} where {T, O}","page":"Internals","title":"Morbit._wrap_func","text":"A general constructor.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit._wrap_func-Union{Tuple{T}, Tuple{T, Function, Morbit.SurrogateConfig, Int64, Int64}} where T<:(Type{var\"#s42\"} where var\"#s42\"<:Morbit.AbstractObjective)","page":"Internals","title":"Morbit._wrap_func","text":"A general constructor.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.add_objective!","page":"Internals","title":"Morbit.add_objective!","text":"add_objective!( mop :: MixedMOP, func :: T where{T <: Function}, type :: Symbol = :expensive, n_out :: Int64 = 1, can_batch :: Bool = false )\n\nAdd scalar-valued objective function func to mop structure. func must take an Vec as its (first) argument, i.e. represent a function f ℝ^n  ℝ. type must either be :expensive or :cheap to determine whether the function is replaced by a surrogate model or not.\n\nIf type is :cheap and func takes 1 argument only then its gradient is calculated by ForwardDiff. A cheap function func with custom gradient function grad (representing f  ℝ^n  ℝ^n) is added by\n\nadd_objective!(mop, func, grad)\n\nThe optional argument n_out allows for the specification of vector-valued objective functions. This is mainly meant to be used for expensive functions that are in some sense inter-dependent.\n\nThe flag can_batch defaults to false so that the objective function is simply looped over a bunch of arguments if required. If can_batch == true then the objective function must be able to return an array of results when provided an array of input vectors (whilst still returning a single result, not a singleton array containing the result, for a single input vector).\n\nExamples\n\n# Define 2 scalar objective functions and a MOP ℝ^2 → ℝ^2\n\nf1(x) =  x[1]^2 + x[2]\n\nf2(x) = exp(sum(x))\n∇f2(x) = exp(sum(x)) .* ones(2);\n\nmop = MixedMOP()\nadd_objective!(mop, f1, :cheap)     # gradient will be calculated using ForwardDiff\nadd_objective!(mop, f2, ∇f2 )       # gradient is provided\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.add_objective!-Tuple{MixedMOP, Function, Function}","page":"Internals","title":"Morbit.add_objective!","text":"add_objective!( mop :: MixedMOP, func :: T where{T <: Function}, grad :: T where{T <: Function})\n\nAdd scalar-valued objective function func and its vector-valued gradient grad to mop struture.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.add_objective!-Tuple{MixedMOP, Function, Morbit.SurrogateConfig}","page":"Internals","title":"Morbit.add_objective!","text":"Add a scalar objective to mop::MixedMOP modelled according to model_config.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.add_vector_objective!-Tuple{MixedMOP, Function, Morbit.SurrogateConfig}","page":"Internals","title":"Morbit.add_vector_objective!","text":"Add a vector objective to mop::MixedMOP modelled according to model_config.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.combine-Union{Tuple{F}, Tuple{T}, Tuple{T, F}} where {T<:Morbit.AbstractObjective, F<:Morbit.AbstractObjective}","page":"Internals","title":"Morbit.combine","text":"Combine two objectives. Only needed if combinable can return true.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.combine-Union{Tuple{T}, Tuple{F}, Tuple{F, T}} where {F<:Function, T<:Function}","page":"Internals","title":"Morbit.combine","text":"Get a new function function handle stacking the output of func1 and func2.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.copy_db-Union{Tuple{DBT}, Tuple{DBT, Type}} where DBT<:Morbit.AbstractDB","page":"Internals","title":"Morbit.copy_db","text":"Return a new database of same 'base' type but with different saveable type.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_all_objectives-Tuple{Morbit.AbstractMOP, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit.eval_all_objectives","text":"(Internally) Evaluate all objectives at site x̂::Vec. Objective order might differ from order in which they were added.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_and_sort_objectives-Tuple{Morbit.AbstractMOP, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit.eval_and_sort_objectives","text":"Evaluate all objectives at site x̂::Vec and sort the result according to the order in which objectives were added.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_handle-Tuple{Morbit.AbstractObjective}","page":"Internals","title":"Morbit.eval_handle","text":"Return a function that evaluates an objective at an unscaled site.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{Morbit.ExactModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}","page":"Internals","title":"Morbit.eval_models","text":"Evaluate output ℓ of the ExactModel em at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{Morbit.ExactModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit.eval_models","text":"Evaluate the ExactModel em at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{Morbit.SurrogateContainer, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}","page":"Internals","title":"Morbit.eval_models","text":"Return model value for output l of sc at x̂. Index l is assumed to be an internal index in the range of 1,…,nobjfs, where nobjfs is the total number of (scalarized) objectives stored in sc.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{Morbit.TaylorModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}","page":"Internals","title":"Morbit.eval_models","text":"Evaluate (internal) output ℓ of tm at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{RbfModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}","page":"Internals","title":"Morbit.eval_models","text":"Evaluate output ℓ of mod::RbfModel at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_models-Tuple{RbfModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit.eval_models","text":"Evaluate mod::RbfModel at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_objf-Tuple{Morbit.AbstractObjective, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit.eval_objf","text":"Evaluate the objective at unscaled site x. and increase counter.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.eval_objf-Tuple{Morbit.AbstractObjective, Morbit.TransformerFn, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit.eval_objf","text":"Evaluate the objective at scaled site x̂ with help of tfn. Used in diff_wrappers.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.full_lower_bounds-Tuple{Morbit.AbstractMOP}","page":"Internals","title":"Morbit.full_lower_bounds","text":"Return full vector of lower variable vectors for original problem.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.full_lower_bounds_internal-Tuple{Morbit.AbstractMOP}","page":"Internals","title":"Morbit.full_lower_bounds_internal","text":"Return lower variable bounds for scaled variables.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.full_upper_bounds-Tuple{Morbit.AbstractMOP}","page":"Internals","title":"Morbit.full_upper_bounds","text":"Return full vector of upper variable vectors for original problem.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.full_upper_bounds_internal-Tuple{Morbit.AbstractMOP}","page":"Internals","title":"Morbit.full_upper_bounds_internal","text":"Return upper variable bounds for scaled variables.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_gradient-Tuple{Morbit.ExactModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}","page":"Internals","title":"Morbit.get_gradient","text":"Gradient vector of output ℓ of em at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_gradient-Tuple{Morbit.SurrogateContainer, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}","page":"Internals","title":"Morbit.get_gradient","text":"Return a gradient for output l of sc at x̂. Index l is assumed to be an internal index in the range of 1,…,nobjfs, where nobjfs is the total number of (scalarized) objectives stored in sc.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_gradient-Tuple{RbfModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}","page":"Internals","title":"Morbit.get_gradient","text":"Gradient vector of output ℓ of mod at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_id-Tuple{Morbit.AbstractResult}","page":"Internals","title":"Morbit.get_id","text":"get_id( res :: AbstractResult ) :: Int\n\nReturn the id of a result such that for the database db  conataining res it holds that get_result(db, id) == res.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_jacobian-Tuple{Morbit.ExactModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit.get_jacobian","text":"Jacobian Matrix of ExactModel em at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_jacobian-Tuple{RbfModel, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}","page":"Internals","title":"Morbit.get_jacobian","text":"Jacobian Matrix of ExactModel em at scaled site x̂.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_optim_handle-Tuple{Morbit.SurrogateContainer, Int64}","page":"Internals","title":"Morbit.get_optim_handle","text":"Return a function handle to be used with NLopt for output l of sc. Index l is assumed to be an internal index in the range of 1, …, n_objfs, where n_objfs is the total number of (scalarized) objectives stored in sc.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_poised_set-Union{Tuple{Any}, Tuple{T}, Tuple{Any, AbstractArray{T, N} where N}} where T<:(AbstractArray{var\"#s160\", N} where {var\"#s160\"<:Real, N})","page":"Internals","title":"Morbit.get_poised_set","text":"get_poised_set( basis, points; solver = :LN_BOBYQA, max_solver_evals = -1 )\n\nCompute a point set suited for polynomial interpolation.\n\nInput:\n\nbasis: A vector of polynomials constituting a basis for the polynomial space.\npoints: (optional) A set of candidate points to be tried for inclusion into the poised set.\nsolver: NLopt solver to use. Should be derivative-free.\nmax_solver_evals: Maximum number of evaluations in each optimization run. \n\nReturn:\n\npoised_points :: Vector{T} where T is either a Vector{F} or an SVector{n_vars, F} and F is the precision of the points in points, but at least Float32. \nlagrange_basis :: Vector{<:AbstractPolynomialLike}: The Lagrange basis corresponding to poised_points.\npoint_indices: An array indicating which points from points are also in poised_points. A positive entry corresponds to the index of a poised point in points. If a poised point is new, then the entry is -1.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_result-Union{Tuple{F}, Tuple{Morbit.AbstractDB{F}, Int64}} where F","page":"Internals","title":"Morbit.get_result","text":"Get result with id from database db.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_scaling_poly-Tuple{Any, Any, Any}","page":"Internals","title":"Morbit.get_scaling_poly","text":"Return vector of polynomials that scales variables from [lb, ub] to [0,1]^n.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_site-Union{Tuple{Morbit.AbstractResult{F}}, Tuple{F}} where F","page":"Internals","title":"Morbit.get_site","text":"Return the site vector associated with a result.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_unscaling_poly-Tuple{Any, Any, Any}","page":"Internals","title":"Morbit.get_unscaling_poly","text":"Return vector of polynomials that unscales variables from [0,1]^n to [lb,ub].\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.get_value-Union{Tuple{Morbit.AbstractResult{F}}, Tuple{F}} where F","page":"Internals","title":"Morbit.get_value","text":"Return the value vector associated with a result.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.grow_radius-Tuple{Val{:standard}, Any, Any, Any}","page":"Internals","title":"Morbit.grow_radius","text":"Grow radius according to min( Δ_max, γ * Δ ).\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.grow_radius-Tuple{Val{:steplength}, Any, Any, Any}","page":"Internals","title":"Morbit.grow_radius","text":"Grow radius according to min( Δ_max, (γ + ||s||/Δ) * Δ )\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.inc_evals!","page":"Internals","title":"Morbit.inc_evals!","text":"Increase evaluation count by N\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.init_db-Tuple{Type{var\"#s43\"} where var\"#s43\"<:Morbit.AbstractDB, Type{var\"#s42\"} where var\"#s42\"<:AbstractFloat, Union{Type{var\"#s41\"} where var\"#s41\"<:Nothing, Type{var\"#s40\"} where var\"#s40\"<:Morbit.AbstractIterSaveable}}","page":"Internals","title":"Morbit.init_db","text":"Constructor for empty database of type T.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.init_res-Union{Tuple{T}, Tuple{T, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Int64}} where T<:(Type{var\"#s72\"} where var\"#s72\"<:Morbit.AbstractResult)","page":"Internals","title":"Morbit.init_res","text":"Constructor for a result, taking site and value vector and id in database.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.init_surrogates-Tuple{Morbit.AbstractMOP, Morbit.AbstractIterData, Morbit.AbstractDB, Morbit.AbstractConfig}","page":"Internals","title":"Morbit.init_surrogates","text":"Return a SurrogateContainer initialized from the information provided in mop.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.is_transformed-Tuple{Morbit.AbstractDB}","page":"Internals","title":"Morbit.is_transformed","text":"Bool indicating if the database data been transformed.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.list_of_objectives-Tuple{Morbit.AbstractMOP}","page":"Internals","title":"Morbit.list_of_objectives","text":"Return a list of AbstractVectorObjectives.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.local_bounds-Tuple{Morbit.AbstractMOP, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Union{Real, AbstractVector{var\"#s1\"} where var\"#s1\"<:Real}}","page":"Internals","title":"Morbit.local_bounds","text":"Local bounds vectors lb_eff and ub_eff using scaled variable constraints from mop.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.make_set_lambda_poised-Union{Tuple{T}, Tuple{Any, AbstractArray{T, N} where N}} where T<:(AbstractArray{var\"#s160\", N} where {var\"#s160\"<:Real, N})","page":"Internals","title":"Morbit.make_set_lambda_poised","text":"make_set_lambda_poised( basis, points; \n    LAMBDA = 1.5, solver = :LN_BOBYQA, max_solver_evals = -1, max_loops = -1, skip_indices = [1,] )\n\nMake the output of get_poised_set even better suited for interpolation.\n\nInput:\n\nbasis: A vector of polynomials constituting a Lagrange basis for the polynomial space.\npoints: The vector of points belonging to the Lagrange basis.\nLAMBDA :: Real > 1: Determines the quality of the interpolation. \nsolver: NLopt solver to use. Should be derivative-free.\nmax_solver_evals: Maximum number of evaluations in each optimization run. \nmax_loops: Maximum number of loops that try to make the set Λ-poised.\nskip_indices: Inidices of points to discard last.\n\nReturn:\n\npoised_points :: Vector{T} where T is either a Vector{F} or an SVector{n_vars, F} and F is the precision of the points in points, but at least Float32. \nlagrange_basis :: Vector{<:AbstractPolynomialLike}: The Lagrange basis corresponding to poised_points.\npoint_indices: An array indicating which points from points are also in poised_points. A positive entry corresponds to the index of a poised point in points. If a poised point is new, then the entry is -1.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.max_evals-Tuple{Morbit.AbstractObjective}","page":"Internals","title":"Morbit.max_evals","text":"(Soft) upper bound on the number of function calls. \n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.new_result!","page":"Internals","title":"Morbit.new_result!","text":"Add a new result to the database, return its id of type Int.\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.num_evals!-Tuple{Morbit.AbstractObjective, Int64}","page":"Internals","title":"Morbit.num_evals!","text":"Set evaluation counter to N.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.num_evals-Tuple{Morbit.AbstractObjective}","page":"Internals","title":"Morbit.num_evals","text":"Number of calls to the original objective function.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.num_objectives-Tuple{Morbit.AbstractMOP}","page":"Internals","title":"Morbit.num_objectives","text":"Number of scalar-valued objectives of the problem.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.pop_objf!-Tuple{Morbit.AbstractMOP, Morbit.AbstractObjective}","page":"Internals","title":"Morbit.pop_objf!","text":"Remove objf from list_of_objectives(mop) and return its output indices.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.reset_evals!-Tuple{Morbit.AbstractMOP}","page":"Internals","title":"Morbit.reset_evals!","text":"Set evaluation counter to 0 for each VectorObjectiveFunction in m.vector_of_objectives.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.results_in_box_indices","page":"Internals","title":"Morbit.results_in_box_indices","text":"Return indices of results in db that lie in a box with corners lb and ub.\n\n\n\n\n\n","category":"function"},{"location":"dev_man/#Morbit.reverse_internal_sorting-Tuple{AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Morbit.AbstractMOP}","page":"Internals","title":"Morbit.reverse_internal_sorting","text":"Sort an interal objective vector so that the objectives are in the order in which they were added.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.reverse_internal_sorting_indices-Tuple{Morbit.AbstractMOP}","page":"Internals","title":"Morbit.reverse_internal_sorting_indices","text":"Return index vector so that an internal objective vector is sorted according to the order the objectives where added.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.scale-Tuple{AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Morbit.AbstractMOP}","page":"Internals","title":"Morbit.scale","text":"Scale variables fully constrained to a closed interval to [0,1] internally.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.set_transformed!-Tuple{Morbit.AbstractDB, Bool}","page":"Internals","title":"Morbit.set_transformed!","text":"Set the flag indicating whether the database data has been transformed or not.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.shrink_radius-Tuple{Val{:standard}, Any, Any, Any}","page":"Internals","title":"Morbit.shrink_radius","text":"Shrink radius according to γ * Δ.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.shrink_radius-Tuple{Val{:steplength}, Any, Any, Any}","page":"Internals","title":"Morbit.shrink_radius","text":"Shrink radius according to γ * ||s||.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.shrink_radius_much-Tuple{Val{:standard}, Any, Any, Any}","page":"Internals","title":"Morbit.shrink_radius_much","text":"Shrink radius much according to γ * Δ.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.shrink_radius_much-Tuple{Val{:steplength}, Any, Any, Any}","page":"Internals","title":"Morbit.shrink_radius_much","text":"Shrink radius according to γ * ||s||.\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.unique_with_indices-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T","page":"Internals","title":"Morbit.unique_with_indices","text":"Return unique_elems, indices = unique_with_indices(arr) such that  unique_elems[indices] == arr (and unique_elems == unique(arr)).\n\n\n\n\n\n","category":"method"},{"location":"dev_man/#Morbit.unscale-Tuple{AbstractVector{var\"#s1\"} where var\"#s1\"<:Real, Morbit.AbstractMOP}","page":"Internals","title":"Morbit.unscale","text":"Reverse scaling for fully constrained variables from [0,1] to their former domain.\n\n\n\n\n\n","category":"method"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/LagrangeModel.jl\"","category":"page"},{"location":"LagrangeModel/#Lagrange-Polynomial-Models","page":"LagrangeModels","title":"Lagrange Polynomial Models","text":"","category":"section"},{"location":"LagrangeModel/#Intro-and-Prerequisites","page":"LagrangeModels","title":"Intro and Prerequisites","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"Polyoniaml interpolation models are a common choice for surrogate modeling. In our setting we want to construct models for n-variate objectives and use polynomials of degree 1 or 2. We hence need a basis for the space Π_n^d of polynomials. Given a point set that is suited for interpolation (a poised set) we can use the Lagarange basis l_i with l_i(x_j) = δ_ij to easily find the coefficients for vector valued models.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We use DynamicPolynomials for polynomial arithmetic, NLopt to optimize polynomials and some more packages:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"using DynamicPolynomials\nimport NLopt\nimport Combinatorics","category":"page"},{"location":"LagrangeModel/#Surrogate-Interface-Implementations","page":"LagrangeModels","title":"Surrogate Interface Implementations","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The model itself is defined only by its vector of Lagrange basis polynomials and the coefficients.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"@with_kw struct LagrangeModel{\n        B <: AbstractArray{<:AbstractPolynomialLike},\n        G <: AbstractArray{<:AbstractArray{<:AbstractPolynomialLike}},\n        V <: AbstractVector{<:AbstractVector{<:AbstractFloat} } } <: SurrogateModel\n    basis :: B\n    grads :: G\n    coeff :: V\n    fully_linear :: Bool = false\nend\n\nfully_linear( lm :: LagrangeModel ) = lm.fully_linear","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"There is a multitude of configuration parameters, most of which will be explained later:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"@with_kw mutable struct LagrangeConfig <: SurrogateConfig\n\n    \"Degree of the surrogate model polynomials.\"\n    degree :: Int = 2\n\n    \"Enlargement parameter to consider more points for inclusion.\"\n    θ_enlarge :: Real = 2\n\n    \"Quality parameter in Λ-Poisedness Algorithm.\"\n    LAMBDA :: Real = 1.5\n\n    \"Whether or not the interpolation sets must be Λ-poised (and the models fully linear).\"\n    allow_not_linear :: Bool = false\n\n    \"Whether or not to try to construct a new interpolation set in each iteration.\"\n    optimized_sampling :: Bool = true\n\n    # if optimized_sampling = false, shall we try to use saved sites?\n    save_path :: String = \"\"\n    io_lock :: Union{Nothing, Threads.ReentrantLock} = nothing\n\n    algo1_max_evals :: Int = -1\n    algo2_max_evals :: Int = -1\n\n    algo1_solver :: Symbol = :LN_BOBYQA\n    algo2_solver :: Symbol = :LN_BOBYQA\n\n    max_evals :: Int64 = typemax(Int64);\n\n    @assert 1 <= degree <= 2 \"Only linear and quadratic models are supported.\"\n    @assert LAMBDA > 1 \"`LAMBDA` must be > 1.\"\n    @assert let algo_str = string( algo1_solver );\n        length( algo_str ) > 2 && string(algo_str[2]) == \"N\"\n    end \"`algo1_solver` must be a derivative-free NLopt algorithm.\"\n    @assert let algo_str = string( algo2_solver );\n        length( algo_str ) > 2 && string(algo_str[2]) == \"N\"\n    end \"`algo2_solver` must be a derivative-free NLopt algorithm.\"\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"Overwrite lock and unlock so we can use nothing as a \"lock\":","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function Base.lock(::Nothing) end\nfunction Base.unlock(::Nothing) end","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The required method implementations are straightforward. Note, thate we allow the models to be combined to vector functions if they share the same configuration to avoid redundant efforts whilst constructing models.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"max_evals( cfg :: LagrangeConfig ) :: Int = cfg.max_evals\ncombinable( cfg :: LagrangeConfig ) :: Bool = true","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We also need to introduce our own implementation for isequal and hash for LagrangeConfigs to be combinable, see the docs too.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function Base.hash( cfg :: LagrangeConfig, h :: UInt )\n\treturn hash( getfield.( cfg, Tuple( fn for fn ∈ fieldnames(LagrangeConfig) ) ), h )\nend\nfunction Base.isequal( cfg1 :: LagrangeConfig, cfg2 :: LagrangeConfig )\n\tall( isequal( getfield(cfg1, fn), getfield(cfg2, fn) ) for fn in fieldnames( LagrangeConfig) )\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The LagrangeMeta simply holds the database indices of the results we want to interpolate at. We also store the output indices of the model for convenience and carry polynomials that act on 01^n.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"@with_kw struct LagrangeMeta{\n        CB <: Union{Nothing, Vector{<:AbstractPolynomialLike}},\n        LB <: Union{Nothing, Vector{<:AbstractPolynomialLike}},\n        P <: Union{Nothing, AbstractVector{<:AbstractVector{<:Real}}}\n    } <: SurrogateMeta\n    interpolation_indices :: Vector{Int} = []\n    out_indices :: Vector{Int} = []\n    canonical_basis :: CB = nothing\n    lagrange_basis :: LB = nothing\n    stamp_points :: P = nothing     ## used only if `unoptimized_sampling == false`\n    fully_linear :: Bool = false\nend\n\nsaveable_type( T :: LagrangeMeta ) = LagrangeMeta{Nothing,Nothing}\nsaveable( meta :: LagrangeMeta ) = LagrangeMeta(;\n    interpolation_indices = meta.interpolation_indices, out_indices = meta.output_indices )\n\nexport LagrangeConfig, LagrangeMeta, LagrangeModel","category":"page"},{"location":"LagrangeModel/#Construction","page":"LagrangeModels","title":"Construction","text":"","category":"section"},{"location":"LagrangeModel/#A-Bit-of-Theory","page":"LagrangeModels","title":"A Bit of Theory","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The canonical basis is obtained by calculating the non-negative integral solutions to the euqation","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"x_1 +  + x_n le d","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"These solutions can be found using the Combinatorics package via multiexponents(n,d) (d must be successively increased).","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function non_negative_ineq_solutions(deg, n_vars)\n\tIterators.flatten( ( collect( Combinatorics.multiexponents( n_vars, d )) for d = 0 : deg ) )\nend\n\nfunction get_poly_basis( deg, n_vars)\n\texponents = non_negative_ineq_solutions(deg, n_vars )\n\tpolys = let\n\t\t@polyvar x[1:n_vars]\n\t\t[ prod(x.^e) for e in exponents ]\n\tend\n\treturn polys\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We are going to use the canonical basis to determine a poised set of points. This does in fact work with any polynomial basis for Π_n^d. \nIn the process of doing so, we also modify (a copy of?) the basis so that it becomes the Lagrange basis for the returned point set.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The Larange basis is formed by normalizing and orthogonalizing with respect to the point set:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function orthogonalize_polys( poly_arr, x, i )\n\t# normalize i-th polynomial with respect to `x`\n\tp_i = poly_arr[i] / poly_arr[i](x)\n\n\t# orthogonalize\n\treturn [ j != i ? poly_arr[j] - ( poly_arr[j](x) * p_i ) : p_i for j = eachindex( poly_arr ) ]\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We use Algorithm 6.2 and Algorithm 6.3 from the book \"Introduction to Derivative-Free Optimization\" by Conn et. al. \nAlgorithm 6.2 makes the set poised (suited for interpolation) and returns the corresponding Lagrange basis. Algorithm 6.3 takes the poised set and the Lagrange basis and tries to make it Λ-poised. Λ must be greater 1 and a smaller value makes the set more suited for good models.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"\"\"\"\n    get_poised_set( basis, points; solver = :LN_BOBYQA, max_solver_evals = -1 )\n\nCompute a point set suited for polynomial interpolation.\n\nInput:\n* `basis`: A vector of polynomials constituting a basis for the polynomial space.\n* `points`: (optional) A set of candidate points to be tried for inclusion into the poised set.\n* `solver`: NLopt solver to use. Should be derivative-free.\n* `max_solver_evals`: Maximum number of evaluations in each optimization run.\n\nReturn:\n* `poised_points :: Vector{T}` where `T` is either a `Vector{F}` or an `SVector{n_vars, F}` and `F` is the precision of the points in `points`, but at least `Float32`.\n* `lagrange_basis :: Vector{<:AbstractPolynomialLike}`: The Lagrange basis corresponding to `poised_points`.\n* `point_indices`: An array indicating which points from `points` are also in `poised_points`. A positive entry corresponds to the index of a poised point in `points`. If a poised point is new, then the entry is `-1`.\n\"\"\"\nfunction get_poised_set( basis, points :: AbstractArray{T} = Vector{MIN_PRECISION}[];\n\t\tsolver = :LN_BOBYQA, max_solver_evals = -1 ) where {\n\t\tT <: AbstractArray{<:Real}\n\t}\n\n\tp = length(basis)\n\t@assert p > 0 \"`basis` must not be an empty array.\"\n\n    @logmsg loglevel3 \"Trying to find a poised set with $(p) points.\"\n\n\tvars = variables( basis[end] )\n\tn_vars = length(vars)\n\t@assert n_vars > 0 \"The number of variables must be positive.\"\n\n\tif max_solver_evals < 0\n\t\tmax_solver_evals = 2000 * n_vars\n\tend\n\n\tF = promote_type( eltype( T ), MIN_PRECISION )\n\t#P_type = n_vars > 100 ? Vector{Vector{F}} : Vector{SVector{n_vars, F}}\n    P_type = Vector{Vector{F}}\n\tZERO_TOL = min(eps(F) * 100, eps(Float16) * 10)\n\n\t# indicates which points from points have been accepted\n\tpoint_indices = fill(-1, p)\n\tnot_accepted_indices = collect( eachindex( points ) )\n\t# return array of points that form a poised set\n\tpoised_points = P_type(undef, p)\n\n\tnew_basis = basis\n\tfor i = 1 : p\n\t\t_points = points[not_accepted_indices]\n\n\t\t# find the point that maximizes the i-th polynomial\n\t\t# if the polynomial is constant, then the first remaining point is used (j = 1)\n\t\tl_max, j = if isempty(_points)\n\t\t\t0.0, 0\n\t\telse\n\t\t\tfindmax( abs.( [ new_basis[i]( x ) for x in _points ] ) )\n\t\tend\n\n\t\tif l_max > ZERO_TOL\n\t\t\t# accept the `j`-th point from `_points`\n\t\t\tpoised_points[i] = _points[j]\n\t\t\t### indicate what the actual point index was\n\t\t\tpoint_indices[i] = not_accepted_indices[j]\n\t\t\t### delete from further consideration\n\t\t\tdeleteat!(not_accepted_indices, j)\n\t\telse\n\t\t\t# no point was suitable to add to the set\n\t\t\t# trying to find the maximizer for a | l_i(x) |\n\t\t\topt = NLopt.Opt( solver, n_vars )\n\t\t\topt.lower_bounds = zeros(F, n_vars )\n            opt.upper_bounds = ones(F, n_vars )\n            opt.maxeval = max_solver_evals\n            opt.xtol_rel = 1e-3\n            opt.max_objective = (x,g) -> abs( new_basis[i](x) )\n\n            # try to find a good starting point\n\t\t\tx₀_tmp = [ rand(F, n_vars) for i = 1 : 50 * n_vars ]\n            x₀ = x₀_tmp[argmax( abs.(new_basis[i].(x₀_tmp)) ) ]\n\n\t\t\t_, ξ, ret = NLopt.optimize(opt, x₀)\n\n\t\t\tpoised_points[i] = ξ\n\t\tend\n\n\t\tnew_basis = orthogonalize_polys( new_basis, poised_points[i], i )\n\tend\n\n\treturn poised_points, new_basis, point_indices\nend\n\n\"\"\"\n    make_set_lambda_poised( basis, points;\n        LAMBDA = 1.5, solver = :LN_BOBYQA, max_solver_evals = -1, max_loops = -1, skip_indices = [1,] )\n\nMake the output of `get_poised_set` even better suited for interpolation.\n\nInput:\n* `basis`: A vector of polynomials constituting a Lagrange basis for the polynomial space.\n* `points`: The vector of points belonging to the Lagrange basis.\n* `LAMBDA :: Real > 1`: Determines the quality of the interpolation.\n* `solver`: NLopt solver to use. Should be derivative-free.\n* `max_solver_evals`: Maximum number of evaluations in each optimization run.\n* `max_loops`: Maximum number of loops that try to make the set Λ-poised.\n* `skip_indices`: Inidices of points to discard last.\n\nReturn:\n* `poised_points :: Vector{T}` where `T` is either a `Vector{F}` or an `SVector{n_vars, F}` and `F` is the precision of the points in `points`, but at least `Float32`.\n* `lagrange_basis :: Vector{<:AbstractPolynomialLike}`: The Lagrange basis corresponding to `poised_points`.\n* `point_indices`: An array indicating which points from `points` are also in `poised_points`. A positive entry corresponds to the index of a poised point in `points`. If a poised point is new, then the entry is `-1`.\n\"\"\"\nfunction make_set_lambda_poised( basis, points :: AbstractArray{T};\n\t\tLAMBDA :: Real = 1.5, solver = :LN_BOBYQA, max_solver_evals = -1,\n\t\tmax_loops = -1, skip_indices = [1,] ) where {\n\t\tT <: AbstractArray{<:Real}\n\t}\n\n\t@assert length(basis) == length(points) \"Polynomial array `basis` and point array `points` must have the same length.\"\n\tif length(points) > 0\n\t\tn_vars = length(points[1])\n\t\t@assert n_vars > 0 \"The number of variables must be positive.\"\n\n\t\tF = promote_type( eltype( T ), MIN_PRECISION )\n\t\t#P_type = n_vars > 100 ? Vector{Vector{F}} : Vector{SVector{n_vars, F}}\n        P_type = Vector{Vector{F}}\n\n\t\tif max_loops < 0\n\t\t\tmax_loops = length(basis) * 100\n\t\tend\n\n\t\tif max_solver_evals < 0\n\t\t\tmax_solver_evals = 2000 * n_vars\n\t\tend\n\n       \t@logmsg loglevel3 \"Trying $(max_loops) times to make a set poised with Λ = $(LAMBDA).\"\n\n\t\tiₖ = -1\n\t\txₖ = points[1]\n\n\t\tnew_basis = basis\n\t\tnew_points = P_type(points)\n\t\tpoint_indices = collect(eachindex(new_points))\n\n\t\tfor k = 1 : max_loops\n\t\t\tfor (i, polyᵢ) in enumerate(basis)\n\t\t\t\topt = NLopt.Opt( solver, n_vars )\n\t\t\t\topt.lower_bounds = zeros(F, n_vars)\n\t\t\t\topt.upper_bounds = ones(F, n_vars)\n\t\t\t\topt.maxeval = max_solver_evals\n\t\t\t\topt.xtol_rel = 1e-3\n\t\t\t\topt.max_objective = (x,g) -> abs( polyᵢ( x ) )\n\n\t\t\t\tx₀_tmp = [ rand(F, n_vars) for i = 1 : 50 * n_vars ]\n\t\t\t\tx₀ = x₀_tmp[argmax( abs.(new_basis[i].(x₀_tmp)) ) ]\n\n\t\t\t\tabs_lᵢ, xᵢ, _ = NLopt.optimize(opt, x₀)\n\n\t\t\t\tif abs_lᵢ > LAMBDA\n\t\t\t\t\tiₖ = i\n\t\t\t\t\txₖ = xᵢ\n\t\t\t\t\tif iₖ ∉ skip_indices\n\t\t\t\t\t\t# i is not prioritized we can brake here\n\t\t\t\t\t\tbreak\n\t\t\t\t\tend#if\n\t\t\t\tend#if\n\t\t\tend#for\n\n\t\t\tif iₖ > 0\n                @logmsg loglevel4 \"Discarding point $(iₖ).\"\n\t\t\t\t# perform a point swap\n\t\t\t\tnew_points[iₖ] = xₖ\n\t\t\t\tpoint_indices[iₖ] = -1\n\t\t\t\t# adapt coefficients of lagrange basis\n\t\t\t\tnew_basis = orthogonalize_polys( new_basis, xₖ, iₖ )\n\t\t\telse\n\t\t\t\t# we are done, the set is lambda poised\n\t\t\t\tbreak\n\t\t\tend#if\n\t\tend#for\n\n\t\treturn new_points, new_basis, point_indices\n\telse\n\t\treturn points, basis, collect(eachindex(points))\n\tend\n\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"And a convenient function that combines both steps:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function get_lambda_poised_set( basis, points; solver1 = :LN_BOBYQA, solver2 = :LN_BOBYQA, max_solver_evals1 = -1, max_solver_evals2 = -1, LAMBDA = 1.5, max_lambda_loops = -1 )\n\tlagrange_points, lagrange_basis, lagrange_indices = get_poised_set(\n\t\tbasis, points; solver = solver1, max_solver_evals = max_solver_evals1 )\n\tlambda_points, lambda_basis, lambda_indices = make_set_lambda_poised(\n\t\tlagrange_basis, lagrange_points; LAMBDA, max_loops = max_lambda_loops,\n\t\tsolver = solver2, max_solver_evals = max_solver_evals2 )\n\tcombined_indices = [ i < 0 ? i : lagrange_indices[j] for (j,i) in enumerate( lambda_indices ) ]\n\treturn lambda_points, lambda_basis, combined_indices\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We actually only try to find points suitable points in the hypercube 01^n. The points can be (un)scaled with the usual methods. But for Polynomials we can actually use substition to make evaluation more effective.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"\"Return vector of polynomials that unscales variables from [0,1]^n to [lb,ub].\"\nfunction get_unscaling_poly( vars, lb, ub )\n    # we don't have to check for Inf here because of finite trust region\n    w = ub .- lb\n    return vars .* w .+ lb\nend\n\n\"Return vector of polynomials that scales variables from [lb, ub] to [0,1]^n.\"\nfunction get_scaling_poly( vars, lb, ub )\n    w = ub .- lb\n    return ( vars .- lb ) ./ w\nend","category":"page"},{"location":"LagrangeModel/#Method-Implementations","page":"LagrangeModels","title":"Method Implementations","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"We will use the functions from above in the prepare_XXX routines:\nThe initial prepare_init_model function should return a meta object that can be used to build an initial surrogate model. We delegate the work to prepare_update_model.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function prepare_init_model( cfg :: LagrangeConfig, objf :: AbstractObjective, mop :: AbstractMOP,\n\tid :: AbstractIterData, db :: AbstractDB, ac :: AbstractConfig;\n\tensure_fully_linear = true, kwargs...)\n\n    n_vars = num_vars( mop )\n\n\tmeta = LagrangeMeta(;\n        canonical_basis = get_poly_basis( cfg.degree, n_vars ),\n        out_indices = output_indices(objf, mop)\n    )\n\treturn prepare_update_model(nothing, objf, meta, mop, id, db, ac; ensure_fully_linear, kwargs... )\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"Usually, prepare_update_model would only accept a model as its first argument. Because of the trick from above, we actually allow nothing, too.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"\"\"\"\n    _consume_points(data_base, poised_points, poised_indices, candidate_indices)\n\nHelper to return array of database indices for `poised_points` and\n`poised_indices`. Add result to database if index is -1.\n`candidate_indices` are the database indices of the points from the trust region.\n\"\"\"\nfunction _consume_points( db, poised_points, poised_indices, candidate_indices, lb, ub, F )\n    interpolation_indices = Int[]\n    for (i,ind) in enumerate(poised_indices)\n        if ind < 0\n            # we need an additional new site\n            new_db_id = new_result!(db, _unscale(poised_points[i], lb, ub), F[] )\n            push!(interpolation_indices, new_db_id)\n        else\n            # we could recycle a candidate point\n            push!(interpolation_indices, candidate_indices[ind])\n        end\n    end\n    return interpolation_indices\nend\n\nfunction _scale_poly_basis( poised_basis, lb, ub )\n    # we modify the basis so that the input is scaled to [0,1]^n with respect to\n    # the enlarged trust region bounds, because the poisedness algos sought points there\n    poly_vars = variables( poised_basis[1] )\n    scaling_poly = get_scaling_poly( poly_vars, lb, ub )\n\n    zero_pol = sum( 0 .* poly_vars ) # TODO remove once https://github.com/JuliaAlgebra/DynamicPolynomials.jl/issues/92 is fixed\n\n    return [ subs(p, poly_vars => scaling_poly) + zero_pol for p in poised_basis ]\nend\n\nfunction prepare_update_model( mod :: Union{Nothing, LagrangeModel}, objf :: AbstractObjective,\n    meta :: LagrangeMeta,  mop :: AbstractMOP, iter_data :: AbstractIterData,\n    db :: AbstractDB, algo_config :: AbstractConfig;\n    ensure_fully_linear = true, kwargs... )\n\n    x = get_x( iter_data )\n    fx = get_fx( iter_data )\n    F = eltype(fx)\n    x_index = get_x_index( iter_data )\n    n_vars = length(x)\n    Δ = get_Δ( iter_data )\n\n    cfg = model_cfg(objf)\n    lb, ub = local_bounds(mop, x, Δ * cfg.θ_enlarge )\n\n    if cfg.optimized_sampling\n        # Find points in current trust region …\n        candidate_indices = [x_index; results_in_box_indices( db, lb, ub, [x_index,] )]\n        # … and scale them to [0,1]^n\n        candidate_points = [_scale(ξ, lb, ub) for ξ in get_site.(db, candidate_indices)]\n\n        # Get a poised set and lagrange basis\n        poised_points, poised_basis, poised_indices = get_poised_set(\n            meta.canonical_basis, candidate_points;\n            solver = cfg.algo1_solver, max_solver_evals = cfg.algo1_max_evals\n        )\n\n        fully_linear = false\n        # Make set even better\n        if ensure_fully_linear || !cfg.allow_not_linear\n            ### We would like to keep x if possible\n            skip_indices = let l = findfirst( i -> i == 1, poised_indices );\n                isnothing(l) ? [] : [l,]\n            end\n\n            poised_points, poised_basis, indices_2 = make_set_lambda_poised(\n                poised_basis, poised_points;\n                LAMBDA = cfg.LAMBDA, solver = cfg.algo2_solver,\n                max_solver_evals = cfg.algo2_max_evals, skip_indices\n            )\n            poised_indices = [ i < 0 ? i : poised_indices[j] for (j,i) in enumerate( indices_2 ) ]\n            fully_linear = true\n        end\n\n        interpolation_indices = _consume_points( db, poised_points, poised_indices, candidate_indices, lb, ub, F)\n        scaled_basis = _scale_poly_basis( poised_basis, lb, ub )\n\n        return LagrangeMeta(;\n            interpolation_indices,\n            out_indices = meta.out_indices,\n            canonical_basis = meta.canonical_basis,\n            lagrange_basis = scaled_basis,\n            fully_linear\n        )\n\n    else\n        # unoptimized sampling: we only look for a good point set once\n        # in the very first iteration and store the basis and the points\n        # in the meta data which is then passed through in subsequent iterations\n        lpoints, lbasis = if isnothing(meta.lagrange_basis)\n            candidate_points = [ fill(.5, n_vars) ]\n            lpoints, lbasis, _ = get_lambda_poised_set(\n                meta.canonical_basis, candidate_points;\n                solver1 = cfg.algo1_solver, solver2 = cfg.algo2_solver,\n                max_solver_evals1 = cfg.algo1_max_evals, max_solver_evals2 = cfg.algo2_max_evals,\n                LAMBDA = cfg.LAMBDA )\n\n            lpoints, _scale_poly_basis( lbasis, lb, ub )\n        else\n            meta.stamp_points, meta.lagrange_basis\n        end\n\n        candidate_indices = [x_index,]\n        @show lindices = fill(-1, length(lpoints))\n\n        # check if x (scaled to [0,1] wrt trust region bounds) is center of `lpoints`\n        #src TODO does using `≈` make problems for small trust region radii? `==` always fails\n        x_s = _scale(x, lb, ub)\n        x_in_points_index = findfirst(χ -> χ ≈ x_s, lpoints )\n        if !isnothing(x_in_points_index)\n             candidate_indices[ x_in_points_index ] = 1\n        end\n\n        interpolation_indices = _consume_points( db, lpoints, lindices, candidate_indices, lb, ub, F)\n\n        return LagrangeMeta(;\n            interpolation_indices,\n            out_indices = meta.out_indices,\n            lagrange_basis = lbasis,\n            stamp_points = lpoints,\n            fully_linear = true\n        )\n    end\nend#function","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The improvement preparation enforces a Λ-poised set:","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function prepare_improve_model( mod :: Union{Nothing, LagrangeModel}, objf :: AbstractObjective, meta :: LagrangeMeta,\n    mop :: AbstractMOP, iter_data :: AbstractIterData, db :: AbstractDB, algo_config :: AbstractConfig;\n    kwargs... )\n    return prepare_update_model( mod, objf, meta, mop, iter_data, db, algo_config; ensure_fully_linear = true, kwargs...)\nend","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"Now, in the 2-phase construction process, first all prepare_ functions are called for all surrogate models. Then, the unevaluated results are evaluated and we can proceed with the model building. As before, _init_model simply delegates work to update_model. \nNot much is left to do, only to retrieve the correct values from the database to use as coefficients. We also store the gradient (vector of polynomials) for each basis polynomial.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function _init_model( cfg :: LagrangeConfig, objf :: AbstractObjective, mop :: AbstractMOP,\n\titer_data :: AbstractIterData, db :: AbstractDB, ac :: AbstractConfig, meta :: LagrangeMeta; kwargs... )\n\treturn update_model( nothing, objf, meta, mop, iter_data, db, ac; kwargs... )\nend\n\nfunction update_model( mod::Union{Nothing,LagrangeModel}, objf:: AbstractObjective,\n    meta :: LagrangeMeta, mop :: AbstractMOP, iter_data :: AbstractIterData, db :: AbstractDB, ac :: AbstractConfig;\n\tkwargs... )\n\n    coeff = [ c[ meta.out_indices ] for c in get_value.(db, meta.interpolation_indices) ]\n\n    return LagrangeModel(;\n        coeff, fully_linear = meta.fully_linear,\n        basis = copy(meta.lagrange_basis),\n        # NOTE I don't know why I need to copy here\n        # but if i don't copy then testing fails:\n        # the meta data does hold a valid Lagrange basis but the model does not !?\n        grads = [ differentiate( p, variables(p) ) for p in meta.lagrange_basis ]\n    ), meta\nend\n\nfunction improve_model( mod::Union{Nothing,LagrangeModel}, objf:: AbstractObjective,\n    meta :: LagrangeMeta, mop :: AbstractMOP, iter_data :: AbstractIterData, db :: AbstractDB, ac :: AbstractConfig;\n\tkwargs... )\n    return update_model( mod, objf, meta, mop, iter_data, db, algo_config; kwargs...)\nend","category":"page"},{"location":"LagrangeModel/#Evaluation","page":"LagrangeModels","title":"Evaluation","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"The evaluation of some output is","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"sum_i=1^p c_i l_i( x )","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"where p = dim Π_n^d.","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"function _eval_poly_vec( poly_vec, x )\n    [ p(x) for p in poly_vec ]\nend\n\nfunction eval_models( lm :: LagrangeModel, x̂ :: Vec, ℓ :: Int)\n    return sum( c[ℓ] * p(x̂) for (c,p) in zip( lm.coeff, lm.basis ) )\nend\n\nfunction eval_models( lm :: LagrangeModel, x̂ :: Vec )\n    return sum( c * p(x̂) for (c,p) in zip( lm.coeff, lm.basis ) )\nend\n\nfunction get_gradient( lm :: LagrangeModel, x̂ :: Vec, ℓ :: Int )\n    sum( c[ℓ] * _eval_poly_vec(p,x̂) for (c,p) in zip( lm.coeff, lm.grads ) )\nend\n\nfunction get_jacobian( lm :: LagrangeModel, x̂ :: Vec )\n    grad_evals = [ _eval_poly_vec(p,x̂) for p in lm.grads ]\n    no_out = length(lm.coeff[1])\n    return transpose( hcat( (sum( c[ℓ] * g for (c,g) in zip( lm.coeff, grad_evals) ) for ℓ = 1 : no_out)... ) )\nend","category":"page"},{"location":"LagrangeModel/#Summary-and-Quick-Examples","page":"LagrangeModels","title":"Summary & Quick Examples","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"To use the default configuration for a scalar objective f do\nadd_objective!(mop, f, LagrangeConfig())\nFor a vector valued objective do\nadd_vector_objective!(mop, f, LagrangeConfig(); n_out = 2)\nIf you want a linear polyonmial only:\nadd_objective!(mop, f, LagrangeConfig(;degree=1))\nBy default, a new interpolation set is built in every iteration. To use a \"stamp\" instead, turn of optimized sampling:\nadd_objective!(mop, f, LagrangeConfig(;optimized_sampling=true))","category":"page"},{"location":"LagrangeModel/#Complete-usage-example","page":"LagrangeModels","title":"Complete usage example","text":"","category":"section"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"using Morbit\nMorbit.print_all_logs()\nmop = MixedMOP(3)\n\nF = x -> [ sum( ( x .- 1 ).^2 ); sum( ( x .+ 1 ).^2 ) ]\n\nadd_vector_objective!( mop, F, LagrangeConfig() )\n\nx_fin, f_fin, _ = optimize( mop, [-π, ℯ, 0])","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"","category":"page"},{"location":"LagrangeModel/","page":"LagrangeModels","title":"LagrangeModels","text":"This page was generated using Literate.jl.","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/examples/example_two_parabolas.jl\"","category":"page"},{"location":"example_two_parabolas/#Two-Parabolas","page":"Two Parabolas","title":"Two Parabolas","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"The “two parabolas” problem in two dimensions reads as","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"    min_𝐱  X \n    beginbmatrix f₁(mathbfx)  f₂(mathbfx) endbmatrix =\n    min_mathbfx  X\n    beginbmatrix\n    (x₁ - 1)² + (x₂ - 1)² \n    (x₁ + 1)² + (x₂ + 1)²\n    endbmatrix","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"It is unconstrained if the feasible set is X = ℝ^2. The individual minima 11 and -1-1 are such that (in the unconstrained case) the global Pareto Set is","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"mathcalP_S =  mathbfx  ℝ^2  x₁ = x₂  -1 le x₁ x₂ le 1  ","category":"page"},{"location":"example_two_parabolas/#Solve-using-Exact-Functions","page":"Two Parabolas","title":"Solve using Exact Functions","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"The gradients are easily calculated as","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"nabla f_1 (mathbf x) = 2 beginbmatrix\nx_1 -1  x_2 - 1 endbmatrix \nnabla f_2 (mathbf x) = 2 beginbmatrix\nx_1 +1  x_2 + 1 endbmatrix ","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"We can provide them to the solver to find a critical point:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"using Morbit\n\nf₁ = x -> sum( (x .- 1).^2 )\nf₂ = x -> sum( (x .+ 1).^2 )\n∇f₁ = x -> 2 .* ( x .- 1 )\n∇f₂ = x -> 2 .* ( x .+ 1 )\n\nmop = MixedMOP(2);  # problem with 2 variables\nadd_objective!(mop, f₁, ∇f₁ )\nadd_objective!(mop, f₂, ∇f₂ )\n\n#  starting point\nx₀ = [ -π ;  2.71828 ]\n\n#  set maximum number of iterations\nac = AlgoConfig( max_iter = 20)\n#  `optimize` will return parameter and result vectors as well\n#  as an return code and the evaluation database:\nx, fx, ret_code, db = optimize( mop, x₀; algo_config = ac );\nx","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"Hopefully, x is critical, i.e., x[1] ≈ x[2].","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"note: Note\nTo print more information on what the solver is doing, you can use the Logging module:import Logging: global_logger, ConsoleLogger\nglobal_logger( ConsoleLogger( stderr, Morbit.loglevel4;\n    meta_formatter = Morbit.morbit_formatter ) )loglevel4 is the most detailed and loglevel1 is least detailed. Morbit.print_all_logs() is a convenient shorthand.","category":"page"},{"location":"example_two_parabolas/#Plotting-Iteration-Sites","page":"Two Parabolas","title":"Plotting Iteration Sites","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"Let's retrieve the iteration sites. We convert to Tuples for easier plotting.","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"iteration_indices = [ iter_.x_index for iter_ in db.iter_info]\nit_sites = Tuple.(Morbit.get_site.(db, iteration_indices))","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"For Plotting we use CairoMakie","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"using Makie, CairoMakie\n\n#  Pareto Set ≙ line from (-1,-1) to (1,1)\nfig, ax, _ = lines( [(-1,-1),(1,1)]; color = :blue, linewidth = 2,\n    figure = (resolution = (600, 600),) )\n\n#  Plot the iteration sites:\nlines!(it_sites)\nscatter!(it_sites;\n    color = LinRange(0, 1, length(it_sites)),\n    colormap = :winter\n)\n\n#  Plot function contours\nY = X = LinRange(-4, 4, 100)\nZ₁ = [ f₁([x;y]) for x ∈ X, y ∈ X ]\nZ₂ = [ f₂([x;y]) for x ∈ X, y ∈ X ]\nlevels = [ i.^2 for i = LinRange(.1, 6, 6) ]\ncontour!(X,Y,Z₁; colormap = :greens, levels = levels, linewidth = .5 )\ncontour!(X,Y,Z₂; colormap = :heat, levels = levels, linewidth = .5 )\n\n#  Show the plot:\nax.title[] = \"Pareto Set and Iterates.\"\nax.xgridvisible[] = false\nax.ygridvisible[] = false\n\nfig","category":"page"},{"location":"example_two_parabolas/#Solving-using-RBF-Surrogates","page":"Two Parabolas","title":"Solving using RBF Surrogates","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"Suppose now that we do not have access to the objective gradients and that the objectives also take some time to evaluate. In this situation, we could try to model them using surrogate models. To use radial basis function models, pass an RbfConfig when specifying the objective:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"mop_rbf = MixedMOP()\n\n#  Define the RBF surrogates\nrbf_cfg = RbfConfig(\n    kernel = :inv_multiquadric\n)\n#  Add objective functions to `mop_rbf`\nadd_objective!(mop_rbf, f₁, rbf_cfg )\nadd_objective!(mop_rbf, f₂, rbf_cfg )\n\n#  only perform 10 iterations\nac = AlgoConfig( max_iter = 10 )\nx, fx, _, db = optimize( mop_rbf, x₀; algo_config = ac )\nx\n\niteration_indices_rbf = [ iter_.x_index for iter_ in db.iter_info]\nit_sites_rbf = Tuple.(Morbit.get_site.(db, iteration_indices_rbf))\nlines!(it_sites_rbf) #hide\nscatter!(it_sites_rbf; color = :orange) #hide","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"The iteration sites are the orange circles:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"fig #hide","category":"page"},{"location":"example_two_parabolas/#Different-Starting-Points-and-Recycling-Data","page":"Two Parabolas","title":"Different Starting Points and Recycling Data","text":"","category":"section"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"The method could converge to different points depending on the starting point. We can pass the evaluation data from previous runs to facilitate the construction of surrogate models:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"ac = AlgoConfig( #hide\n    max_iter = 10 #hide\n    ); #hide\nmop_rbf = MixedMOP(); #hide\n#  define the RBF surogates #hide\nrbf_cfg = RbfConfig(  #hide\n    kernel = :inv_multiquadric, #hide\n); #hide\n#  add objective functions to `mop_rbf` #hide\nadd_objective!(mop_rbf, f₁, rbf_cfg ); #hide\nadd_objective!(mop_rbf, f₂, rbf_cfg ); #hide\n\n#  an array of well spread points in [-4,4]² #hide\nX =[ #hide\n [-4.0, -4.0], #hide\n [3.727327839472812, 3.8615291196035457], #hide\n [3.804712690019901, -3.9610212058521235], #hide\n [-0.14512898384374573, -0.005775390168885508], #hide\n [-3.775315499879552, 3.8150054323309064], #hide\n [1.714228746087743, 1.8435786475209621], #hide\n [-1.9603720505875337, -2.0123206708499275], #hide\n [3.9953803225349187, -0.47734576293976794], #hide\n [-3.9944468955728745, 0.49857343385493635], #hide\n [-1.0455585089057458, 2.735699160002545] #hide\n]; #hide\n\n#  Suppose, `X` is a list of different points in ℝ².\n\n#  A dict to associate starting and end points:\nstart_fin_points = Dict();\n\n#  perform several runs:\ndb₀ = nothing # initial database can be `nothing`\nfor x₀ ∈ X\n    global db₀, start_fin_points\n    x_fin, fx_fin, _, db₀ = optimize( mop_rbf, x₀; algo_config = ac, populated_db = db₀ )\n    #  add points to dict\n    start_fin_points[x₀] = x_fin\nend","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"Plotting:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"fig, ax, _ = lines( [(-1,-1),(1,1)]; color = :blue, linewidth = 2,\n    figure = (resolution = (600, 600), ),\n    axis = (title=\"Different Starting Points\",),\n)\n\nfor (k,v) in start_fin_points\n    lines!( [ Tuple(k), Tuple(v) ]; color = :lightgray )\nend\n\nscatter!( Tuple.(keys(start_fin_points));\n    color = :green\n)\nscatter!( Tuple.(values(start_fin_points));\n    color = :lightblue\n)\n\nfig #hide","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"In the plot, the green points show the starting points and the lightblue circles show the final iterates:","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"","category":"page"},{"location":"example_two_parabolas/","page":"Two Parabolas","title":"Two Parabolas","text":"This page was generated using Literate.jl.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/custom_logging.jl\"","category":"page"},{"location":"custom_logging/#Printing-Debug-Info","page":"Pretty Printing","title":"Printing Debug Info","text":"","category":"section"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"We provide a custom formatter method and define our own log levels. The user can choose, how much information is printed and it should look nicer this way.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Log messages are only displayed if they have a LogLevel that is ≥ than a minimum log-level defined for the current logger. The current minimum log-level can be determined with","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Logging.min_enabled_level( Logging.current_logger() )","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"For more information see the docs. Usually, the minimum log level is -1.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"We have the following LogLevels and they can be referred to as Morbit.loglevel1 ect.:","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"const loglevel1 = LogLevel(-1);\nconst loglevel2 = LogLevel(-2);\nconst loglevel3 = LogLevel(-3);\nconst loglevel4 = LogLevel(-4);\nnothing #hide","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"The can be made visible by setting one of these levels with a custom logger. For example, to see the most detailled messages, do something like this:","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"logger = Logging.ConsoleLogger( stderr, Morbit.loglevel4 )\nLogging.global_logger(logger)","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Or use with_logger(logger) do … end to leave the global logger unchanged.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"For prettier output, we define custom colors and indented prefixes:","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"const printDict = Dict(\n    loglevel1 => (:blue, \"Morbit\"),\n    loglevel2 => (:cyan, \"Morbit \"),\n    loglevel3 => (:green, \"Morbit  \"),\n    loglevel4 => (:green, \"Morbit   \")\n)","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"These are used in the morbit_formatter. The morbit_formatter can be enabled for a logger, such as Logging.ConsoleLogger, by passing the keyword argument meta_formatter, i.e.,","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Logging.ConsoleLogger( stderr, Morbit.loglevel4; meta_formatter = morbit_formatter )","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"Note, that morbit_formatter is exported.","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"function morbit_formatter(level::LogLevel, _module, group, id, file, line)\n    @nospecialize\n\tglobal printDict\n    if level in keys(printDict)\n        color, prefix = printDict[ level ]\n        return color, prefix, \"\"\n    else\n        return Logging.default_metafmt( level, _module, group, id, file, line )\n    end\nend","category":"page"},{"location":"custom_logging/#Shorthand-Function","page":"Pretty Printing","title":"Shorthand Function","text":"","category":"section"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"The following (unexported) function sets the global logger to print everything:","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"function print_all_logs()\n    Logging.global_logger( Logging.ConsoleLogger( stderr, Morbit.loglevel4; meta_formatter = morbit_formatter ) )\nend","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"","category":"page"},{"location":"custom_logging/","page":"Pretty Printing","title":"Pretty Printing","text":"This page was generated using Literate.jl.","category":"page"},{"location":"notebook_finite_differences/","page":"Finite Differences","title":"Finite Differences","text":"<iframe id=\"fdnotebook\" src=\"../custom_assets/notebook_finite_differences.html\" width=\"100%\"></iframe>\n<!--<script src=\"../custom_assets/iframeResizer.min.js\"></srcipt>-->\n<script>\nconst iFrameResizerPath = '../custom_assets/iframeResizer.min.js';\n\nif (require) {\n  require([iFrameResizerPath], (iFrameResize) => iFrameResize())\n} else {\n  const script = document.createElement('script')\n  script.onload = () => iFrameResize()\n  script.src = iFrameResizerPath\n}\n</script>\n<script>\ndocument.addEventListener('DOMContentLoaded', function(){\n\tvar myIframe = document.getElementById(\"fdnotebook\");\n\tiFrameResize({log:true}, myIframe);\t\n});\n</script>","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/RbfModel.jl\"","category":"page"},{"location":"RbfModel/#Radial-Basis-Function-Surrogate-Models","page":"RbfModels","title":"Radial Basis Function Surrogate Models","text":"","category":"section"},{"location":"RbfModel/#Intro-and-Prerequisites","page":"RbfModels","title":"Intro and Prerequisites","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"We want to offer radial basis function (RBF) surrogate models (implementing the SurrogateModel interface). To this end, we leverage the package RadialBasisFunctionModels.jl. A scalar RBF model consists of a n-variate Polynomial and linear combination of shifted radial kernels. For more information, see the documentation of RadialBasisFunctionModels.jl.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"import RadialBasisFunctionModels as RBF\nusing LinearAlgebra: qr, Hermitian, cholesky, inv, I, givens, diag","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The polyonmials will have a degree of at most 1. To construct “good” linear polynomials, we need to make sure to have construction sites, that span the decision space well. Such a set of construction sites is called Λ-poised or sufficiently affinely independent. The file AffinelyIndependentPoints implements some helpers to find suitable points as described by Wild et. al.[wild_diss]","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"include(\"AffinelyIndependentPoints.jl\")","category":"page"},{"location":"RbfModel/#Surrogate-Interface-Implementations","page":"RbfModels","title":"Surrogate Interface Implementations","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The model used in our algorithm simply wraps an interpolation model from the RBF package.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"@with_kw struct RbfModel{R} <: SurrogateModel\n\tmodel :: R\n\n\t# indicator: is the model fully linear?\n\tfully_linear :: Bool = false\nend\n\nfully_linear( rbf :: RbfModel ) :: Bool = rbf.fully_linear","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"We offer a large range of configuration parameters in the RBFConfig, which implements a SurrogateConfig.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"\"\"\"\n    RbfConfig(; kwarg1 = val1, … )\n\nConfiguration type for local RBF surrogate models.\n\nTo choose a kernel, use the kwarg `kernel` and a value of either\n`:cubic` (default), `:inv_multiquadric`, `:multiquadric`, `:gaussian` or `:thin_plate_spline`.\nThe kwarg `shape_parameter` takes a constant number or a string\nthat defines a calculation on `Δ`, e.g, \"Δ/10\".\nNote, that `shape_parameter` has a different meaning for the different kernels.\nFor ``:gaussian, :inv_multiquadric, :multiquadric` it actually is a floating point shape_parameter.\nFor :cubic it is the (odd) integer exponent and for `thin_plate_spline` it is an integer exponent as well.\nUse `NaN` for defaults.\n\nTo see other configuration parameters use `fieldnames(Morbit.RbfConfig)`.\nThey have individual docstrings attached.\n\"\"\"\n@with_kw mutable struct RbfConfig <: SurrogateConfig\n    \"(default `:cubic`) RBF kernel (Symbol), either `:cubic`, `:multiquadric`, `:exp` or `:thin_plate_spline`.\"\n    kernel :: Symbol = :cubic\n\n\t\"(default `1`) RBF shape paremeter, either a number or a string containing `Δ`.\"\n    shape_parameter :: Union{String, Float64} = NaN\n\n\t\"(default `1`) Degree of polynomial attached to RBF. `-1` means no polynomial.\"\n    polynomial_degree :: Int64 = 1;\n\n    \"(default `2`) Local enlargment factor of trust region for sampling.\"\n    θ_enlarge_1 :: Float64 = 2\n\n\t\"(default `5`) Maximum enlargment factor of maximum trust region for sampling.\"\n    θ_enlarge_2 :: Float64 = 2\n\n\t\"(default `1/(2*θ_enlarge_1)` Sampling parameter to generate Λ-poised set. The higher, the more poised.\"\n    θ_pivot :: Float64 = 1 / (2 * θ_enlarge_1)\n\n\t\"(default `1e-7`) Parameter for 2nd sampling algorithm to ensure boundedness of Cholesky factors.\"\n    θ_pivot_cholesky :: Float64 = 1e-7\n\n    \"(default `false`) Require models to be fully linear in each iteration.\"\n    require_linear :: Bool = false\n\n    \"(default `-1`) Maximum number of training sites. `-1` is reset to `2n+1`.\"\n    max_model_points :: Int64 = -1 # is probably reset in the algorithm\n    \"(default `false`) Sample new sites to always use the maximum number of points.\"\n    use_max_points :: Bool = false\n\n\t\"Whether or not to re-construct the training set in each iteration.\"\n\toptimized_sampling = true\n\n#    \"(default `:orthogonal`) Algorithm to use for finding affinely independent set.\"\n#    sampling_algorithm :: Symbol = :orthogonal # :orthogonal or :monte_carlo\n\n##\t\"(default `:standard_rand`) Algorithm to use if additional points are required.\"\n#    sampling_algorithm2 :: Symbol = :standard_rand\n\n    \"(default `typemax(Int64)`) Maximum number of objective evaluations.\"\n    max_evals :: Int64 = typemax(Int64)\n\n\t@assert θ_enlarge_1 * θ_pivot ≤ 1 \"θ_pivot must be <= θ_enlarge_1^(-1).\"\n\n##\t@assert sampling_algorithm ∈ [:orthogonal, :monte_carlo] \"Sampling algorithm must be either `:orthogonal` or `:monte_carlo`.\"\n    @assert kernel ∈ Symbol.([\"gaussian\", \"inv_multiquadric\", \"multiquadric\", \"cubic\", \"thin_plate_spline\"]) \"Kernel '$kernel' not supported yet.\"\n\t# Some sanity checks for the shape parameters\n    @assert kernel != :thin_plate_spline || ( isnan(shape_parameter) || shape_parameter % 1 == 0 && shape_parameter >= 1 ) \"Invalid shape_parameter for :thin_plate_spline.\"\n\t@assert kernel != :cubic || ( isnan(shape_parameter) || shape_parameter % 1 == 0 && shape_parameter % 2 == 1 ) \"Invalid shape_parameter for :cubic.\"\n\t@assert (isa( shape_parameter, String ) || isnan(shape_parameter)) || shape_parameter > 0 \"Shape parameter must be strictly positive.\"\n    # @assert θ_enlarge_1 >=1 && θ_enlarge_2 >=1 \"θ's must be >= 1.\"\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The required method implementations are straightforward. Note, thate we allow the models to be combined to vector functions if they share the same configuration to avoid redundant efforts whilst constructing models.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"max_evals( cfg :: RbfConfig ) :: Int = cfg.max_evals\ncombinable( cfg :: RbfConfig ) :: Bool = true\ncombine(cfg1 :: RbfConfig, :: RbfConfig) :: RbfConfig = cfg1","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"We also need to introduce our own implementation for isequal and hash for RbfConfigs to be combinable, see the docs too.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function Base.hash( cfg :: RbfConfig, h :: UInt )\n\treturn hash( getfield.( cfg, Tuple( fn for fn ∈ fieldnames(RbfConfig) ) ), h )\nend\nfunction Base.isequal( cfg1 :: RbfConfig, cfg2 :: RbfConfig )\n\tall( isequal( getfield(cfg1, fn), getfield(cfg2, fn) ) for fn in fieldnames( RbfConfig) )\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"To allow the user to set the shape parameter relative to the current trust region radius using a verbose string, we need this little helper function, which evaluates the string.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function parse_shape_param_string( Δ :: F, expr_str) :: F where F\n    ex = Meta.parse(expr_str)\n    sp = @eval begin\n        let Δ=$Δ\n            $ex\n        end\n    end\n\treturn sp\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The RbfMeta is used to store construction and update data for the models. To be specific, we have several inidices lists that store database indices of (potentially unevaluated) results that are later used for fitting the model.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"@with_kw mutable struct RbfMeta{F<:AbstractFloat} <: SurrogateMeta\n    center_index :: Int = -1\n    round1_indices :: Vector{Int} = []\n    round2_indices :: Vector{Int} = []\n    round3_indices :: Vector{Int} = []\n    round4_indices :: Vector{Int} = []\n    fully_linear :: Bool = false\n\timproving_directions :: Vector{Vector{F}} = []\nend\n\n\nsaveable_type( meta :: T ) where {T<:RbfMeta} = T\nsaveable( meta :: RbfMeta ) = deepcopy(meta)","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"A little helper to retrieve all those indices:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _collect_indices( meta :: RbfMeta; include_x = true ) :: Vector{Int}\n\treturn [\n\t\tinclude_x ? meta.center_index : [];\n\t\tmeta.round1_indices;\n\t\tmeta.round2_indices;\n\t\tmeta.round3_indices;\n\t\tmeta.round4_indices\n\t]\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"And a helper, to partially copy some data from src to dest. This is due to the fact, that the first 3 rounds of construction data gathering are the same for all possible RBF models and we can safe some effort.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function copy_meta!(dest, src)\n\tdest.center_index = src.center_index\n\tfor fn in [ Symbol(\"round$(i)_indices\") for i = 1: 3 ]\n\t\tdest_arr = getfield(dest, fn)\n\t\tempty!( dest_arr )\n\t\tappend!( dest_arr, getfield( src, fn) )\n\tend\n\tempty!(dest.improving_directions)\n\tappend!(dest.improving_directions, src.improving_directions)\nend\n\nexport RbfConfig, RbfMeta, RbfModel","category":"page"},{"location":"RbfModel/#Construction","page":"RbfModels","title":"Construction","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The initial prepare_init_model function should return a meta object that can be used to build an initial surrogate model. We delegate the work to prepare_update_model.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function prepare_init_model( cfg :: RbfConfig, objf :: AbstractObjective, mop :: AbstractMOP,\n\tid :: AbstractIterData{F}, db :: AbstractDB, ac :: AbstractConfig;\n\tensure_fully_linear = true, kwargs...) where F<:AbstractFloat\n\tmeta = RbfMeta{F}()\n\treturn prepare_update_model(nothing, objf, meta, mop, id, db, ac; ensure_fully_linear = true, kwargs... )\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"Usually, prepare_update_model would only accept a model as its first argument. Because of the trick from above, we actually allow nothing, too.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function prepare_update_model( mod :: Union{Nothing, RbfModel}, objf :: AbstractObjective, meta :: RbfMeta,\n\tmop :: AbstractMOP, iter_data :: AbstractIterData, db :: AbstractDB, algo_config :: AbstractConfig;\n\tensure_fully_linear = false, force_rebuild = false, meta_array = nothing )\n\n\t!force_rebuild && @logmsg loglevel2 \"Trying to find results for fitting an RBF model.\"\n\n\t# Retrieve current iteration information and some meta data.\n\tΔ = get_Δ(iter_data)\n\tΔ_max = Δᵘ(algo_config)\n\tx = get_x(iter_data)\n\tx_index = get_x_index(iter_data)\n\tcfg = model_cfg( objf )\n\n\tF = eltype(x)\n\tn_vars = length(x)\n\n\t# Can we skip the first rounds? (Because we already found interpolation sets for other RBFModels?)\n\tall_objfs = list_of_objectives(mop)\n\tskip_first_rounds = false\n\tfor (i,other_meta) in enumerate(meta_array)\n\t\tother_objf = all_objfs[i]\n\t\tif other_meta isa RbfMeta\n\t\t\tother_cfg = model_cfg(other_objf)\n\t\t\tif other_cfg.θ_pivot == cfg.θ_pivot && other_cfg.θ_enlarge_1 == cfg.θ_enlarge_1 &&\n\t\t\t\tother_cfg.θ_enlarge_2 == cfg.θ_enlarge_2 && other_cfg.optimized_sampling == cfg.optimized_sampling\n\t\t\t\tcopy_meta!( meta, other_meta )\n\t\t\t\tskip_first_rounds = true\n\t\t\tend\n\t\tend\n\tend\n\n\t# By default, assume that our model is not fully linear\n\tmeta.fully_linear = false\n\n\t# use center as first training site ⇒ at least `n_vars` required still\n\tmeta.center_index = x_index\n\n\t# First round of sampling:\n\t### Try to find points in slightly enlarged trust region\n\tΔ_1 = F.(cfg.θ_enlarge_1 * Δ)\n\tlb_1, ub_1 = local_bounds( mop, x, Δ_1 )\n\tpiv_val_1 = F.(cfg.θ_pivot * Δ_1) # threshold value for acceptance in filter\n\n\t### `Δ_2` is the maximum allowed trust region radius and used in rounds 2 & 4\n\tΔ_2 = F.(cfg.θ_enlarge_2 * Δ_max )\n\tlb_2, ub_2 = local_bounds( mop, x, Δ_2 )\n\tpiv_val_2 = piv_val_1 # the pivot value stays the same\n\n\tskip_first_rounds && @goto round4\n\n\tif force_rebuild || !cfg.optimized_sampling\n\t\t### `force_rebuild` makes us skip the point searching procedures to …\n\t\t### … rebuild the model along the coordinate axes.\n\t\tfiltered_indices_1 = Int[]\n\t\timproving_directions = [ [zeros(F,i-1); one(F); zeros(F,n_vars - i)] for i = 1:n_vars ]\n\telse\n\t\t@logmsg loglevel3 \"Round1: Inspect box with radius $(Δ_1) and pivot value $(piv_val_1).\"\n\n\t\t### only consider points from within current trust region …\n\t\tcandidate_indices_1 = results_in_box_indices( db, lb_1, ub_1, [x_index],)\n\n\t\t### … and filter them to obtain affinely independent points.\n\t\tfilter = AffinelyIndependentPointFilter(;\n\t\t\tx_0 = x,\n\t\t\tseeds = get_site.(db, candidate_indices_1),\n\t\t\treturn_indices = true,\n\t\t\tpivot_val = piv_val_1\n\t\t)\n\n\t\tfiltered_indices_1 = candidate_indices_1[ collect( filter ) ]\n\t\timproving_directions = reverse(collect(Vector{F}, eachcol(filter.Z)))\n\n\t\t@logmsg loglevel3 \"Round1: Found $(length(filtered_indices_1)) sites in database.\"\n\tend\n\t### Store indices in meta data object:\n\tempty!(meta.round1_indices)\n\tappend!(meta.round1_indices, filtered_indices_1)\n\tempty!(meta.improving_directions)\n\tappend!(meta.improving_directions, improving_directions )\n\n\t# Second round of sampling:\n\t### If there are not enough sites to have a fully linear model …\n\t### … try to at least find more sites in maximum allowed radius\n\tn_missing = n_vars - length( meta.round1_indices )\n\n\tif n_missing == 0 || force_rebuild || !cfg.optimized_sampling || ensure_fully_linear || Δ ≈ Δ_max && cfg.θ_enlarge_1 == cfg.θ_enlarge_2\n\t\t@logmsg loglevel3 \"Skipping round 2.\"\n\n\t\tmeta.fully_linear = true\n\t\tfilter_2 = filter\n\t\tempty!(meta.round2_indices)\n\telse\n\t\t### actually perform round 2\n\n\t\t@logmsg loglevel3 \"Missing $(n_missing) sites still.\"\n\t\t@logmsg loglevel3 \"Round2: Inspect box with radius $(Δ_2) and pivot value $(piv_val_1).\"\n\n\t\t### as before, only consider points in box of radius `Δ_2`, but ignore `x` and the previous points\n\t\tcandidate_indices_2 = results_in_box_indices( db, lb_2, ub_2, [x_index; candidate_indices_1])\n\n\t\tfilter_2 = AffinelyIndependentPointFilter(;\n\t\t\tx_0 = x,\n\t\t\tseeds = get_site.(db, candidate_indices_2),\n\t\t\tY = filter.Y,\t# pass prior matrices, so that new points are projected onto span of Z\n\t\t\tZ = filter.Z,\n\t\t\tn = n_missing,\n\t\t\treturn_indices = true,\n\t\t\tpivot_val = piv_val_2\n\t\t)\n\n\t\tfiltered_indices_2 = candidate_indices_2[ collect(filter_2) ]\n\n\t\t### Store indices\n\t\tempty!(meta.round2_indices)\n\t\tappend!(meta.round2_indices, filtered_indices_2)\n\n\t\t@logmsg loglevel3 \"Round2: Found $(length(meta.round2_indices)) sites and model is $(meta.fully_linear ? \"\" : \"not \" )fully linear.\"\n\tend\n\n\t# Round 3:\n\t### If we still don't have enough sites, generate them\n\t### along model improving directions (from first round of sampling)\n\n\tn_missing -= length(meta.round2_indices)\n\tempty!(meta.round3_indices)\n\tif n_missing > 0\n\n\t\t@logmsg loglevel3 \"Round3: Still missing $(n_missing). Sampling in box of radius $(Δ_1).\"\n\n\t\t### If round 2 did not yield any new points, the model will hopefully be made fully linear now.\n\t\tif length(meta.round2_indices) == 0\n\t\t\tmeta.fully_linear = true\n\t\tend\n\n\t\t### Take into consideration the maximum number of evaluations allowed:\n\t\tmax_new = min( max_evals(algo_config), max_evals(cfg) ) - 1 - num_evals( objf )\n\t\tn_new = min(n_missing, max_new)\n\n\t\tnew_points = Vector{F}[]\n\t\twhile !isempty(meta.improving_directions) && length( new_points ) < n_new\n\t\t\tdir = popfirst!( meta.improving_directions )\n\t\t\tlen = intersect_bounds( x, dir, lb_1, ub_1; return_vals = :absmax )\n\t\t\toffset = len .* dir\n\t\t\tif norm( offset, Inf ) <= piv_val_1\n\t\t\t\t### the new point does not pass the thresholding test\n\t\t\t\tif ensure_fully_linear && !force_rebuild\n\t\t\t\t\t### If we need a fully linear model, we dismiss the inidices gathered so far …\n\t\t\t\t\t### … and call for a rebuild along the coordinate axis:\n\t\t\t\t\treturn prepare_update_model(mod, objf, meta, mop, iter_data, db, algo_config; ensure_fully_linear = true, force_rebuild = true)\n\t\t\t\telse\n\t\t\t\t\t### we include the point nonetheless, but the model will not qualify as fully linear...\n\t\t\t\t\tmeta.fully_linear = false\n\t\t\t\tend\n\t\t\tend\n\t\t\tpush!( new_points, x .+ offset )\n\t\tend\n\n\t\t### by adding the points to the database at this point in time we avoid\n\t\t### requesting unnecessary results from a round 3 interrupted by rebuilding\n\t\tnew_indices = Int[]\n\t\tfor p ∈ new_points\n\t\t\tnew_id = new_result!( db, p, F[] )\n\t\t\tpush!(new_indices, new_id)\n\t\tend\n\n\t\tappend!(meta.round3_indices, new_indices)\n\tend\n\n\t@label round4\n\n\t# In round 4 we have found `n_vars + 1` training sites and try to find additional points within the\n\t# largest possible trust region.\n\tempty!(meta.round4_indices)\n\n\tif cfg.optimized_sampling\n\n\t\tmax_points = cfg.max_model_points <= 0 ? 2 * n_vars + 1 : cfg.max_model_points\n\t\tindices_found_so_far = _collect_indices( meta )\n\t\tN = length(indices_found_so_far)\n\n\t\tcandidate_indices_4 = results_in_box_indices( db, lb_2, ub_2, indices_found_so_far )\n\n\t\tmax_tries = 10 * max_points\n\t\tnum_tries = 0\n\n\t\tif N < max_points && ( !isempty(candidate_indices_4) || cfg.use_max_points )\n\t\t\t@logmsg loglevel3 \"Round4: Can we find $(max_points - N) additional sites?\"\n\t\t\tround4_indices = Int[]\n\n\t\t\tchol_pivot = cfg.θ_pivot_cholesky\n\n\t\t\tcenters = get_site.(db, indices_found_so_far)\n\t\t\tφ = _get_radial_function( Δ, cfg )\n\t\t\tΦ, Π, kernels, polys = RBF.get_matrices( φ, centers; poly_deg = cfg.polynomial_degree )\n\n\t\t\t# prepare matrices as by Wild, R has to be augmented by rows of zeros\n\t\t\tQ, R = qr( transpose(Π) )\n\t\t\tR = [\n\t\t\t\tR;\n\t\t\t\tzeros( size(Q,1) - size(R,1), size(R,2) )\n\t\t\t]\n\t\t\tZ = Q[:, N + 1 : end ] ## columns of Z are orthogonal to Π\n\n\t\t\t# Note: usually, Z, ZΦZ and L should be empty (if N == n_vars + 1)\n\t\t\tZΦZ = Hermitian(Z'Φ*Z)\t## make sure, it is really symmetric\n\t\t\tL = cholesky( ZΦZ ).L   ## perform cholesky factorization\n\t\t\tL⁻¹ = inv(L)\t\t\t\t ## most likely empty at this point\n\n\t\t\tφ₀ = Φ[1,1]\n\n\t\t\t@logmsg loglevel3 \"Round4: Considering $(length(candidate_indices_4)) candidates.\"\n\n\t\t\twhile N < max_points && num_tries <= max_tries\n\n\t\t\t\tif !isempty( candidate_indices_4 )\n\t\t\t\t\tid = popfirst!( candidate_indices_4 )\n\t\t\t\t\t### get candidate site ξ ∈ ℝⁿ\n\t\t\t\t\tξ = get_site( db, id )\n\t\t\t\telse\n\t\t\t\t\tif cfg.use_max_points\n\t\t\t\t\t\t### there are no more sites in the db, but we **want**\n\t\t\t\t\t\t### to use as many as possible\n\t\t\t\t\t\tid = -1\n\t\t\t\t\t\tξ = _rand_box_point( lb_2, ub_2, F)\n\t\t\t\t\t\tnum_tries += 1\n\t\t\t\t\telse\n\t\t\t\t\t\tbreak\n\t\t\t\t\tend\n\t\t\t\tend\n\n\t\t\t\t### apply all RBF kernels\n\t\t\t\tφξ = kernels( ξ )\n\n\t\t\t\t### apply polynomial basis system and augment polynomial matrix\n\t\t\t\tπξ = polys( ξ )\n\t\t\t\tRξ = [ R; πξ' ]\n\n\t\t\t\t### perform Givens rotations to turn last row in Rξ to zeros\n\t\t\t\trow_index = size( Rξ, 1)\n\t\t\t\tG = Matrix(I, row_index, row_index) # whole orthogonal matrix\n\t\t\t\tfor j = 1 : size(R,2)\n\t\t\t\t\t# in each column, take the diagonal as pivot to turn last elem to zero\n\t\t\t\t\tg = givens( Rξ[j,j], Rξ[row_index, j], j, row_index )[1]\n\t\t\t\t\tRξ = g*Rξ;\n\t\t\t\t\tG = g*G;\n\t\t\t\tend\n\n\t\t\t\t### now, from G we can update the other matrices\n\t\t\t\tGᵀ = transpose(G)\n\t\t\t\tg̃ = Gᵀ[1 : end-1, end]\n\t\t\t\tĝ = Gᵀ[end, end]\n\n\t\t\t\tQg = Q*g̃;\n\t\t\t\tv_ξ = Z'*( Φ*Qg + φξ .* ĝ )\n\t\t\t\tσ_ξ = Qg'*Φ*Qg + (2*ĝ) * φξ'*Qg + ĝ^2*φ₀\n\n\t\t\t\tτ_ξ² = σ_ξ - norm( L⁻¹ * v_ξ, 2 )^2\n\t\t\t\t# τ_ξ (and hence τ_ξ^2) must be bounded away from zero\n\t\t\t\t# for the model to remain fully linear\n\t\t\t\tif τ_ξ² > chol_pivot\n\n\t\t\t\t\tif id < 0\n\t\t\t\t\t\tid = new_result!( db, ξ, F[] )\n\t\t\t\t\tend\n\t\t\t\t\tpush!(round4_indices, id)\t# accept the result\n\n\t\t\t\t\tτ_ξ = sqrt(τ_ξ²)\n\n\t\t\t\t\t# zero-pad Q and multiply with Gᵗ\n\t\t\t\t\tQ = [\n\t\t\t\t\t\tQ \t\t\t\t\tzeros( size(Q,1), 1);\n\t\t\t\t\t\tzeros(1, size(Q,2)) 1\n\t\t\t\t\t] * Gᵀ\n\n\t\t\t\t\tZ = [\n\t\t\t\t\t\tZ  \t\t\t\t\t\tQg;\n\t\t\t\t\t\tzeros(1, size(Z,2)) \tĝ\n\t\t\t\t\t]\n\n\t\t\t\t\tL = [\n\t\t\t\t\t\tL          zeros(size(L,1), 1) ;\n\t\t\t\t\t\tv_ξ'L⁻¹'   τ_ξ\n\t\t\t\t\t]\n\n\t\t\t\t\tL⁻¹ = [\n\t\t\t\t\t\tL⁻¹                zeros(size(L⁻¹,1),1);\n\t\t\t\t\t\t-(v_ξ'L⁻¹'L⁻¹)./τ_ξ   1/τ_ξ\n\t\t\t\t\t]\n\n\t\t\t\t\tR = Rξ\n\n\t\t\t\t\t# finally, augment basis matrices and add new kernel for next iteration\n\t\t\t\t\tΠ = [ Π πξ ]\n\n\t\t\t\t\tΦ = [\n\t\t\t\t\t\tΦ   φξ;\n\t\t\t\t\t\tφξ' φ₀\n\t\t\t\t\t]\n\t\t\t\t\tpush!( kernels, RBF.make_kernel(φ, ξ) )\n\n\t\t\t\t\t# assert all( diag( L * L⁻¹) .≈ 1 )\n\t\t\t\t\tN += 1\n\t\t\t\tend#if\n\t\t\tend#for\n\t\t\tappend!(meta.round4_indices, round4_indices)\n\t\t\t@logmsg loglevel3 \"Round4: found $(length(round4_indices)) additional sites.\"\n\t\tend#if\n\tend# if cfg.optimized_sampling\n\n\treturn meta\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"note: Note\nAt the moment, we do not store the matrices calculated in round 4 of the update procedure. This could be done to save some work when actually calculating the coefficients.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"In contrast to the old RBF mechanism, the models in RadialBasisFunctionModels sometimes accept 2 parameters for the kernel. We use this little helper, to get defaults from the shape parameter. Note, that sanity check are performed in the RbfConfig constructor.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _get_kernel_params( Δ , cfg )\n\n\tsp = if cfg.shape_parameter isa String\n\t\tparse_shape_param_string( Δ, cfg.shape_parameter )\n\telse\n\t\tF(cfg.shape_parameter)\n\tend\n\n\tisnan(sp) && return nothing\n\n\tkernel_name = cfg.kernel\n\n\tif kernel_name == :gaussian\n\t\treturn sp\n\telseif kernel_name == :inv_multiquadric\n\t\treturn (sp, 1//2)\n\telseif kernel_name == :multiquadric\n\t\treturn (sp, 1//2)\n\telseif kernel_name == :cubic\n\t\treturn Int(sp)\n\telseif kernel_name == :thin_plate_spline\n\t\treturn Int(sp)\n\telse\n\t\treturn sp\n\tend\nend\n\nfunction _get_radial_function( Δ, cfg )\n\tkernel_params = _get_kernel_params( Δ, cfg )\n\n\treturn RBF._get_rad_func( cfg.kernel, kernel_params )\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"An improvement step consists of adding a new site to the database, along an improving direction:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function prepare_improve_model( mod :: Union{Nothing, RbfModel}, objf :: AbstractObjective,\n\tmeta :: RbfMeta, mop :: AbstractMOP, iter_data :: AbstractIterData, db :: AbstractDB,\n\talgo_config :: AbstractConfig; kwargs... )\n\tif !meta.fully_linear\n\t\tif isempty(meta.improving_directions)\n\t\t\t@warn \"RBF model is not fully linear, but there are no improving directions.\"\n\t\telse\n\t\t\tcfg = model_cfg(objf)\n\t\t\tx = get_x(iter_data)\n\t\t\tfx = get_fx(iter_data)\n\t\t\tF = typeof(fx)\n\t\t\tΔ = get_Δ(iter_data)\n\t\t\tΔ_1 = Δ * cfg.θ_enlarge_1\n\t\t\tlb_1, ub_1 = local_bounds(mop, x, Δ_1)\n\t\t\tpiv_val_1 = Δ_1 * cfg.θ_pivot\n\n\t\t\tsuccess = false\n\t\t\tdir = popfirst!( meta.improving_directions )\n\t\t\tlen = intersect_bounds( x, dir, lb_1, ub_1; return_vals = :absmax )\n\t\t\toffset = len .* dir\n\t\t\tif norm( offset, Inf ) > piv_val_1\n\t\t\t\tnew_id = new_result!( db, x .+ offset, F() )\n\t\t\t\tpush!(meta.round1_indices, new_id)\n\t\t\t\tsuccess = true\n\t\t\tend\n\n\t\t\tsuccess && @logmsg loglevel3 \"Performed an improvement step.\"\n\t\t\tif isempty( meta.improving_directions ) && success\n\t\t\t\tmeta.fully_linear = true\n\t\t\t\t@logmsg loglevel3 \"The RBF Model is now fully linear.\"\n\t\t\tend\n\t\tend\n\tend\n\treturn meta\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"Now, in the 2-phase construction process, first all prepare_ functions are called for all surrogate models. Then, the unevaluated results are evaluated and we can proceed with the model building. As before, _init_model simply delegates work to update_model.","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function _init_model( cfg :: RbfConfig, objf :: AbstractObjective, mop :: AbstractMOP,\n\titer_data :: AbstractIterData, db :: AbstractDB, ac :: AbstractConfig, meta :: RbfMeta; kwargs... )\n\treturn update_model( nothing, objf, meta, mop, iter_data, db, ac; kwargs... )\nend\n\nfunction update_model( mod::Union{Nothing,RbfModel}, objf:: AbstractObjective, meta :: RbfMeta,\n\tmop :: AbstractMOP, iter_data :: AbstractIterData, db :: AbstractDB, ac :: AbstractConfig;\n\tkwargs... )\n\n\tkernel_params = _get_kernel_params( Δ, cfg )\n\n\t# get the training data from `meta` and the database `db`\n\ttraining_indices = _collect_indices( meta )\n\ttraining_results = get_result.( db, training_indices )\n\ttraining_sites = get_site.( training_results )\n\toi = output_indices( objf, mop)\t# only consider the objective output indices\n\ttraining_values = [ v[oi] for v in get_value.( training_results ) ]\n\n\tinner_model = RBF.RBFInterpolationModel( training_sites, training_values, cfg.kernel, kernel_params; save_matrices = false )\n\n\t@logmsg loglevel3 \"The model is $(meta.fully_linear ? \"\" : \"not \")fully linear.\"\n\treturn RbfModel( inner_model, meta.fully_linear ), meta\n\nend","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"The improvement function also simply cals the update function:","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"function improve_model( mod::Union{Nothing,RbfModel}, objf:: AbstractObjective, meta :: RbfMeta,\n\tmop :: AbstractMOP, id :: AbstractIterData, db :: AbstractDB, ac :: AbstractConfig; kwargs... )\n\treturn update_model( mod, objf, meta, mop, id, db, ac; kwargs... )\nend","category":"page"},{"location":"RbfModel/#Evaluation","page":"RbfModels","title":"Evaluation","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"All the work is done by the inner model :)","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"\"Evaluate `mod::RbfModel` at scaled site `x̂`.\"\nfunction eval_models( mod :: RbfModel, x̂ :: Vec)\n\treturn mod.model( x̂ )\nend\n\n\"Evaluate output `ℓ` of `mod::RbfModel` at scaled site `x̂`.\"\nfunction eval_models( mod :: RbfModel, x̂ :: Vec, ℓ :: Int)\n\treturn mod.model( x̂, ℓ)\nend\n\n@doc \"Gradient vector of output `ℓ` of `mod` at scaled site `x̂`.\"\nfunction get_gradient( mod :: RbfModel, x̂ :: Vec, ℓ :: Int64)\n    return RBF.grad( mod.model, x̂, ℓ )\nend\n\n@doc \"Jacobian Matrix of ExactModel `em` at scaled site `x̂`.\"\nfunction get_jacobian( mod :: RbfModel, x̂ :: Vec )\n    return RBF.jac( mod.model, x̂ )\nend","category":"page"},{"location":"RbfModel/#Summary-and-Quick-Examples","page":"RbfModels","title":"Summary & Quick Examples","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"To use the default configuration for a scalar objective f do\nadd_objective!(mop, f, RbfConfig())\nFor a vector valued objective do\nadd_vector_objective!(mop, f, RbfConfig(); n_out = 2)\nIf you don't want to use a polynomial:\nadd_objective!(mop, f, RbfConfig(;kernel = :cubic, polynomial_degree = -1 ))\nThis only works for certain kernels. polynomial_degree = 0 will add a constant term.\nTo require sampling of the maximum number of allowed model points:\nRbfConfig(;use_max_points = true)\nTo only sample along the coordinate axis:\nRbfConfig(;optimized_sampling = false)\nIf polynomial_degree == 1 the model will now be a linear interpolation model.","category":"page"},{"location":"RbfModel/#Complete-usage-example","page":"RbfModels","title":"Complete usage example","text":"","category":"section"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"using Morbit\nMorbit.print_all_logs()\nmop = MixedMOP(3)\n\nF = x -> [ sum( ( x .- 1 ).^2 ); sum( ( x .+ 1 ).^2 ) ]\n\nadd_vector_objective!( mop, F, RbfConfig() )\n\nx_fin, f_fin, _ = optimize( mop, [-π, ℯ, 0])","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"[wild_diss]: “Derivative-Free Optimization Algorithms For Computationally Expensive Functions”, Stefan M. Wild, 2009","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"","category":"page"},{"location":"RbfModel/","page":"RbfModels","title":"RbfModels","text":"This page was generated using Literate.jl.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/TaylorModel.jl\"","category":"page"},{"location":"TaylorModel/#Taylor-Polynomial-Models","page":"TaylorModels","title":"Taylor Polynomial Models","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"We provide vector valued polynomial Taylor models of degree 1 or 2. They implement the SurrogateModel interface.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"We allow the user to either provide gradient and hessian callback handles or to request finite difference approximations. For using callbacks, we have TaylorConfigCallbacks. \nThere are two ways to use finite differences. The old (not recommended way) is to use TaylorConfigFiniteDiff. This uses FiniteDiff.jl and could potentially require more evaluations. \nTo make use of the new 2-phase construction procedure, use TaylorConfig and set the fields gradients and hessians to an RFD.FiniteDiffStamp. If they use the same stamp (default: RFD.CFDStamp(1,3) :: CFDStamp{3,Float64}), it should be the most efficient, because we get the gradients for free from computing the hessians.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"include(\"RecursiveFiniteDifferences.jl\")\n\nusing .RecursiveFiniteDifferences\nconst RFD = RecursiveFiniteDifferences","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The actual model is defined only by the gradient vectors at x₀ and the Hessians (if applicable).","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"@with_kw struct TaylorModel{\n    XT <: AbstractVector{<:Real}, FXT <: AbstractVector{<:Real},\n    G <: AbstractVector{<:AbstractVector{<:Real}},\n    HT <: Union{Nothing,AbstractVector{<:AbstractMatrix{<:Real}}},\n    } <: SurrogateModel\n\n    # expansion point and value\n    x0 :: XT\n    fx0 :: FXT\n\n    # gradient(s) at x0\n    g :: G\n    H :: HT = nothing\nend\n\nfully_linear( :: TaylorModel ) = true","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Note, that the derivative approximations are actually constructed for the function(s)","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"    f_ℓ  s^-1","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"if some internal transformation s has happened before. If the problem is unbounded then s = operatornameid = s^-1.","category":"page"},{"location":"TaylorModel/#Model-Construction","page":"TaylorModels","title":"Model Construction","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Because of all the possibilities offered to the user, we actually have several (sub-)implementiations of SurrogateConfig for Taylor Models.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"abstract type TaylorCFG <: SurrogateConfig end","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"We make sure, that all subtypes have a field max_evals:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"max_evals( cfg :: TaylorCFG ) = cfg.max_evals","category":"page"},{"location":"TaylorModel/#Recursive-Finite-Difference-Models","page":"TaylorModels","title":"Recursive Finite Difference Models","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Let's start by defining the recommended way of using Taylor approximations. The derivative information is approximated using a dynamic programming approach and we take care to avoid unnecessary objective evaluations.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"@doc \"\"\"\n    TaylorConfig(; degree, gradients :: RFD.CFDStamp, hessians :: RFD.CFDStamp, max_evals)\n\nConfiguration for a polynomial Taylor model using finite difference approximations of the derivatives.\nBy default we have `degree = 2` and `gradients == hessians == RFD.CFDStamp(1,2)`, that is,\na first order central difference scheme of accuracy order 3 is recursed to compute the Hessians\nand the gradients.\nIn this case, the finite difference scheme is the same for both Hessians and gradients and we profit\nfrom caching intermediate results.\n\"\"\"\n@with_kw struct TaylorConfig{\n        S1 <: RFD.FiniteDiffStamp,\n        S2 <: Union{Nothing,RFD.FiniteDiffStamp}\n    } <: TaylorCFG\n\n    degree :: Int64 = 2\n\n    gradients :: S1 = RFD.CFDStamp(1,2)\n    hessians :: S2 = gradients\n\n    max_evals :: Int64 = typemax(Int64)\n\n    @assert 1 <= degree <= 2 \"Can only construct linear and quadratic polynomial Taylor models.\"\nend\n\ncombinable( :: TaylorConfig ) = true","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The new meta type only stores database indices of sites used for a finite diff approximation in the actual construction call and is filled in the prepare_XXX methods:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"@with_kw struct TaylorIndexMeta{W1, W2} <: SurrogateMeta\n    database_indices :: Vector{Int} = Int[]\n    grad_setter_indices :: Vector{Int} = Int[]\n    hess_setter_indices :: Vector{Int} = Int[]\n    hess_wrapper :: W1 = nothing\n    grad_wrapper :: W2 = nothing\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The end user won't be interested in the wrappers, so we put nothing in there:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"saveable_type( :: TaylorIndexMeta ) = TaylorIndexMeta{Nothing, Nothing}\nsaveable( meta :: TaylorIndexMeta ) = TaylorIndexMeta(;\n    grad_setter_indices = meta.grad_setter_indices,\n    hess_setter_indices = meta.hess_setter_indices\n)","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The new construction process it is a bit complicated. We set up a recursive finite diff tree and need this little helper:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"\"Return `unique_elems, indices = unique_with_indices(arr)` such that\n`unique_elems[indices] == arr` (and `unique_elems == unique(arr)`).\"\nfunction unique_with_indices( x :: AbstractVector{T} ) where T\n\tunique_elems = T[]\n\tindices = Int[]\n\tfor elem in x\n\t\ti = findfirst( e -> all( isequal.(e,elem) ), unique_elems )\n\t\tif isnothing(i)\n\t\t\tpush!(unique_elems, elem)\n\t\t\tpush!(indices, length(unique_elems) )\n\t\telse\n\t\t\tpush!(indices, i)\n\t\tend\n\tend\n\treturn unique_elems, indices\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Now, if the polynomial degree equals 2 we construct a tree for the Hessian calculation. In any case, we need a tree for the gradients/jacobian. If the RFD.FiniteDiffStamp for the gradients is the same as for the Hessians, we can re-use the Hessian tree for this purpose. Else, we need to construct a new one.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function _get_RFD_trees( x, fx, grad_stamp, hess_stamp = nothing, deg = 2)\n    if deg >= 2\n        @assert !isnothing(hess_stamp)\n        # construct tree for hessian first\n        hess_wrapper = RFD.DiffWrapper(; x0 = x, fx0 = fx, stamp = hess_stamp, order = 2 )\n    else\n        hess_wrapper = nothing\n    end\n\n    if !isnothing(hess_wrapper) && grad_stamp == hess_stamp\n        grad_wrapper = hess_wrapper\n    else\n        grad_wrapper = RFD.DiffWrapper(; x0 = x, fx0 = fx, stamp = grad_stamp, order = 1 )\n    end\n\n    return grad_wrapper, hess_wrapper\nend\n\n\nfunction prepare_init_model(cfg :: TaylorConfig, objf :: AbstractObjective,\n    mop :: AbstractMOP, iter_data ::AbstractIterData, db :: AbstractDB, algo_cfg :: AbstractConfig; kwargs...)\n\n    return prepare_update_model( nothing, objf, TaylorIndexMeta(), mop, iter_data, db, algo_cfg; kwargs... )\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The actual database preparations are delegated to the prepare_update_model function.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function prepare_update_model( mod :: Union{Nothing, TaylorModel}, objf, meta :: TaylorIndexMeta, mop,\n    iter_data, db, algo_cfg; kwargs... )\n\n    x = get_x( iter_data )\n    fx = get_fx( iter_data )\n    x_index = get_x_index( iter_data )\n\n    cfg = model_cfg( objf )\n\n    grad_wrapper, hess_wrapper = _get_RFD_trees( x, fx, cfg.gradients, cfg.hessians, cfg.degree )\n\n    XT = typeof(x)\n    FXT = typeof(fx)\n\n    lb, ub = full_bounds_internal( mop )\n\n    if cfg.degree >= 2\n        RFD.substitute_leaves!(hess_wrapper)\n        # We project into the scaled variable boundaries to avoid violations:\n        hess_sites = [ _project_into_box(s,lb,ub) for s in RFD.collect_leave_sites( hess_wrapper ) ]\n    else\n        hess_sites = XT[]\n    end\n\n    # collect leave sites for gradients\n    if grad_wrapper == hess_wrapper\n        grad_sites = hess_sites\n    else\n        RFD.substitute_leaves!( grad_wrapper )\n        grad_sites = [ _project_into_box(s, lb,ub) for s in RFD.collect_leave_sites( grad_wrapper ) ]\n    end\n\n    combined_sites = [ [x,]; hess_sites; grad_sites ]\n\n    unique_new, unique_indices = unique_with_indices(combined_sites)\n    # now: `combined_sites == unique_new[unique_indices]`\n\n    num_hess_sites = length(hess_sites)\n    hess_setter_indices = unique_indices[ 2 : num_hess_sites + 1]\n    grad_setter_indices = unique_indices[ num_hess_sites + 2 : end ]\n    # now: `hess_sites == unique_new[ hess_setter_indices ]` and\n    # `grad_sites == unique_new[ grad_setter_indices ]`\n\n    db_indices = [ [x_index,]; [ new_result!(db, ξ, FXT()) for ξ in unique_new[ 2:end ] ] ]\n    # now: `unique_new == get_site.(db, db_indices)`\n\n    # we return a new meta object in each iteration, so that the node cache is reset in between.\n    return TaylorIndexMeta(;\n        database_indices = db_indices,\n        grad_setter_indices,\n        hess_setter_indices,\n        grad_wrapper,\n        hess_wrapper\n    )\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"If the meta data is set correctly, we only have to set the value vectors for the RFD trees and then ask for the right matrices:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function _init_model( cfg :: TaylorConfig, objf :: AbstractObjective, mop :: AbstractMOP,\n    iter_data :: AbstractIterData, db :: AbstractDB, algo_config :: AbstractConfig, meta :: TaylorIndexMeta; kwargs... )\n    return update_model( nothing, objf, meta, mop, iter_data, db, algo_config; kwargs...)\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Note, that we only perform updates if the iterate has changed, x != mod.x0, because we don't change the differencing parameters.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function update_model( mod :: Union{Nothing, TaylorModel}, objf :: AbstractObjective, meta :: TaylorIndexMeta,\n    mop :: AbstractMOP, iter_data :: AbstractIterData, db :: AbstractDB, algo_config :: AbstractConfig; kwargs...)\n\n    x = get_x(iter_data)\n    if isnothing(mod) || (x != mod.x0)\n        all_leave_vals = get_value.( db, meta.database_indices )\n\n        if !isnothing( meta.hess_wrapper )\n            hess_leave_vals = all_leave_vals[ meta.hess_setter_indices ]\n            RFD.set_leave_values!( meta.hess_wrapper, hess_leave_vals )\n            H = [ RFD.hessian( meta.hess_wrapper; output_index = ℓ ) for ℓ = 1 : num_outputs(objf) ]\n        else\n            H = nothing\n        end\n\n        # calculate gradients\n        if meta.hess_wrapper != meta.grad_wrapper\n            grad_leave_vals = all_leave_vals[ meta.grad_setter_indices ]\n            RFD.set_leave_values!( meta.grad_wrapper, grad_leave_vals )\n        end\n\n        # if hessians have been calculated before and `grad_wrapper == hess_wrapper` we profit from caching\n        J = RFD.jacobian( meta.grad_wrapper )\n        g = copy.( eachrow( J ) )\n\n        return TaylorModel(;\n            x0 = x,\n            fx0 = get_fx( iter_data ),\n            g, H\n        ), meta\n    else\n        return mod,meta\n    end\nend","category":"page"},{"location":"TaylorModel/#Callback-Models-with-Derivatives,-AD-or-Adaptive-Finite-Differencing","page":"TaylorModels","title":"Callback Models with Derivatives, AD or Adaptive Finite Differencing","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The old way of defining Taylor Models was to provide an objective callback function and either give callbacks for the derivatives too or ask for automatic differencing. This is very similar to the ExactModels, with the notable difference that the gradient and Hessian information is only used to construct models m_ℓ = f_0 + mathbf g^T mathbf h + mathbf h^T mathbf H mathbf h once per iteration and then use these m_ℓ for all subsequent model evaluations/differentiation.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"\"\"\"\n    TaylorCallbackConfig(;degree=1,gradients,hessians=nothing,max_evals=typemax(Int64))\n\nConfiguration for a linear or quadratic Taylor model where there are callbacks provided for the\ngradients and -- if applicable -- the Hessians.\nThe `gradients` keyword point to an array of callbacks where each callback evaluates\nthe gradient of one of the outputs.\n\"\"\"\n@with_kw struct TaylorCallbackConfig{\n        G <:Union{Nothing,AbstractVector{<:Function}},\n        J <:Union{Nothing,Function},\n        H <:Union{Nothing,AbstractVector{<:Function}},\n    } <: TaylorCFG\n\n    degree :: Int64 = 1\n    gradients :: G\n    jacobian :: J = nothing\n    hessians :: H = nothing\n\n    max_evals :: Int64 = typemax(Int64)\n\n    @assert 1 <= degree <= 2 \"Can only construct linear and quadratic polynomial Taylor models.\"\n    @assert !(isnothing(gradients) && isnothing(jacobian)) \"Provide either `gradients` or `jacobian`.\"\n    @assert isa( gradients, AbstractVector ) && !isempty( gradients ) || !isnothing(jacobian) \"Provide either `gradients` or `jacobian`.\"\n    @assert !(isnothing(gradients)) && ( isnothing(hessians) || length(gradients) == length(hessians) ) \"Provide same number of gradients and hessians.\"\nend\n\n\"\"\"\n    TaylorApproximateConfig(;degree=1,mode=:fdm,max_evals=typemax(Int64))\n\nConfigure a linear or quadratic Taylor model where the gradients and Hessians are constructed\neither by finite differencing (`mode = :fdm`) or automatic differencing (`mode = :autodiff`).\n\"\"\"\n@with_kw struct TaylorApproximateConfig <: TaylorCFG\n    degree :: Int64 = 1\n\n    mode :: Symbol = :fdm\n\n    max_evals :: Int64 = typemax(Int64)\n\n    @assert 1 <= degree <= 2 \"Can only construct linear and quadratic polynomial Taylor models.\"\n    @assert mode in [:fdm, :autodiff] \"Use `mode = :fdm` or `mode = :autodiff`.\"\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"For these models, it is not advisable to combine objectives:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"combinable( :: Union{TaylorCallbackConfig, TaylorApproximateConfig}) = false","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"In both cases we transfer the finalized callbacks to the same meta structs. In fact, GW and HW are DiffFns as defined in src/diff_wrappers.jl (or nothing):","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"struct TaylorMetaCallbacks{GW, HW} <: SurrogateMeta\n    gw :: GW\n    hw :: HW\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"Again, we have a tfn::TransformerFn that represents the (un)scaling. \nIf callbacks are provided, then we use the GradWrapper and the HessWrapper.","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function init_meta( cfg :: TaylorCallbackConfig, objf, tfn )\n    gw = GradWrapper( tfn, cfg.gradients, cfg.jacobian )\n    hw = cfg.degree == 2 ? isa( cfg.hessians, AbstractVector{<:Function} ) ?\n        HessWrapper(tfn, cfg.hessians ) : nothing : nothing;\n    return TaylorMetaCallbacks( gw, hw )\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"If no callbacks are provided, we inspect the mode and use the corresponding wrappers:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function init_meta( cfg :: TaylorApproximateConfig, objf, tfn )\n    if cfg.mode == :fdm\n        gw = FiniteDiffWrapper(objf, tfn, nothing)\n    else\n        gw = AutoDiffWrapper( objf, tfn, nothing )\n    end\n    hw = cfg.degree == 2 ? HessFromGrads(gw) : nothing\n    return TaylorMetaCallbacks( gw, hw )\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The initialization for the legacy config types is straightforward as they don't use the new 2-phase process:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function prepare_init_model(cfg :: Union{TaylorCallbackConfig, TaylorApproximateConfig}, objf :: AbstractObjective,\n    mop :: AbstractMOP, ::AbstractIterData, ::AbstractDB, :: AbstractConfig; kwargs...)\n    tfn = TransformerFn(mop)\n    return init_meta( cfg, objf, tfn )\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The model construction happens in the update_model method and makes use of the get_gradient and get_hessian methods for the wrappers stored in meta:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function _init_model(cfg :: Union{TaylorCallbackConfig, TaylorApproximateConfig}, objf :: AbstractObjective,\n    mop :: AbstractMOP, iter_data ::AbstractIterData, db ::AbstractDB, algo_config :: AbstractConfig,\n    meta :: TaylorMetaCallbacks; kwargs...)\n    return update_model(nothing, objf, meta, mop, iter_data, db, algo_config; kwargs...)\nend\n\nfunction update_model( mod :: Union{Nothing,TaylorModel}, objf :: AbstractObjective, meta :: TaylorMetaCallbacks,\n    mop :: AbstractMOP, iter_data :: AbstractIterData, db :: AbstractDB, algo_config :: AbstractConfig; kwargs...)\n\n    x = get_x(iter_data)\n    if isnothing(mod) || (x != mod.x0)\n        fx = get_fx( iter_data )\n\n        num_out = num_outputs( objf )\n        g = [ get_gradient(meta.gw , x , ℓ ) for ℓ = 1 : num_out ]\n\n        if !isnothing(meta.hw)\n            H = [ get_hessian(meta.hw, x, ℓ) for ℓ = 1 : num_out ]\n        else\n            H = nothing\n        end\n\n        return TaylorModel(; x0 = x, fx0 = fx, g, H ), meta\n    else\n        return mod, meta\n    end\n\nend","category":"page"},{"location":"TaylorModel/#Model-Evaluation","page":"TaylorModels","title":"Model Evaluation","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The evaluation of a Taylor model of form","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"    m_ℓ(mathbf x) = f_ℓ(mathbf x_0) +\n    mathbf g^T ( mathbf x - mathbf x_0 ) + ( mathbf x - mathbf x_0 )^T mathbf H_ℓ ( mathbf x - mathbf x_0)","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"is straightforward:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"\"Evaluate (internal) output `ℓ` of TaylorModel `tm`, provided a difference vector `h = x - x0`.\"\nfunction _eval_models( tm :: TaylorModel, h :: Vec, ℓ :: Int )\n    ret_val = tm.fx0[ℓ] + tm.g[ℓ]'h\n    if !isnothing(tm.H)\n        ret_val += .5 * h'tm.H[ℓ]*h\n    end\n    return ret_val\nend\n\n\"Evaluate (internal) output `ℓ` of `tm` at scaled site `x̂`.\"\nfunction eval_models( tm :: TaylorModel, x̂ :: Vec, ℓ :: Int )\n    h = x̂ .- tm.x0\n    return _eval_models( tm, h, ℓ)\n end","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"For the vector valued model, we iterate over all (internal) outputs:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function eval_models( tm :: TaylorModel, x̂ :: Vec )\n    h = x̂ .- tm.x0\n    return [ _eval_models(tm, h, ℓ) for ℓ = eachindex(tm.g)]\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The gradient of m_ℓ can easily be determined:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function get_gradient( tm :: TaylorModel, x̂ :: Vec, ℓ :: Int)\n    if isnothing(tm.H)\n        return tm.g[ℓ]\n    else\n        h = x̂ .- tm.x0\n        return tm.g[ℓ] .+ .5 * ( tm.H[ℓ]' + tm.H[ℓ] ) * h\n    end\nend","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"And for the Jacobian, we again iterate:","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"function get_jacobian( tm :: TaylorModel, x̂ :: Vec )\n    grad_list = [ get_gradient(tm, x̂, ℓ) for ℓ=eachindex( tm.g ) ]\n    return transpose( hcat( grad_list... ) )\nend","category":"page"},{"location":"TaylorModel/#Summary-and-Quick-Examples","page":"TaylorModels","title":"Summary & Quick Examples","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"The recommended way to use Finite Difference Taylor models is to define them with TaylorConfig, i.e.,\nadd_objective!(mop, f, TaylorConfig())\nTo use FiniteDiff.jl instead, do\nadd_objective!(mop, f, TaylorApproximateConfig(; mode = :fdm))\nHave callbacks for the gradients and the Hessians? Great!\nadd_objective!(mop, f, TaylorCallbackConfig(; degree = 1, gradients = [g1,g2]))\nNo callbacks, but you want the correct matrices anyways? ForwardDiff to the rescue:\nadd_objective!(mop, f, TaylorApproximateConfig(; degree = 2, mode = :autodiff)","category":"page"},{"location":"TaylorModel/#Complete-usage-example","page":"TaylorModels","title":"Complete usage example","text":"","category":"section"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"using Morbit\nMorbit.print_all_logs()\nmop = MixedMOP(3)\n\nadd_objective!( mop, x -> sum( ( x .- 1 ).^2 ), Morbit.TaylorApproximateConfig(;degree=2,mode=:fdm) )\nadd_objective!( mop, x -> sum( ( x .+ 1 ).^2 ), Morbit.TaylorApproximateConfig(;degree=2,mode=:autodiff) )\n\nx_fin, f_fin, _ = optimize( mop, [-π, ℯ, 0])","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"","category":"page"},{"location":"TaylorModel/","page":"TaylorModels","title":"TaylorModels","text":"This page was generated using Literate.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Morbit","category":"page"},{"location":"#Morbit","page":"Home","title":"Morbit","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package Morbit.jl provides a local derivative-free solver for multiobjective optimization problems with possibly expensive objectives. It is meant to find a single Pareto-critical point, not a good covering of the global Pareto Set.","category":"page"},{"location":"","page":"Home","title":"Home","text":"“Morbit” stands for Multiobjective Optimization by Radial Basis Function Interpolation in Trust-regions.  The name was chosen so as to pay honors to the single objective algorithm ORBIT by Wild et. al.  ","category":"page"},{"location":"","page":"Home","title":"Home","text":"We have a paper explaining the algorithm!","category":"page"},{"location":"","page":"Home","title":"Home","text":"This was my first project using Julia and there have been many messy rewrites. Nonetheless, the solver should now work sufficiently well to tackle most problems.  I hope to rewrite the custom types soonish. At the moment they are weakly typed and the performance suffers.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To get started, see the examples, e.g. Two Parabolas.","category":"page"},{"location":"","page":"Home","title":"Home","text":"There are also some documentation pages for the different model types. These were auto-generated from source code using Literate.jl. Hence, they are very detailed but not user-oriented, except for some usage examples at the bottom.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This project was founded by the European Region Development Fund.","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"https://www.efre.nrw.de/fileadmin/Logos/EU-Fo__rderhinweis__EFRE_/EFRE_Foerderhinweis_englisch_farbig.jpg\" width=\"45%\"/>","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"https://www.efre.nrw.de/fileadmin/Logos/Programm_EFRE.NRW/Ziel2NRW_RGB_1809_jpg.jpg\" width=\"45%\"/>","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"EditURL = \"https://github.com/manuelbb-upb/Morbit.jl/blob/master/src/ExactModel.jl\"","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"Exact models","category":"page"},{"location":"ExactModel/#Introduction","page":"ExactModels","title":"Introduction","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"The ExactModel is used to evaluate the objective exactly, without surrogate modelling (except for internal variable scaling). The derivatives are either user provided callbacks or can be deterimned using ForwardDiff or FiniteDiff automatically.","category":"page"},{"location":"ExactModel/#Surrogate-Model-Interface-Implementations","page":"ExactModels","title":"Surrogate Model Interface Implementations","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"\"\"\"\n    ExactModel( tfn, objf, diff_fn )\n\nExact Model type for evaluating the objective function `objf` directly.\nIs instantiated by the corresponding `init_model` and `update_model` functions.\n\"\"\"\nstruct ExactModel{\n        M <: TransformerFn,\n        O <: AbstractObjective,\n        D <: DiffFn\n    } <: SurrogateModel\n\n    # reference to a `TransformerFn` to have unscaling availabe:\n    tfn :: M\n\n    # reference to objective(s) to evaluate\n    objf :: O\n\n    # a `DiffFn` providing derivative information\n    diff_fn :: Union{D,Nothing}\nend","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"The can determine the behavior of an ExactModel using ExactConfig:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"\"\"\"\n    ExactConfig(; gradients, jacobian = nothing, max_evals = typemax(Int64))\n\nConfiguration for an `ExactModel`.\n`gradients` should be a vector of callbacks for the objective gradients **or**\na `Symbol`, either `:autodiff` or `fdm`, to define the differentiation method\nto use on the objective.\nAlternatively, a `jacobian` handle can be provided.\n\"\"\"\n@with_kw struct ExactConfig{\n        G <: Union{Symbol, Nothing, AbstractVector{<:Function} },\n        J <: Union{Nothing, Function}\n    } <: SurrogateConfig\n\n    gradients :: G = :autodiff\n    # alternative keyword, usage discouraged...\n    jacobian :: J = nothing\n\n    max_evals :: Int64 = typemax(Int64)\n\n    @assert !(isnothing(gradients) && isnothing(jacobian)) \"Provide either `gradients` or `jacobian`.\"\n    @assert !(gradients isa Symbol) || gradients in [:autodiff, :fdm ] \"`gradients` must be `:autodiff` or `:fdm`\"\nend","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"There is no need for custom meta information:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"struct ExactMeta <: SurrogateMeta end   # no construction meta data needed","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"The remaining implementations are straightforward:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"max_evals( emc :: ExactConfig ) = emc.max_evals","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"We always deem the models fully linear:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"fully_linear( em :: ExactModel ) = true","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"They are not combinable to have individiual gradients availabe:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"combinable( :: ExactConfig ) = false","category":"page"},{"location":"ExactModel/#Construction","page":"ExactModels","title":"Construction","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"When cfg.gradients is a Symbol we make use of the DiffWrappers defined in src/diff_wrappers.jl:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"function get_DiffFn( cfg :: ExactConfig{G,J}, objf :: AbstractObjective, tfn ) where{G<:Symbol,J}\n    if cfg.gradients == :autodiff\n        return AutoDiffWrapper( objf, tfn, nothing )\n    elseif cfg.gradients == :fdm\n        return FiniteDiffWrapper( objf, tfn, nothing );\n    end\nend","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"Else we use a GradWrapper:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"function get_DiffFn( cfg :: ExactConfig{G,J}, objf :: AbstractObjective, tfn) where{G,J}\n    @assert length(cfg.gradients) == num_outputs(objf) \"Provide as many gradient functions as the objective has outputs.\"\n    return GradWrapper( tfn, cfg.gradients, cfg.jacobian )\nend","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"All \"construction\" work is done in the _init_model function:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"function prepare_init_model(cfg ::ExactConfig, objf :: AbstractObjective,\n    mop :: AbstractMOP, ::AbstractIterData, ::AbstractDB, :: AbstractConfig; kwargs...)\n    return ExactMeta()\nend\n\n@doc \"Return an ExactModel build from a VectorObjectiveFunction `objf`.\nModel is the same inside and outside of criticality round.\"\nfunction _init_model(cfg ::ExactConfig, objf :: AbstractObjective,\n    mop :: AbstractMOP, ::AbstractIterData, ::AbstractDB, :: AbstractConfig, emeta :: ExactMeta; kwargs...)\n    tfn = TransformerFn(mop)\n    diff_fn = get_DiffFn( cfg, objf, tfn )\n    em = ExactModel(tfn, objf, diff_fn )\n    return em, emeta\nend","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"All the other functions simply return the input:","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"function update_model( em :: ExactModel, :: AbstractObjective, meta ::ExactMeta,\n    ::AbstractMOP, :: AbstractIterData, ::AbstractDB, :: AbstractConfig;\n    ensure_fully_linear :: Bool = false, kwargs... )\n    return em, meta\nend\n\nfunction improve_model( em :: ExactModel, :: AbstractObjective, meta ::ExactMeta,\n    ::AbstractMOP, :: AbstractIterData, ::AbstractDB, :: AbstractConfig;\n    ensure_fully_linear :: Bool = false, kwargs ... )\n    return em, meta\nend","category":"page"},{"location":"ExactModel/#Evaluation","page":"ExactModels","title":"Evaluation","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"@doc \"Evaluate the ExactModel `em` at scaled site `x̂`.\"\nfunction eval_models( em :: ExactModel, x̂ :: Vec )\n    return eval_objf( em.objf, em.tfn, x̂ )\n    # using `eval_objf` will increase the evaluation count of `em.objf`\n    # That is why this count might be very high when using backtracking.\n    # eval_handle( em.objf )(x̂) would not increase the count.\nend\n\n@doc \"Evaluate output `ℓ` of the ExactModel `em` at scaled site `x̂`.\"\nfunction eval_models( em :: ExactModel, x̂ :: Vec, ℓ :: Int64)\n    return eval_models(em,x̂)[ℓ]\nend\n\n@doc \"Gradient vector of output `ℓ` of `em` at scaled site `x̂`.\"\nfunction get_gradient( em :: ExactModel, x̂ :: Vec, ℓ :: Int64)\n    return get_gradient( em.diff_fn, x̂, ℓ )\nend\n\n@doc \"Jacobian Matrix of ExactModel `em` at scaled site `x̂`.\"\nfunction get_jacobian( em :: ExactModel, x̂ :: Vec )\n    return get_jacobian( em.diff_fn, x̂ );\nend","category":"page"},{"location":"ExactModel/#Quick-Usage-Example","page":"ExactModels","title":"Quick Usage Example","text":"","category":"section"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"using Morbit\nMorbit.print_all_logs()\nmop = MixedMOP(3)\n\nf1 = x -> sum( ( x .- 1 ).^2\nf2 = x -> sum( ( x .+ 1 ).^2\ng1 = x -> 2 .* ( x .- 1 )\ng2 = x -> 2 .* ( x .+ 1 )\n\nadd_objective!( mop, f1, ExactConfig(; gradients = [g1,]) )\nadd_objective!( mop, f2, ExactConfig(; gradients = [g2,]) )\n\nx_fin, f_fin, _ = optimize( mop, [-π, ℯ, 0])","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"","category":"page"},{"location":"ExactModel/","page":"ExactModels","title":"ExactModels","text":"This page was generated using Literate.jl.","category":"page"}]
}
